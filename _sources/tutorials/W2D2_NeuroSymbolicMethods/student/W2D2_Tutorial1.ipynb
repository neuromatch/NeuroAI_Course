{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {},
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/neuromatch/NeuroAI_Course/blob/main/tutorials/W2D2_NeuroSymbolicMethods/student/W2D2_Tutorial1.ipynb\" target=\"_blank\"><img alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"/></a> Â  <a href=\"https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/neuromatch/NeuroAI_Course/main/tutorials/W2D2_NeuroSymbolicMethods/student/W2D2_Tutorial1.ipynb\" target=\"_blank\"><img alt=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Tutorial 1: Basic operations of vector symbolic algebra \n",
    "\n",
    "**Week 2, Day 2: Neuro-Symbolic Methods**\n",
    "\n",
    "**By Neuromatch Academy**\n",
    "\n",
    "__Content creators:__ P. Michael Furlong, Chris Eliasmith\n",
    "\n",
    "__Content reviewers:__ Hlib Solodzhuk, Patrick Mineault, Aakash Agrawal, Alish Dipani, Hossein Rezaei, Yousef Ghanbari, Mostafa Abdollahi\n",
    "\n",
    "__Production editors:__ Konstantine Tsafatinos, Ella Batty, Spiros Chavlis, Samuele Bolotta, Hlib Solodzhuk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "___\n",
    "\n",
    "\n",
    "# Tutorial Objectives\n",
    "\n",
    "*Estimated timing of tutorial: 1 hour*\n",
    "\n",
    "In this tutorial we will introduce vector symbolic algebra and discuss its main operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @markdown\n",
    "from IPython.display import IFrame\n",
    "from ipywidgets import widgets\n",
    "out = widgets.Output()\n",
    "with out:\n",
    "    print(f\"If you want to download the slides: https://osf.io/download/2szmk/\")\n",
    "    display(IFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/2szmk/?direct%26mode=render%26action=download%26mode=render\", width=730, height=410))\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Install and import feedback gadget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Install and import feedback gadget\n",
    "\n",
    "!pip install --quiet numpy matplotlib ipywidgets scipy vibecheck\n",
    "\n",
    "from vibecheck import DatatopsContentReviewContainer\n",
    "def content_review(notebook_section: str):\n",
    "    return DatatopsContentReviewContainer(\n",
    "        \"\",  # No text prompt\n",
    "        notebook_section,\n",
    "        {\n",
    "            \"url\": \"https://pmyvdlilci.execute-api.us-east-1.amazonaws.com/klab\",\n",
    "            \"name\": \"neuromatch_neuroai\",\n",
    "            \"user_key\": \"wb2cxze8\",\n",
    "        },\n",
    "    ).render()\n",
    "\n",
    "\n",
    "feedback_prefix = \"W2D2_T1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Notice that exactly the `neuromatch` branch of `sspspace` should be installed! Otherwise, some of the functionality won't work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Install dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Install dependencies\n",
    "\n",
    "# Install sspspace\n",
    "!pip install git+https://github.com/neuromatch/sspspace@neuromatch --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Imports\n",
    "\n",
    "#working with data\n",
    "import numpy as np\n",
    "\n",
    "#plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "#interactive display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "#modeling\n",
    "import sspspace\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Figure settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Figure settings\n",
    "\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' # perfrom high definition rendering for images and plots\n",
    "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/nma.mplstyle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Plotting functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Plotting functions\n",
    "\n",
    "def plot_vectors(concepts, labels, shape = (32, 32)):\n",
    "    \"\"\"\n",
    "    Plot vector symbols associated with the given concepts.\n",
    "\n",
    "    Inputs:\n",
    "    - concepts (list of sspspace.ssp.SSP): list of concepts which contain associated vectors.\n",
    "    - labels (list of str): list of strings which represent concepts.\n",
    "    - shape (tuple, default = (32, 32)): desired image shape.\n",
    "    \"\"\"\n",
    "    with plt.xkcd():\n",
    "        n = len(concepts)\n",
    "        for i in range(len(concepts)):\n",
    "            plt.subplot(1,n,i+1)\n",
    "            plt.imshow(concepts[i].view(dtype=float,type=np.ndarray).reshape(shape), cmap='Greys')\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.title(labels[i])\n",
    "\n",
    "def plot_similarity_matrix(sim_mat, labels, values = False):\n",
    "    \"\"\"\n",
    "    Plot the similarity matrix between vectors.\n",
    "\n",
    "    Inputs:\n",
    "    - sim_mat (numpy.ndarray): similarity matrix between vectors.\n",
    "    - labels (list of str): list of strings which represent concepts.\n",
    "    - values (bool): True if we would like to plot values of similarity too.\n",
    "    \"\"\"\n",
    "    with plt.xkcd():\n",
    "        plt.imshow(sim_mat, cmap='Greys')\n",
    "        plt.colorbar()\n",
    "        plt.xticks(np.arange(len(labels)), labels, rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "        plt.yticks(np.arange(len(labels)), labels)\n",
    "        if values:\n",
    "            for x in range(sim_mat.shape[1]):\n",
    "                for y in range(sim_mat.shape[0]):\n",
    "                    plt.text(x, y, f\"{sim_mat[y, x]:.2f}\", fontsize = 8, ha=\"center\", va=\"center\", color=\"green\")\n",
    "        plt.title('Similarity between vector-symbols')\n",
    "        plt.xlabel('Symbols')\n",
    "        plt.ylabel('Symbols')\n",
    "        plt.show()\n",
    "\n",
    "def plot_line_similarity_matrix(sim_mat, xaxis_ticks, multiple_objects = True, labels = None, title = \"Awesome title!\"):\n",
    "    \"\"\"\n",
    "    Plot similarirty matrix (or vector if multiple_objects is False) as lines.\n",
    "\n",
    "    Inputs:\n",
    "    - sim_mat (numpy.ndarray): similarity matrix between vectors.\n",
    "    - xaxis_ticks (list): list of ticks to put in x-axis.\n",
    "    - multiple_objects (bool, default = True): True if there are a couple of objects to plot similarity.\n",
    "    - labels (list, default = None): labels to plot.\n",
    "    - title (str): title of the plot.\n",
    "    \"\"\"\n",
    "    with plt.xkcd():\n",
    "        if multiple_objects:\n",
    "            for idx, integer_sims in enumerate(sim_mat):\n",
    "                if labels:\n",
    "                    plt.plot(xaxis_ticks, integer_sims.flatten(), label=f'$\\phi$[{idx+1}]', marker='o', ls='--')\n",
    "                else:\n",
    "                    plt.plot(xaxis_ticks, integer_sims.flatten(), marker='o', ls='--')\n",
    "        else:\n",
    "            plt.plot(xaxis_ticks,sim_mat.flatten(), ls='--',marker='o')\n",
    "\n",
    "    plt.ylabel('Similarity')\n",
    "    plt.xlabel('n')\n",
    "    plt.xticks(xaxis_ticks)\n",
    "    if labels:\n",
    "        plt.legend(loc='upper right')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def plot_double_line_similarity_matrix(sim_mat, xaxis_ticks, labels, title):\n",
    "    \"\"\"\n",
    "    Plot similarirty matrix (or vector if multiple_objects is False) as lines for two different matrices.\n",
    "\n",
    "    Inputs:\n",
    "    - sim_mat (numpy.ndarray): list of similarity matrix between vectors.\n",
    "    - xaxis_ticks (list): list of ticks to put in x-axis.\n",
    "    - multiple_objects (bool, default = True): True if there are a couple of objects to plot similarity.\n",
    "    - labels (list): labels to plot.\n",
    "    - title (str): title of the plot.\n",
    "    \"\"\"\n",
    "    with plt.xkcd():\n",
    "        plt.plot(xaxis_ticks,sim_mat[0].flatten(), ls='--',marker='o', label = labels[0])\n",
    "        plt.plot(xaxis_ticks,sim_mat[1].flatten(), ls='--',marker='o', label = labels[1])\n",
    "    plt.ylabel('Similarity')\n",
    "    plt.xlabel('n')\n",
    "    plt.xticks(xaxis_ticks)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def plot_real_valued_line_similarity(sim_mat, x_range, title):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - sim_mat (numpy.ndarray): similarity matrix between vectors.\n",
    "    - x_range (numpy.ndarray): x-axis range.\n",
    "    - title (str): title of the plot.\n",
    "    \"\"\"\n",
    "    with plt.xkcd():\n",
    "        plt.plot(x_range, sim_mat)\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('Similarity')\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Set random seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Set random seed\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def set_seed(seed=None):\n",
    "  if seed is None:\n",
    "    seed = np.random.choice(2 ** 32)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "\n",
    "set_seed(seed = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Helper functions\n",
    "\n",
    "# mainly contains solutions to exercises for correct plot output; please don't take a look!\n",
    "set_seed(42)\n",
    "\n",
    "vector_length = 1024\n",
    "symbol_names = ['circle','square','triangle']\n",
    "discrete_space = sspspace.DiscreteSPSpace(symbol_names, ssp_dim=vector_length, optimize = False)\n",
    "\n",
    "circle = discrete_space.encode('circle')\n",
    "square = discrete_space.encode('square')\n",
    "triangle = discrete_space.encode('triangle')\n",
    "\n",
    "shape = (circle + square + triangle).normalize()\n",
    "\n",
    "shape_sim_mat = np.zeros((4,4))\n",
    "\n",
    "shape_sim_mat[0,0] = (circle | circle).item()\n",
    "shape_sim_mat[1,1] = (square | square).item()\n",
    "shape_sim_mat[2,2] = (triangle | triangle).item()\n",
    "shape_sim_mat[3,3] = (shape | shape).item()\n",
    "\n",
    "shape_sim_mat[0,1] = shape_sim_mat[1,0] = (circle | square).item()\n",
    "shape_sim_mat[0,2] = shape_sim_mat[2,0] = (circle | triangle).item()\n",
    "shape_sim_mat[0,3] = shape_sim_mat[3,0] = (circle | shape).item()\n",
    "\n",
    "shape_sim_mat[1,2] = shape_sim_mat[2,1] = (square | triangle).item()\n",
    "shape_sim_mat[1,3] = shape_sim_mat[3,1] = (square | shape).item()\n",
    "\n",
    "shape_sim_mat[2,3] = shape_sim_mat[3,2] = (triangle | shape).item()\n",
    "\n",
    "new_symbol_names = ['circle','square','triangle', 'red', 'blue', 'green']\n",
    "new_discrete_space = sspspace.DiscreteSPSpace(new_symbol_names, ssp_dim=vector_length, optimize=False)\n",
    "\n",
    "objs = {n:new_discrete_space.encode(np.array([n])) for n in new_symbol_names}\n",
    "\n",
    "objs['red*circle'] = objs['red'] * objs['circle']\n",
    "objs['blue*triangle'] = objs['blue'] * objs['triangle']\n",
    "objs['green*square'] = objs['green'] * objs['square']\n",
    "\n",
    "new_object_names = ['red','red^','red*circle','circle','circle^']\n",
    "new_objs = objs.copy()\n",
    "\n",
    "new_objs['red^'] = new_objs['red*circle'] * ~new_objs['circle']\n",
    "new_objs['circle^'] = new_objs['red*circle'] * ~new_objs['red']\n",
    "\n",
    "axis_vectors = ['one']\n",
    "\n",
    "encoder = sspspace.DiscreteSPSpace(axis_vectors, ssp_dim=1024, optimize=False)\n",
    "\n",
    "vocab = {w:encoder.encode(w) for w in axis_vectors}\n",
    "\n",
    "integers = [vocab['one']]\n",
    "\n",
    "max_int = 5\n",
    "for i in range(2, max_int + 1):\n",
    "    integers.append(integers[-1] * vocab['one'])\n",
    "\n",
    "integers = np.array(integers).squeeze()\n",
    "integer_sims = integers @ integers.T\n",
    "\n",
    "five_unbind_two = sspspace.SSP(integers[4]) * ~sspspace.SSP(integers[1])\n",
    "five_unbind_two_sims = five_unbind_two @ integers.T\n",
    "\n",
    "new_encoder = sspspace.RandomSSPSpace(domain_dim=1, ssp_dim=1024)\n",
    "\n",
    "xs = np.linspace(-4,4,401)[:,None]\n",
    "phis = new_encoder.encode(xs)\n",
    "\n",
    "real_line_sims = phis[200, :] @ phis.T\n",
    "\n",
    "phi_shifted = phis[200,:][None,:] * new_encoder.encode([[np.pi/2]])\n",
    "shifted_real_line_sims = phi_shifted.flatten() @ phis.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "\n",
    "# Section 1: High-dimensional vector symbols\n",
    "\n",
    "In this section, we are going to start our journey by representing concepts as high-dimensional vectors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Video 1: Similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Video 1: Similarity\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', 'D9VzF9AyDic'), ('Bilibili', 'BV17x4y1b7ED')]\n",
    "tab_contents = display_videos(video_ids, W=730, H=410)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Submit your feedback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_high_dimensional_vector_symbols\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding Exercise 1: Concepts as High-Dimensional Vectors\n",
    "\n",
    "In an arbitrary space of concepts, we will represent the ideas of 'circle,' 'square,' and triangle.' For that, we will use the SSP space library (`sspspace`) to map identifiers for the concepts (strings of their names in this case) into high-dimensional vectors of unit length. It means that for each `name`, we will uniquely identify $\\mathbf{v}$ where $||\\mathbf{v}|| = 1$.\n",
    "\n",
    "In this exercise, check that, indeed, vectors are of unit length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete check that norms of the vector representations are of unit lengths.\")\n",
    "###################################################################\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "vector_length = 1024\n",
    "symbol_names = ['circle','square','triangle']\n",
    "discrete_space = sspspace.DiscreteSPSpace(symbol_names, ssp_dim=vector_length, optimize = False)\n",
    "\n",
    "circle = discrete_space.encode('circle')\n",
    "square = discrete_space.encode('square')\n",
    "triangle = discrete_space.encode('triangle')\n",
    "\n",
    "print('|circle| =', np.linalg.norm(circle))\n",
    "print('|triangle| =', np.linalg.norm(...))\n",
    "print('|square| =', ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_NeuroSymbolicMethods/solutions/W2D2_Tutorial1_Solution_a86d03c8.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We can visualize the assigned vectors as 32x32 images (notice that the dimension is 1024; it is exactly 32 multiplied by 32)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "plot_vectors([circle, square, triangle], symbol_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "As vectors are assigned randomly, the images do not display any meaningful structure.\n",
    "\n",
    "One of the most useful properties of random high-dimensional vectors is that they are approximately orthogonal. This is an important aspect for vector symbolic algebras (VSAs) since we will use the vector dot product to measure similarity between objects encoded as random, high-dimensional vectors. \n",
    "\n",
    "Discrete objects are either the same or different, so we expect similarity would be either 1 (the same) or 0 (not the same). Given how we select the vectors that represent discrete symbols if they are the same, they will have the dot product of 1, and if they are different concepts, then they will have a dot product of (approximately) 0.\n",
    "\n",
    "Below, we use the | operator to indicate similarity. This is borrowed from the bra-ket notation in physics, i.e.,\n",
    "\n",
    "$$\n",
    "\\mathbf{a}\\cdot\\mathbf{b} = \\langle \\mathbf{a} \\mid \\mathbf{b}\\rangle\n",
    "$$\n",
    "\n",
    "Notice that this operator **| is** the **dot product** under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "concepts_sim_mat = np.zeros((3,3))\n",
    "\n",
    "concepts_sim_mat[0,0] = (circle | circle).item()\n",
    "concepts_sim_mat[1,1] = (square | square).item()\n",
    "concepts_sim_mat[2,2] = (triangle | triangle).item()\n",
    "\n",
    "concepts_sim_mat[0,1] = concepts_sim_mat[1,0] = (circle | square).item()\n",
    "concepts_sim_mat[0,2] = concepts_sim_mat[2,0] = (circle | triangle).item()\n",
    "concepts_sim_mat[1,2] = concepts_sim_mat[2,1] = (square | triangle).item()\n",
    "\n",
    "plot_similarity_matrix(concepts_sim_mat, symbol_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "As you can see from the above figure, the three randomly selected vectors are approximately orthogonal. This will be important later when we go to make more complicated objects from our vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Submit your feedback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_concepts_as_high_dimensional_vectors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "\n",
    "# Section 2: Bundling\n",
    "\n",
    "Estimated timing to here from start of tutorial: 10 minutes\n",
    "\n",
    "In this section, we are going to explore the bundling operation, which allows us to construct vectors that represent something like sets. Basically, we combine two vectors into a new one that retains similarity to the previous two. We implement bundling using vector addition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Video 2: Bundling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Video 2: Bundling\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', 'MzOjyvWTdmI'), ('Bilibili', 'BV1LS411P7pf')]\n",
    "tab_contents = display_videos(video_ids, W=730, H=410)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Submit your feedback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_bundling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding Exercise 2: A Composite Object - Shape\n",
    "\n",
    "Let's start with our previous example of different shapes (circle, square, and triangle) and use them to create a new object, 'shape,' which will represent all the atomic concepts we've introduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "shape = (circle + square + triangle).normalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Notice that we need to normalize the obtained vector. Now, let us calculate the similarity matrix for the three default concepts and the new one.\n",
    "\n",
    "In the exercise below, complete the similarity matrix calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete calcualtion of similarity matrix.\")\n",
    "###################################################################\n",
    "\n",
    "shape_sim_mat = np.zeros((4,4))\n",
    "\n",
    "shape_sim_mat[0,0] = (circle | circle).item()\n",
    "shape_sim_mat[1,1] = (square | square).item()\n",
    "shape_sim_mat[2,2] = (triangle | ...).item()\n",
    "shape_sim_mat[3,3] = (shape | ...).item()\n",
    "\n",
    "shape_sim_mat[0,1] = shape_sim_mat[1,0] = (circle | square).item()\n",
    "shape_sim_mat[0,2] = shape_sim_mat[2,0] = (circle | triangle).item()\n",
    "shape_sim_mat[0,3] = shape_sim_mat[3,0] = (circle | shape).item()\n",
    "\n",
    "shape_sim_mat[1,2] = shape_sim_mat[2,1] = (square | triangle).item()\n",
    "shape_sim_mat[1,3] = shape_sim_mat[3,1] = (square | shape).item()\n",
    "\n",
    "shape_sim_mat[2,3] = shape_sim_mat[3,2] = (... | ...).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_NeuroSymbolicMethods/solutions/W2D2_Tutorial1_Solution_708701bb.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "plot_similarity_matrix(shape_sim_mat, symbol_names + [\"shape\"], values = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Observe that as each of the basic concepts was included equally in the definition of the 'shape' symbol, it has the same similarity between all other vectors, pairwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Coding Exercise 2 Discussion\n",
    "\n",
    "1. Why do we need to normalize the vector obtained as a result of the bundling operation? What length do you expect to receive without normalization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_NeuroSymbolicMethods/solutions/W2D2_Tutorial1_Solution_b9294b66.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Submit your feedback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_composite_object_shape\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "\n",
    "# Section 3: Binding & Unbinding\n",
    "\n",
    "Estimated timing to here from start of tutorial: 20 minutes\n",
    "\n",
    "In this section, we will talk about binding, an operation that takes two vectors and produces a new vector that is *not* similar to either of its constituent elements.\n",
    "\n",
    "Binding and unbinding are implemented using circular convolution.  Luckily, that is implemented for you inside the SSPSpace library. If you would like a refresher on convolution, this [Three Blue One Brown video](https://www.youtube.com/watch?v=KuXjwB4LzSA) is a good place to start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Video 3: Binding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Video 3: Binding\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', 'pSWjd3EcrXI'), ('Bilibili', 'BV19n4y197jt')]\n",
    "tab_contents = display_videos(video_ids, W=730, H=410)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Submit your feedback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_binding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding Exercise 3: Colorful Shapes\n",
    "\n",
    "We can think of binding as an \"and\"-like operation. Both arguments need to be the same to produce a similar vector. In this example, let's think about colors and shapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "new_symbol_names = ['circle','square','triangle', 'red', 'blue', 'green']\n",
    "new_discrete_space = sspspace.DiscreteSPSpace(new_symbol_names, ssp_dim=vector_length, optimize=False)\n",
    "\n",
    "objs = {n:new_discrete_space.encode(np.array([n])) for n in new_symbol_names}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now, we are going to take two of the objects to make new ones: a red circle, a blue triangle, and a green square.\n",
    "\n",
    "We will combine the two primitive objects using the binding operation, which for us is implemented using circular convolution, and we denote it by \n",
    "\n",
    "\\begin{align*}\n",
    " a \\circledast b\n",
    "\\end{align*}\n",
    "\n",
    "<details>\n",
    "<summary>Mathematical details</summary>\n",
    "\n",
    "The circular convolution of two vectors $\\mathbf{a}$ and $\\mathbf{b} \\in \\mathbb{R}^N$ is defined as:\n",
    "\n",
    "$$c_j = a \\circledast b = \\sum_{k=1}^{N} a_k b_{1 + (j-k) \\mod N}$$\n",
    "\n",
    "where $N$ is the length of the vectors, and $j$ is the index of the output vector. It's often more convenient to calculate the circular convolution in the Fourier domain. The circular convolution is equivalent to the element-wise product of the Fourier transforms of the two vectors, followed by an inverse Fourier transform:\n",
    "\n",
    "$$a \\circledast b = \\mathcal{F}^{-1}(\\mathcal{F}(\\mathbf{a}) \\odot \\mathcal{F}(\\mathbf{b}))$$\n",
    "where $\\mathcal{F}$ is the Fourier transform, $\\odot$ is the element-wise product, and $\\mathcal{F}^{-1}$ is the inverse Fourier transform. The equivalence between these two formulations is a consequence of the [convolution theorem](https://en.wikipedia.org/wiki/Convolution_theorem).\n",
    "\n",
    "</details>\n",
    "\n",
    "In the cell below, complete the missing concepts and then observe the computed similarity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete derivation of new objects using binding operation.\")\n",
    "###################################################################\n",
    "\n",
    "objs['red*circle'] = objs['red'] * objs['circle']\n",
    "objs['blue*triangle'] = ... * objs['triangle']\n",
    "objs['green*square'] = objs['green'] * ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_NeuroSymbolicMethods/solutions/W2D2_Tutorial1_Solution_f9fa3af1.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Notice how we iterate through all objects in `object_names` and calculate pairwise dot products (similarity metric)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "object_names = list(objs.keys())\n",
    "obj_sims = np.zeros((len(object_names), len(object_names)))\n",
    "\n",
    "for name_idx, name in enumerate(object_names):\n",
    "    for other_idx in range(name_idx, len(object_names)):\n",
    "        obj_sims[name_idx, other_idx] = obj_sims[other_idx, name_idx] = (objs[name] | objs[object_names[other_idx]]).item()\n",
    "\n",
    "plot_similarity_matrix(obj_sims, object_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "As you can see here, not only do the shapes and colors have no similarity, but the compound objects also have no similarity with either of their constituent elements - `green * square` is not similar to either `green` or `square.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Submit your feedback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_colorful_shapes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding Exercise 4: Foundations of Colorful Shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Video 4: Unbinding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Video 4: Unbinding\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', 'vHHX98jBvk8'), ('Bilibili', 'BV1gZ421g7XT')]\n",
    "tab_contents = display_videos(video_ids, W=730, H=410)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Submit your feedback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_unbinding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We can also undo the binding operation, which we call unbinding. It is implemented by binding with the pseudo-inverse of the vector we wish to unbind. We denote the pseudo-inverse of the vector using the ~ symbol.\n",
    "\n",
    "The SSPSpace library implements the pseudo-inverse for you, but the pseudo-inverse of a vector $\\mathbf{x} = (x_{0},\\ldots, x_{d-1})$ is defined:\n",
    "\n",
    "$$\\sim\\mathbf{x} = \\left(x_{0},x_{d-1},x_{d-2},\\ldots,x_{1}\\right)$$\n",
    "\n",
    "\n",
    "Consider the example of our red circle. If we want to recover the shape of the object, we will unbind from it the color:\n",
    "\n",
    "$$\n",
    "(\\mathtt{red} \\circledast \\mathtt{circle}) \\circledast \\sim \\mathtt{red} \\approx \\mathtt{circle}\n",
    "$$\n",
    "\n",
    "<details>\n",
    "<summary>Mathematical details</summary>\n",
    "\n",
    "By the definition of the pseudo-inverse and circular convolution, we have:\n",
    "\n",
    "$$\\mathbf{x} \\, \\circledast \\sim \\mathbf{x} = \n",
    "\\sum_{k=1}^{N} x_k x_{1 + (j + k - 2) \\mod N} \\approx \\delta_j$$\n",
    "\n",
    "where $\\delta_j$ is the Kronecker delta function. This is:\n",
    "\n",
    "* exactly equal to 1 when $j=1$. This is because the vectors in SSP have a norm of 1.\n",
    "* approximately 0 otherwise. This is because the vectors in SSP are random, and so a vector is approximately orthogonal to a shifted version of itself.\n",
    "\n",
    "The Kronecker delta is the identity function for the circular convolution, and circular convolutions commute, hence:\n",
    "\n",
    "$$\n",
    "(\\mathtt{a} \\circledast \\mathtt{b}) \\circledast \\sim \\mathtt{a} = \\mathtt{b} \\circledast (\\mathtt{a} \\circledast \\sim \\mathtt{a}) \\approx \\mathtt{b} \\circledast \\delta = \\mathtt{b}\n",
    "$$\n",
    "\n",
    "</details>\n",
    "\n",
    "In the cell below, unbind the color and shape, and then observe the similarity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "new_object_names = ['red','red^','red*circle','circle','circle^']\n",
    "new_objs = objs\n",
    "\n",
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete derivation of default objects using pseudoinverse.\")\n",
    "###################################################################\n",
    "\n",
    "new_objs['red^'] = new_objs['red*circle'] * ~new_objs['circle']\n",
    "new_objs['circle^'] = new_objs[...] * ~new_objs[...]\n",
    "\n",
    "new_obj_sims = np.zeros((len(new_object_names), len(new_object_names)))\n",
    "\n",
    "for name_idx, name in enumerate(new_object_names):\n",
    "    for other_idx in range(name_idx, len(new_object_names)):\n",
    "        new_obj_sims[name_idx, other_idx] = new_obj_sims[other_idx, name_idx] = (new_objs[name] | new_objs[new_object_names[other_idx]]).item()\n",
    "\n",
    "plot_similarity_matrix(new_obj_sims, new_object_names, values = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_NeuroSymbolicMethods/solutions/W2D2_Tutorial1_Solution_9bc21529.py)\n",
    "\n",
    "*Example output:*\n",
    "\n",
    "<img alt='Solution hint' align='left' width=660.0 height=577.0 src=https://raw.githubusercontent.com/neuromatch/NeuroAI_Course/main/tutorials/W2D2_NeuroSymbolicMethods/static/W2D2_Tutorial1_Solution_9bc21529_0.png>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Looking at the above graph, we can see that the compound red circle object is not similar to either of the elements, but the circle and the unbound circle are similar to one another, and the red and unbound red objects are similar to one another.\n",
    "\n",
    "With these elements together, we have constructed the basic tools we need to construct complex objects in vector symbolic algebra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Submit your feedback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_foundations_of_colorful_shapes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "\n",
    "# Section 4: Cleanup\n",
    "\n",
    "Estimated timing to here from start of tutorial: 30 minutes\n",
    "\n",
    "In this section we will address the issue of vectors being corrupted with noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Video 5: Cleanup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Video 5: Cleanup\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', 'eAdDocNOmSc'), ('Bilibili', 'BV1Jy411z7L6')]\n",
    "tab_contents = display_videos(video_ids, W=730, H=410)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Submit your feedback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_cleanup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding Exercise 5: Cleanup Memories To Find The Best-Fit\n",
    "\n",
    "In the process of computing with VSAs, the vectors themselves can become corrupted due to noise, because we implement these systems with spiking neurons, or due to approximations like using the pseudo-inverse for unbinding, or because noise gets added when we operate on complex structures.\n",
    "\n",
    "To address this problem, we employ \"cleanup memories.\"  These are lots of ways to implement these systems, but today, we're going to do it with a single hidden layer neural network.  Let's start with a sequence of symbols, say $\\texttt{fire-fighter},\\texttt{math-teacher},\\texttt{sales-manager},$ and so on, in that fashion, and create a new vector that is a corrupted combination of all three.  We will then use a cleanup memory to find the best-fitting vector in our vocabulary.\n",
    "\n",
    "In the cell below, you will see the definition of `noisy_vector`, your task is to complete the calculation of similarity values for this vector and all default ones.\n",
    "\n",
    "Here, we introduce another graphical way to represent the similarity: by putting a similarity value on the y-axis (instead of the box in the grid) and representing each of the objects by line (the x-axis stays the same, and similarity takes place between the corresponding label on the x-axis and line-object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete similarities calculation between noisy vector and given symbols.\")\n",
    "###################################################################\n",
    "set_seed(42)\n",
    "\n",
    "symbol_names = ['fire-fighter','math-teacher','sales-manager']\n",
    "discrete_space = sspspace.DiscreteSPSpace(symbol_names, ssp_dim=1024, optimize=False)\n",
    "\n",
    "vocab = {n:discrete_space.encode(n) for n in symbol_names}\n",
    "\n",
    "noisy_vector = 0.2 * vocab['fire-fighter'] + 0.15 * vocab['math-teacher'] + 0.3 * vocab['sales-manager']\n",
    "\n",
    "sims = np.array([noisy_vector | vocab[...] for name in ...]).squeeze()\n",
    "\n",
    "plot_line_similarity_matrix(sims, symbol_names, multiple_objects = False, title = 'Similarity - pre cleanup')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_NeuroSymbolicMethods/solutions/W2D2_Tutorial1_Solution_7024b3c7.py)\n",
    "\n",
    "*Example output:*\n",
    "\n",
    "<img alt='Solution hint' align='left' width=773.0 height=575.0 src=https://raw.githubusercontent.com/neuromatch/NeuroAI_Course/main/tutorials/W2D2_NeuroSymbolicMethods/static/W2D2_Tutorial1_Solution_7024b3c7_0.png>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Conceptually, with a discrete vocabulary, we can clean up a vector by finding the reference vector that's closest to the noisy vector and replacing it:\n",
    "\n",
    "$$\\text{cleanup}(\\boldsymbol{x}) = \\arg\\max_{\\boldsymbol{w} \\in \\text{vocab}} \\boldsymbol{x} \\cdot \\boldsymbol{w}$$\n",
    "\n",
    "Now, let's construct a simple one-hidden layer neural network that does cleanup using a soft version of this operation, replacing the max operation with a softmax. The input weights will be the vectors in the vocabulary, and we will place a softmax function on the hidden layer. The output weights will again be the vectors representing the symbols in the vocabulary.\n",
    "\n",
    "To snap the corrupted vectors back to the vocabulary, we'll apply this operation:\n",
    "\n",
    "$$\\text{cleanup}(\\boldsymbol{x}) = \\text{softmax}(T \\cdot \\boldsymbol{x} \\boldsymbol{W}^T) \\boldsymbol{W}$$\n",
    "\n",
    "Where $T$ is the temperature parameter, and $\\boldsymbol{W}$ is the matrix of vectors in the vocabulary. As $T \\to \\infty$, this operation converges to the original hard max cleanup operation. Your task is to complete the `__call__` function. Then, we calculate the similarity between the obtained vector and the ones in the vocabulary.\n",
    "\n",
    "Observe the result and compare it to the pre-cleanup metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete Cleanup class.\")\n",
    "###################################################################\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "class Cleanup:\n",
    "    def __init__(self, vocab, temperature=1e5):\n",
    "        self.weights = np.array([vocab[k] for k in vocab.keys()]).squeeze()\n",
    "        self.temp = temperature\n",
    "    def __call__(self, x):\n",
    "        ###################################################################\n",
    "        ## Fill out the following then remove\n",
    "        raise NotImplementedError(\"Student exercise: complete similarity calculation between input vector and weights of the network.\")\n",
    "        ###################################################################\n",
    "        sims = ...\n",
    "        max_sim = softmax(sims * self.temp, axis=1)\n",
    "        return sspspace.SSP(...) #sspspace.SSP() wrapper is necessary for further bitwise comparison, it doesn't change the result vector\n",
    "\n",
    "\n",
    "cleanup = Cleanup(vocab)\n",
    "\n",
    "clean_vector = cleanup(noisy_vector)\n",
    "\n",
    "clean_sims = np.array([clean_vector | vocab[name] for name in symbol_names]).squeeze()\n",
    "\n",
    "plot_double_line_similarity_matrix([sims, clean_sims], symbol_names, ['Noisy Similarity', 'Clean Similarity'], title = 'Similarity - post cleanup')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_NeuroSymbolicMethods/solutions/W2D2_Tutorial1_Solution_da811641.py)\n",
    "\n",
    "*Example output:*\n",
    "\n",
    "<img alt='Solution hint' align='left' width=773.0 height=575.0 src=https://raw.githubusercontent.com/neuromatch/NeuroAI_Course/main/tutorials/W2D2_NeuroSymbolicMethods/static/W2D2_Tutorial1_Solution_da811641_0.png>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "For the scenario where we have a discrete, known vocabulary, we can do this cleanup with a single feed-forward network, and we don't need to learn any of the synaptic weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Submit your feedback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_cleanup_memories_to_find_the_best_fit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Section 5: Iterated Binding\n",
    "\n",
    "Estimated timing to here from start of tutorial: 45 minutes\n",
    "\n",
    "In this section, we will represent numbers with iterated binding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Video 6: Iterated Binding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Video 6: Iterated Binding\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', 'jUUkxnVHGnY'), ('Bilibili', 'BV1Qs421u7jj')]\n",
    "tab_contents = display_videos(video_ids, W=730, H=410)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Submit your feedback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_iterated_binding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding Exercise 6: Representing Numbers\n",
    "\n",
    "It is often useful to be able to represent numbers. For example, we may want to represent the position of an object in a list, or we may want to represent the coordinates of an object in a grid. To do this, we use the binding operator to construct a vector that represents a number. We start by picking what we refer to as an \"axis vector,\" let's call it $\\texttt{one}$, and then iteratively apply binding like this:\n",
    "\n",
    "$$\n",
    "\\texttt{two} = \\texttt{one}\\circledast\\texttt{one} \n",
    "$$\n",
    "$$\n",
    "\\texttt{three} = \\texttt{two}\\circledast\\texttt{one} = \\texttt{one}\\circledast\\texttt{one}\\circledast\\texttt{one}\n",
    "$$\n",
    "\n",
    "and so on. We extend that to arbitrary integers, $n$, by writing:\n",
    "\n",
    "$$\n",
    "\\phi[n] = \\underset{i=1}{\\overset{n}{\\circledast}}\\texttt{one}\n",
    "$$\n",
    "\n",
    "Let's try that now and see how similarity between iteratively bound vectors develops. In the cell below, you should complete the missing part, which implements the iterative binding mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete iterated binding.\")\n",
    "###################################################################\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "#define axis vector\n",
    "axis_vectors = ['one']\n",
    "\n",
    "encoder = sspspace.DiscreteSPSpace(axis_vectors, ssp_dim=1024, optimize=False)\n",
    "\n",
    "#vocabulary\n",
    "vocab = {w:encoder.encode(w) for w in axis_vectors}\n",
    "\n",
    "#we will add new vectors to this list\n",
    "integers = [vocab['one']]\n",
    "\n",
    "max_int = 5\n",
    "for i in range(2, max_int + 1):\n",
    "    #bind one more \"one\" to the previous integer to get the new one\n",
    "    integers.append(integers[-1] * vocab[...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_NeuroSymbolicMethods/solutions/W2D2_Tutorial1_Solution_f0f796f7.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now, we will observe the similarity metric between the obtained vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "integers = np.array(integers).squeeze()\n",
    "integer_sims = integers @ integers.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "plot_similarity_matrix(integer_sims, [i for i in range(1, 6)], values = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Here, we will take a look at another graphical representation of the similarity through lines (the only difference with the previous section is the fact that here, we will have a couple of them, each representing a distinct concept)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "plot_line_similarity_matrix(integer_sims, range(1, 6), multiple_objects = True, labels = [f'$\\phi$[{idx+1}]' for idx in range(5)], title = \"Similarity for digits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "What we can see here is that each number acts like its own vector; they are highly dissimilar, but we can still do arithmetic with them. Let's see what happens when we unbind $\\texttt{two}$ from $\\texttt{five}$.\n",
    "\n",
    "In the cell below you are invited to complete the missing parts (be attentive! python is zero-indexed, thus you need to choose the correct indices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: unbinding of two from five.\")\n",
    "###################################################################\n",
    "\n",
    "five_unbind_two = sspspace.SSP(integers[...]) * ~sspspace.SSP(integers[...])\n",
    "five_unbind_two_sims = five_unbind_two @ integers.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_NeuroSymbolicMethods/solutions/W2D2_Tutorial1_Solution_04cf23a5.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "plot_line_similarity_matrix(five_unbind_two_sims, range(1, 6), multiple_objects = False,  title = '$(\\phi[5]\\circledast \\phi[2]^{-1}) \\cdot \\phi[n]$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We get what we expected - when we removed $\\texttt{two}$ from $\\texttt{five}$ we get a vector that is similar to $\\texttt{three}$.  We can do arithmetic with our vector encoding!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Submit your feedback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_representing_numbers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding Exercise 7: Beyond Binding Integers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Video 7: Fractional Binding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Video 7: Fractional Binding\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', 'mTIodqegq_4'), ('Bilibili', 'BV1b4421Q7mS')]\n",
    "tab_contents = display_videos(video_ids, W=730, H=410)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Submit your feedback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_fractional_binding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "This is all well and good, but sometimes, we want to encode values that are not integers. Is there an easy way to do this? You'll be surprised to learn that the answer is: yes.\n",
    "\n",
    "We actually use the same technique, but we recognize that iterated binding can be implemented in the Fourier domain:\n",
    "\n",
    "$$\n",
    "\\phi[n] = \\mathcal{F}^{-1}\\left\\{\\mathcal{F}\\left\\{\\texttt{one}\\right\\}^{n}\\right\\}\n",
    "$$\n",
    "\n",
    "where the power of $n$ in the Fourier domain is applied element-wise to the vector. To encode real-valued data, we simply let the integer value, $n$, be a real-valued vector, $x$, and we let the axis vector be a randomly generated vector, $X$. \n",
    "\n",
    "$$\n",
    "\\phi(x) = \\mathcal{F}^{-1}\\left\\{\\mathcal{F}\\left\\{X\\right\\}^{x}\\right\\}\n",
    "$$\n",
    "\n",
    "We call vectors that represent real-valued data Spatial Semantic Pointers (SSPs). We can also extend this to multi-dimensional data by binding different SSPs together.\n",
    "\n",
    "$$\n",
    "\\phi(x,y) = \\phi_{X}(x) \\circledast \\phi_{Y}(y)\n",
    "$$\n",
    "\n",
    "\n",
    "In the $\\texttt{sspspace}$ library, we provide an encoder for real- and integer-valued data, and we'll demonstrate it next by encoding a bunch of points in the range $[-4,4]$ and comparing their value to $0$, encoded with SSP.\n",
    "\n",
    "In the cell below, you should complete the similarity calculation by injecting the correct index for the $0$ element (observe that it is right in the middle of the encoded array)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete similarity calculation: correct index for `0` and array.\")\n",
    "###################################################################\n",
    "\n",
    "set_seed(42)\n",
    "new_encoder = sspspace.RandomSSPSpace(domain_dim=1, ssp_dim=1024)\n",
    "\n",
    "xs = np.linspace(-4,4,401)[:,None] #we expect the encoded values to be two-dimensional in `encoder.encode()` so we add extra dimension\n",
    "phis = new_encoder.encode(xs)\n",
    "\n",
    "#`0` element is right in the middle of phis array! notice that we have 401 samples inside it\n",
    "real_line_sims = phis[..., :] @ phis.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_NeuroSymbolicMethods/solutions/W2D2_Tutorial1_Solution_f5f2174f.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "plot_real_valued_line_similarity(real_line_sims, xs, title = '$\\phi(x)\\cdot\\phi(0)$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "As with the integers, we can update the values post-encoding through the binding operation.  Let's look at the similarity between all the points in the range $[-4,4]$, this time with the value $\\pi/2$, but we will shift it by binding the origin with the desired shift value.\n",
    "\n",
    "In the cell below, you need to provide the value for which we are going to shift the origin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: provide value to shift and observe the usage of the operation.\")\n",
    "###################################################################\n",
    "\n",
    "phi_shifted = phis[200,:][None,:] * new_encoder.encode([[...]])\n",
    "shifted_real_line_sims = phi_shifted.flatten() @ phis.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_NeuroSymbolicMethods/solutions/W2D2_Tutorial1_Solution_d25db2a0.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "plot_real_valued_line_similarity(shifted_real_line_sims, xs, title = '$\\phi(x)\\cdot(\\phi(0)\\circledast\\phi(\\pi/2))$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We can then take that vector and shift it again to a new location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "new_phi_shifted = phis[200,:][None,:] * new_encoder.encode([[-1.5*np.pi]])\n",
    "new_shifted_real_line_sims = new_phi_shifted.flatten() @ phis.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "plot_real_valued_line_similarity(new_shifted_real_line_sims, xs, title = '$\\phi(x)\\cdot(\\phi(0)\\circledast\\phi(-1.5\\pi))$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We will go on to use these encodings to build spatial maps in Tutorial 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Coding Exercise 7 Discussion\n",
    "\n",
    "1. How would you explain the lines `sims = vector @ phis.T` in the previous coding exercises?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_NeuroSymbolicMethods/solutions/W2D2_Tutorial1_Solution_87190668.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Submit your feedback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_beyond_bidning_integers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Video 8: Iterated Binding Conclusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Video 8: Iterated Binding Conclusion\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', 'zXYODzMw_Vc'), ('Bilibili', 'BV1Wm421L7ax')]\n",
    "tab_contents = display_videos(video_ids, W=730, H=410)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Submit your feedback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_iterated_binding_conclusion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Summary\n",
    "\n",
    "*Estimated timing of tutorial: 1 hour*\n",
    "\n",
    "In this tutorial, we developed the toolbox of the main operations on the vector symbolic algebra. In particular, it includes:\n",
    "- similarity operation (|), which measures how similar the two vectors are (by calculating their dot product);\n",
    "- bundling (+), which creates new set-like objects using vector addition;\n",
    "- binding ($\\circledast$), which creates a new combined representation of the two given objects using circular convolution;\n",
    "- unbinding (~), which allows to derive a pure object from the bound representation by unbinding another one that stands in the pair;\n",
    "- cleanup, which tries to identify the most similar vector in the vocabulary with multiple possible implementations.\n",
    "- iterated binding, which allows one to \"count\" by iteratively binding an axis vector with itself.\n",
    "- encoding real-valued data using fractional binding.\n",
    "\n",
    "In the following tutorials, we will take a look at how we can use these tools to create more complicated structures and derive useful information from them."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "W2D2_Tutorial1",
   "provenance": [],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}