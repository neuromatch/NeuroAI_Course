{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {},
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/neuromatch/course-content-template/blob/main/tutorials/W1D2_Template/student/W1D2_Tutorial1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> &nbsp; <a href=\"https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/neuromatch/course-content-template/main/tutorials/W1D2_Template/student/W1D2_Tutorial1.ipynb\" target=\"_parent\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open in Kaggle\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Tutorial 1: Cognitive Structures\n",
    "\n",
    "**Week 2, Day 2: Cognitive Structures**\n",
    "\n",
    "**By Neuromatch Academy**\n",
    "\n",
    "__Content creators:__ Michael Furlong\n",
    "\n",
    "__Content reviewers:__ Hlib Solodzhuk\n",
    "\n",
    "__Production editors:__ Names & Surnames\n",
    "\n",
    "<br>\n",
    "\n",
    "Acknowledgments: [ACKNOWLEDGMENT_INFORMATION]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "___\n",
    "\n",
    "\n",
    "# Tutorial Objectives\n",
    "\n",
    "*Estimated timing of tutorial: 2 hours 40 minutes*\n",
    "\n",
    "Here we will write about tutorial objectives in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Tutorial slides\n",
    "# @markdown These are the slides for the videos in all tutorials today\n",
    "\n",
    "# from IPython.display import IFrame\n",
    "#link_id = \"<YOUR_LINK_ID_HERE>\"\n",
    "# print(f\"If you want to download the slides: https://osf.io/download/{link_id}/\")\n",
    "#IFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{link_id}/?direct%26mode=render\", width=854, height=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Install and import feedback gadget\n",
    "\n",
    "# !pip3 install vibecheck datatops --quiet\n",
    "\n",
    "# from vibecheck import DatatopsContentReviewContainer\n",
    "# def content_review(notebook_section: str):\n",
    "#     return DatatopsContentReviewContainer(\n",
    "#         \"\",  # No text prompt - leave this as is\n",
    "#         notebook_section,\n",
    "#         {\n",
    "#             \"url\": \"https://pmyvdlilci.execute-api.us-east-1.amazonaws.com/klab\",\n",
    "#             \"name\": \"sciencematch_sm\", # change the name of the course : neuromatch_dl, climatematch_ct, etc\n",
    "#             \"user_key\": \"y1x3mpx5\",\n",
    "#         },\n",
    "#     ).render()\n",
    "\n",
    "# feedback_prefix = \"W2D2_T1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Install dependencies\n",
    "# @markdown\n",
    "\n",
    "# Install sspspace\n",
    "# !pip install git+https://github.com/ctn-waterloo/sspspace@neuromatch --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "#working with data\n",
    "import numpy as np\n",
    "\n",
    "#plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "#interactive display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "#modeling\n",
    "import sspspace\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Figure settings\n",
    "\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' # perfrom high definition rendering for images and plots\n",
    "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/nma.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Plotting functions\n",
    "\n",
    "def plot_vectors(concepts, labels, shape = (32, 32)):\n",
    "    \"\"\"\n",
    "    Plot vector symbols associated with the given concepts.\n",
    "\n",
    "    Inputs:\n",
    "    - concepts (list of sspspace.ssp.SSP): list of concepts which contain associated vectors.\n",
    "    - labels (list of str): list of strings which represent concepts.\n",
    "    - shape (tuple, default = (32, 32)): desired image shape.\n",
    "    \"\"\"\n",
    "    with plt.xkcd():\n",
    "        n = len(concepts)\n",
    "        for i in range(len(concepts)):\n",
    "            plt.subplot(1,n,i+1)\n",
    "            plt.imshow(concepts[i].view(dtype=float,type=np.ndarray).reshape(shape), cmap='Greys')\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.title(labels[i])\n",
    "\n",
    "def plot_similarity_matrix(sim_mat, labels, values = False):\n",
    "    \"\"\"\n",
    "    Plot the similarity matrix between vectors.\n",
    "\n",
    "    Inputs:\n",
    "    - sim_mat (numpy.ndarray): similarity matrix between vectors.\n",
    "    - labels (list of str): list of strings which represent concepts.\n",
    "    - values (bool): True if we would like to plot values of similarity too.\n",
    "    \"\"\"\n",
    "    with plt.xkcd():\n",
    "        plt.imshow(sim_mat, cmap='Greys')\n",
    "        plt.colorbar()\n",
    "        plt.xticks(np.arange(len(labels)), labels, rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "        plt.yticks(np.arange(len(labels)), labels)\n",
    "        if values:\n",
    "            for x in range(sim_mat.shape[1]):\n",
    "                for y in range(sim_mat.shape[0]):\n",
    "                    plt.text(x, y, f\"{sim_mat[y, x]:.2f}\", fontsize = 8, ha=\"center\", va=\"center\", color=\"green\")\n",
    "        plt.title('Similarity between vector-symbols')\n",
    "        plt.xlabel('Symbols')\n",
    "        plt.ylabel('Symbols')\n",
    "        plt.show()\n",
    "\n",
    "def plot_line_similarity_matrix(sim_mat, xaxis_ticks, multiple_objects = True, labels = None, title = \"Awesome title!\"):\n",
    "    \"\"\"\n",
    "    Plot similarirty matrix (or vector if multiple_objects is False) as lines.\n",
    "\n",
    "    Inputs:\n",
    "    - sim_mat (numpy.ndarray): similarity matrix between vectors.\n",
    "    - xaxis_ticks (list): list of ticks to put in x-axis.\n",
    "    - multiple_objects (bool, default = True): True if there are a couple of objects to plot similarity.\n",
    "    - labels (list, default = None): labels to plot.\n",
    "    - title (str): title of the plot.\n",
    "    \"\"\"\n",
    "    with plt.xkcd():\n",
    "        if multiple_objects:\n",
    "            for idx, integer_sims in enumerate(sim_mat):\n",
    "                if labels:\n",
    "                    plt.plot(xaxis_ticks, integer_sims.flatten(), label=f'$\\phi$[{idx+1}]', marker='o', ls='--')\n",
    "                else:\n",
    "                    plt.plot(xaxis_ticks, integer_sims.flatten(), marker='o', ls='--')\n",
    "        else:\n",
    "            plt.plot(xaxis_ticks,sim_mat.flatten(), ls='--',marker='o')\n",
    "\n",
    "    plt.ylabel('Similarity')\n",
    "    plt.xlabel('n')\n",
    "    plt.xticks(xaxis_ticks)\n",
    "    if labels:\n",
    "        plt.legend(loc='upper right')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def plot_double_line_similarity_matrix(sim_mat, xaxis_ticks, labels, title):\n",
    "    \"\"\"\n",
    "    Plot similarirty matrix (or vector if multiple_objects is False) as lines for two different matrices.\n",
    "\n",
    "    Inputs:\n",
    "    - sim_mat (numpy.ndarray): list of similarity matrix between vectors.\n",
    "    - xaxis_ticks (list): list of ticks to put in x-axis.\n",
    "    - multiple_objects (bool, default = True): True if there are a couple of objects to plot similarity.\n",
    "    - labels (list): labels to plot.\n",
    "    - title (str): title of the plot.\n",
    "    \"\"\"\n",
    "    with plt.xkcd():\n",
    "        plt.plot(xaxis_ticks,sim_mat[0].flatten(), ls='--',marker='o', label = labels[0])\n",
    "        plt.plot(xaxis_ticks,sim_mat[1].flatten(), ls='--',marker='o', label = labels[1])\n",
    "    plt.ylabel('Similarity')\n",
    "    plt.xlabel('n')\n",
    "    plt.xticks(xaxis_ticks)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def plot_real_valued_line_similarity(sim_mat, x_range, title):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - sim_mat (numpy.ndarray): similarity matrix between vectors.\n",
    "    - x_range (numpy.ndarray): x-axis range.\n",
    "    - title (str): title of the plot.\n",
    "    \"\"\"\n",
    "    with plt.xkcd():\n",
    "        plt.plot(x_range, sims)\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('Similarity')\n",
    "    plt.title(title)\n",
    "\n",
    "def plot_3d_function(X, Y, zs, titles):\n",
    "    \"\"\"Plot 3D function.\n",
    "\n",
    "    Inputs:\n",
    "    - X (list): list of np.ndarray of x-values.\n",
    "    - Y (list): list of np.ndarray of y-values.\n",
    "    - zs (list): list of np.ndarray of z-values.\n",
    "    - titles (list): list of titles of the plot.\n",
    "    \"\"\"\n",
    "    with plt.xkcd():\n",
    "        fig = plt.figure(figsize=(10,10))\n",
    "        for index, (x, y, z) in enumerate(zip(X, Y, zs)):\n",
    "            fig.add_subplot(1, len(X), index + 1, projection='3d')\n",
    "            plt.gca().plot_surface(x,y,z.reshape(x.shape),cmap='plasma', antialiased=False, linewidth=0)\n",
    "            plt.xlabel(r'$x_{1}$')\n",
    "            plt.ylabel(r'$x_{2}$')\n",
    "            plt.gca().set_zlabel(r'$f(\\mathbf{x})$')\n",
    "            plt.title(titles[index])\n",
    "        plt.show()\n",
    "\n",
    "def plot_performance(bound_performance, bundle_performance, test_sizes, title):\n",
    "    \"\"\"Plot RMSE values for two different representations of the input data.\n",
    "\n",
    "    Inputs:\n",
    "    - bound_performance (list): list of RMSE for bound representation.\n",
    "    - bundle_performance (list): list of RMSE for bundle representation.\n",
    "    - test_sizes (list): x-axis.\n",
    "    - title (str): title of the plot.\n",
    "    \"\"\"\n",
    "    with plt.xkcd():\n",
    "        plt.plot(test_sizes, bound_performance, label='Bound Representation')\n",
    "        plt.plot(test_sizes, bundle_performance, label='Bundling Representation', ls='--')\n",
    "        plt.legend()\n",
    "        plt.title(title)\n",
    "        plt.ylabel('RMSE (a.u.)')\n",
    "        plt.xlabel('Test Set Fraction')\n",
    "        plt.show()\n",
    "\n",
    "def plot_2d_similarity(sims, obj_names, size, title_argmax = False):\n",
    "    \"\"\"\n",
    "    Plot 2D similarity between query points (grid) and the ones associated with the objects.\n",
    "\n",
    "    Inputs:\n",
    "    - sims (list): list of similarity values for each of the objects.\n",
    "    - obj_names (list): list of object names.\n",
    "    - size (tuple): to reshape the similarities.\n",
    "    - title_argmax (bool, default = False): looks for the point coordinates as arg max from all similarity value.\n",
    "    \"\"\"\n",
    "    ticks = [0,24,49,74,99]\n",
    "    ticklabels = [-5,-2,0,2,5]\n",
    "    with plt.xkcd():\n",
    "        for obj_idx, obj in enumerate(obj_names):\n",
    "            plt.subplot(1,len(obj_names), 1+obj_idx)\n",
    "            plt.imshow(sims[obj_idx].reshape(size), origin='lower', vmin=-1, vmax=1)\n",
    "            plt.gca().set_xticks(ticks)\n",
    "            plt.gca().set_xticklabels(ticklabels)\n",
    "            if obj_idx == 0:\n",
    "                plt.gca().set_yticks(ticks)\n",
    "                plt.gca().set_yticklabels(ticklabels)\n",
    "            else:\n",
    "                plt.gca().set_yticks([])\n",
    "            if not title_argmax:\n",
    "                plt.title(f'{obj}, {positions[obj_idx]}')\n",
    "            else:\n",
    "                plt.title(f'{obj}, {query_xs[sims[obj_idx].argmax()]}')\n",
    "        plt.show()\n",
    "\n",
    "def plot_unbinding_objects_map(sims, positions, query_xs, size):\n",
    "    \"\"\"\n",
    "    Plot 2D similarity between query points (grid) and the unbinded from the objects map.\n",
    "\n",
    "    Inputs:\n",
    "    - sims (np.ndarray): similarity values for each of the query points with the map.\n",
    "    - positions (np.ndarray): positions of the objects.\n",
    "    - query_xs (np.ndarray): grid points.\n",
    "    - size (tuple): to reshape the similarities.\n",
    "\n",
    "    \"\"\"\n",
    "    ticks = [0,24,49,74,99]\n",
    "    ticklabels = [-5,-2,0,2,5]\n",
    "    with plt.xkcd():\n",
    "        plt.imshow(sims.reshape(size), origin='lower')\n",
    "\n",
    "        for idx, marker in enumerate(['o','s','^']):\n",
    "            plt.scatter(*get_coordinate(positions[idx,:], query_xs, size), marker=marker,s=100)\n",
    "\n",
    "        plt.gca().set_xticks(ticks)\n",
    "        plt.gca().set_xticklabels(ticklabels)\n",
    "        plt.gca().set_yticks(ticks)\n",
    "        plt.gca().set_yticklabels(ticklabels)\n",
    "        plt.title(f'All Object Locations')\n",
    "        plt.show()\n",
    "\n",
    "def plot_unbinding_positions_map(sims, positions, obj_names):\n",
    "    \"\"\"\n",
    "    Plot 2D similarity between query points (grid) and the unbinded from the positions map.\n",
    "\n",
    "    Inputs:\n",
    "    - sims (np.ndarray): similarity values for each of the query points with the map.\n",
    "    - positions (np.ndarray): test positions to query.\n",
    "    - obj_names (list): names of the objects for labels.\n",
    "    - size (tuple): to reshape the similarities.\n",
    "    \"\"\"\n",
    "    with plt.xkcd():\n",
    "        plt.figure(figsize=(25,5))\n",
    "        for pos_idx, pos in enumerate(positions):\n",
    "            plt.subplot(1,len(test_positions), 1+pos_idx)\n",
    "            plt.bar([1,2,3], sims[pos_idx])\n",
    "            plt.ylim([-0.3,1.05])\n",
    "            plt.gca().set_xticks([1,2,3])\n",
    "            plt.gca().set_xticklabels(obj_names, rotation=90)\n",
    "            if pos_idx != 0:\n",
    "                plt.gca().set_yticks([])\n",
    "            plt.title(f'Symbols at {pos}')\n",
    "        plt.show()\n",
    "\n",
    "def plot_training_and_choice(losses, sims, ant_names, cons_names, action_names):\n",
    "    \"\"\"\n",
    "    Plot loss progression over training as well as predicted similarities for given rules / correct solutions.\n",
    "\n",
    "    Inputs:\n",
    "    - losses (list): list of loss values.\n",
    "    - sims (list): list of similartiy matrices.\n",
    "    - ant_names (list): list of antecedance names.\n",
    "    - cons_names (list): list of consequent names.\n",
    "    - action_names (list): full list of concepts.\n",
    "    \"\"\"\n",
    "    with plt.xkcd():\n",
    "        plt.subplot(1, len(ant_names) + 1, 1)\n",
    "        plt.plot(losses)\n",
    "        plt.xlabel('Training number')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training Error')\n",
    "        index = 1\n",
    "        for ant_name, cons_name, sim in zip(ant_names, cons_names, sims):\n",
    "            index += 1\n",
    "            plt.subplot(1, len(ant_names) + 1, index)\n",
    "            plt.bar(range(len(action_names)), sim.flatten())\n",
    "            plt.gca().set_xticks(range(len(action_names)))\n",
    "            plt.gca().set_xticklabels(action_names, rotation=90)\n",
    "            plt.title(f'{ant_name}, not*{cons_name}')\n",
    "\n",
    "def plot_choice(sims, ant_names, cons_names, action_names):\n",
    "    \"\"\"\n",
    "    Plot predicted similarities for given rules / correct solutions.\n",
    "    \"\"\"\n",
    "    with plt.xkcd():\n",
    "        index = 0\n",
    "        for ant_name, cons_name, sim in zip(ant_names, cons_names, sims):\n",
    "            index += 1\n",
    "            plt.subplot(1, len(ant_names) + 1, index)\n",
    "            plt.bar(range(len(action_names)), sim.flatten())\n",
    "            plt.gca().set_xticks(range(len(action_names)))\n",
    "            plt.gca().set_xticklabels(action_names, rotation=90)\n",
    "            plt.ylabel(\"Similarity\")\n",
    "            plt.title(f'{ant_name}, not*{cons_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Helper functions\n",
    "\n",
    "def get_model(xs, ys, test_size):\n",
    "    \"\"\"Fit linear regression to the given data.\n",
    "\n",
    "    Inputs:\n",
    "    - xs (np.ndarray): input data.\n",
    "    - ys (np.ndarray): outpu data.\n",
    "    - test_size (float): fraction of data to use for test.\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(xs, ys, random_state=1, test_size=test_size)\n",
    "    return LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "def get_coordinate(x, positions, target_shape):\n",
    "    \"\"\"Return the closest column and row coordinates for the given position.\n",
    "\n",
    "    Inputs:\n",
    "    - x (np.ndarray): query position.\n",
    "    - positions (np.ndarray): all positions.\n",
    "    - target_shape (tuple): shape of the grid.\n",
    "\n",
    "    Outputs:\n",
    "    - coordinates (tuple): column and row positions.\n",
    "    \"\"\"\n",
    "    idx = np.argmin(np.linalg.norm(x - positions, axis=1))\n",
    "    c = idx % target_shape[1]\n",
    "    r = idx // target_shape[1]\n",
    "    return (c,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Set random seed\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def set_seed(seed=None):\n",
    "  if seed is None:\n",
    "    seed = np.random.choice(2 ** 32)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "\n",
    "set_seed(seed = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "\n",
    "# Section 1: High-dimensional vector symbols\n",
    "\n",
    "In this section we are going to start our journey by representing concepts as high-dimensional vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 1: Similarity\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "# video_ids = [('Youtube', '<video_id_1>'), ('Bilibili', '<video_id_2>'), ('Osf', '<video_id_3>')]\n",
    "# tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "# tabs = widgets.Tab()\n",
    "# tabs.children = tab_contents\n",
    "# for i in range(len(tab_contents)):\n",
    "#   tabs.set_title(i, video_ids[i][0])\n",
    "# display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_high_dimensional_vector_symbols\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding Exercise 1: Geometric Concepts as High-Dimensional Vectors\n",
    "\n",
    "In an arbitrary space of concepts we will represent the ideas of 'circle', 'square', and triangle'. For that, we will use the SSP space library (`sspspace`) to map identifiers for the concepts (strings of their names in thise case) into high-dimensional vectors of unit length. It means that for each `name` we will have unique identification of $\\mathbf{v}$ where $||\\mathbf{v}|| = 1$.\n",
    "\n",
    "In this exercise, check that, indeed, vectors are of unit length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete check that norms of the vector representations are of unit lengths.\")\n",
    "###################################################################\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "vector_length = 1024\n",
    "symbol_names = ['circle','square','triangle']\n",
    "discrete_space = sspspace.DiscreteSPSpace(symbol_names, ssp_dim=vector_length, optimize = False)\n",
    "\n",
    "circle = discrete_space.encode('circle')\n",
    "square = discrete_space.encode('square')\n",
    "triangle = discrete_space.encode('triangle')\n",
    "\n",
    "print('|circle| =', np.linalg.norm(...))\n",
    "print('|triangle| =', ...)\n",
    "print('|square| =', ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_CognitiveStructures/solutions/W2D2_Tutorial1_Solution_a86d03c8.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We can visualize the assigned vectors as 32x32 images (notice, that dimension is 1024, it is exactly 32 multiplied by 32)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "plot_vectors([circle, square, triangle], symbol_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "As vectors are assigned randomly, no wonder that images do not display the assigned figure:) \n",
    "\n",
    "One of the extremely useful properties of random high-dimensional vectors is that they are approximately orthogonal.\n",
    "\n",
    "This is an important aspect of VSAs, we will use the vector dot product to measure similarity between them. For discrete objects, they are either the same, or not, and given how we select the vectors, if they are the same they will have the dot product of 1, and if they are different concepts, they will have a dot product of (approximately) 0. \n",
    "\n",
    "Below we use the | operator to indicate similarity. This is borrowed from the bra-ket notation in physics, i.e.,\n",
    "\n",
    "$$\n",
    "\\mathbf{a}\\cdot\\mathbf{b} = \\langle \\mathbf{a} \\mid \\mathbf{b}\\rangle\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "sim_mat = np.zeros((3,3))\n",
    "\n",
    "sim_mat[0,0] = (circle | circle).item()\n",
    "sim_mat[1,1] = (square | square).item()\n",
    "sim_mat[2,2] = (triangle | triangle).item()\n",
    "\n",
    "sim_mat[0,1] = sim_mat[1,0] = (circle | square).item()\n",
    "sim_mat[0,2] = sim_mat[2,0] = (circle | triangle).item()\n",
    "sim_mat[1,2] = sim_mat[2,1] = (square | triangle).item()\n",
    "\n",
    "plot_similarity_matrix(sim_mat, symbol_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "As you can see from the above figure, the three randomly selected vectors are approximately orthogonal. This will be important later when we go to make more complicated objects from our vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_geometric_concepts_high_dimensional_vectors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Coding Exercise 1 Discussion\n",
    "\n",
    "1. How would you provide intuitive reasoning (or rigorous mathematical proof) behind the fact that random high-dimensional vectors (note that each of the components is drawn from uniform distribution with zero mean) approximately orthogonal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_CognitiveStructures/solutions/W2D2_Tutorial1_Solution_3e9c4916.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_geometric_concepts_high_dimensional_vectors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "\n",
    "# Section 2: Bundling\n",
    "\n",
    "Estimated timing to here from start of tutorial: 15 minutes\n",
    "\n",
    "In this section we are going to explore bundling operation which allows us to construct vectors that represent something like sets. Basically, we combine two vectors into a new one that retains similarity to the previous two. We implement bundling using vector addition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 2: Bundling\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "# video_ids = [('Youtube', '<video_id_1>'), ('Bilibili', '<video_id_2>'), ('Osf', '<video_id_3>')]\n",
    "# tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "# tabs = widgets.Tab()\n",
    "# tabs.children = tab_contents\n",
    "# for i in range(len(tab_contents)):\n",
    "#   tabs.set_title(i, video_ids[i][0])\n",
    "# display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_bundling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding Exercise 2: Shape In-Between\n",
    "\n",
    "Let's start with our previous example of different shapes (circle, square, and triangle) and use them to create a new object 'shape', which will represent all atomic concepts we've introduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "shape = (circle + square + triangle).normalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Notice that we need to normalize the obtained vector. Now, let us calculate similarity matrix for the three default concepts and the new one.\n",
    "\n",
    "In the exercise below, complete similarity matrix calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete calcualtion of similarity matrix.\")\n",
    "###################################################################\n",
    "\n",
    "sim_mat = np.zeros((4,4))\n",
    "\n",
    "sim_mat[0,0] = (... | circle).item()\n",
    "sim_mat[1,1] = (square | ...).item()\n",
    "sim_mat[2,2] = (triangle | ...).item()\n",
    "sim_mat[3,3] = (... | ...).item()\n",
    "\n",
    "sim_mat[0,1] = sim_mat[1,0] = (circle | square).item()\n",
    "sim_mat[0,2] = sim_mat[2,0] = (circle | ...).item()\n",
    "sim_mat[0,3] = sim_mat[3,0] = (... | shape).item()\n",
    "\n",
    "sim_mat[1,2] = sim_mat[2,1] = (square | triangle).item()\n",
    "sim_mat[1,3] = sim_mat[3,1] = (square | ...).item()\n",
    "\n",
    "sim_mat[2,3] = sim_mat[3,2] = (triangle | shape).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_CognitiveStructures/solutions/W2D2_Tutorial1_Solution_8d8fa911.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "plot_similarity_matrix(sim_mat, symbol_names + [\"shape\"], values = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Observe that as each of the default concepts were introduced equally in the definition of the shape, it shares the same similarity between all of them pairwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Coding Exercise 2 Discussion\n",
    "\n",
    "1. Why do we need to normalize the vector obtained in the result of bundling operation? What length do you expect to receive without normalization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_CognitiveStructures/solutions/W2D2_Tutorial1_Solution_5c62f306.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_shape_in_between\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "\n",
    "# Section 3: Binding & Unbinding\n",
    "\n",
    "Estimated timing to here from start of tutorial: 25 minutes\n",
    "\n",
    "In this section we will talk about binding - an operation that takes two vectors and produces a new vector that is *not* similar to either of it's constituent elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 3: Binding & Unbinding\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "# video_ids = [('Youtube', '<video_id_1>'), ('Bilibili', '<video_id_2>'), ('Osf', '<video_id_3>')]\n",
    "# tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "# tabs = widgets.Tab()\n",
    "# tabs.children = tab_contents\n",
    "# for i in range(len(tab_contents)):\n",
    "#   tabs.set_title(i, video_ids[i][0])\n",
    "# display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_bunding_and_unbinding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding Exercise 3: Colorful Shapes\n",
    "\n",
    "We can think of binding as an \"and\"-like operation. It needs both of the arguments to be the same to produce a similar vector. In this example, let's think about colors and shapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "symbol_names = ['circle','square','triangle', 'red', 'blue', 'green']\n",
    "discrete_space = sspspace.DiscreteSPSpace(symbol_names, ssp_dim=vector_length, optimize=False)\n",
    "\n",
    "objs = {n:discrete_space.encode(np.array([n])) for n in symbol_names}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now we are going to take two of the objects to make new ones: a red circle, a blue triangle and a green square.\n",
    "\n",
    "We will combine the two primitive objects using the binding operation, which for us is implemented using circular convolution, and we denote it by \n",
    "$$\n",
    " a * b\n",
    "$$\n",
    "\n",
    "In the cell below, complete the missing concepts and then observe the computed similarity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete derivation of new objects using binding operation.\")\n",
    "###################################################################\n",
    "\n",
    "objs['red*circle'] = objs['red'] * ...\n",
    "objs['blue*triangle'] = ... * objs['triangle']\n",
    "objs['green*square'] = ... * objs['square']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_CognitiveStructures/solutions/W2D2_Tutorial1_Solution_f9fa3af1.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "object_names = list(objs.keys())\n",
    "sims = np.zeros((len(object_names), len(object_names)))\n",
    "\n",
    "for name_idx, name in enumerate(object_names):\n",
    "    for other_idx in range(name_idx, len(object_names)):\n",
    "        sims[name_idx, other_idx] = sims[other_idx, name_idx] = (objs[name] | objs[object_names[other_idx]]).item()\n",
    "\n",
    "plot_similarity_matrix(sims, object_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "As you can see here, not only to the shapes and colours have no similarity, but the compound objects also have no similarity with either of their constituent elements - `green * square` is not similar to either `green` or `square`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_colorful_shapes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding Exercise 4: Foundations of Colorful Shapes\n",
    "\n",
    "We can also undo the binding operation, which we call unbinding. It is implemented by binding with the pseduo-inverse of the vector we wish to unbind. We denote the pseudoinverse of the vector using the ~ symbol.\n",
    "\n",
    "\n",
    "Consider the example of our red circle. If we wanted to recover the shape of the object, we will unbind from it the color:\n",
    "\n",
    "$$\n",
    "(\\mathtt{red} * \\mathtt{circle}) * \\sim \\mathtt{red} \\approx \\mathtt{circle}\n",
    "$$\n",
    "\n",
    "In the cell below unbind color and shape, and then observe the similarity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "object_names = ['red','red^','red*circle','circle','circle^']\n",
    "\n",
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete derivation of default objects using pseudoinverse.\")\n",
    "###################################################################\n",
    "\n",
    "objs['red^'] = objs[...] * ~objs['circle']\n",
    "objs['circle^'] = objs[...] * ~objs[...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_CognitiveStructures/solutions/W2D2_Tutorial1_Solution_685af726.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "sims = np.zeros((len(object_names), len(object_names)))\n",
    "\n",
    "for name_idx, name in enumerate(object_names):\n",
    "    for other_idx in range(name_idx, len(object_names)):\n",
    "        sims[name_idx, other_idx] = sims[other_idx, name_idx] = (objs[name] | objs[object_names[other_idx]]).item()\n",
    "\n",
    "plot_similarity_matrix(sims, object_names, values = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Looking at the above graph, we can see that the compound red circle object is not similar to either of the elements, but the circle and the unbound circle are similar to one another, and the red and unbound red object are similar to one another.\n",
    "\n",
    "With these elements together, we have constructed the basic tools we need to construct complex objects in the vector symbolic algebra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "\n",
    "# Section 4: Cleanup\n",
    "\n",
    "Estimated timing to here from start of tutorial: 40 minutes\n",
    "\n",
    "In this section we will address the issue of vectors being corrupted with noise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 4: Cleanup\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "# video_ids = [('Youtube', '<video_id_1>'), ('Bilibili', '<video_id_2>'), ('Osf', '<video_id_3>')]\n",
    "# tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "# tabs = widgets.Tab()\n",
    "# tabs.children = tab_contents\n",
    "# for i in range(len(tab_contents)):\n",
    "#   tabs.set_title(i, video_ids[i][0])\n",
    "# display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_cleanup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding Exercise 5: Cleanup Memories To Find The Best-Fit\n",
    "\n",
    "In the process of computing with VSAs, the vectors themselves can become corrupted, due to noises (because we implement these systems with spiking neurons), or due to the approximations like using the pseudo inverse for unbinding, or because noise gets added when we operate on complex structures.\n",
    "\n",
    "To address this problem we employ \"cleanup memories\".  There are lots of ways to implement these systems, but today we're going to do it with a single hidden layer neural network.  Lets start with a sequence of symbols, say $\\texttt{fire-fighter},\\texttt{math-teacher},\\texttt{sales-manager},$ and so on, in that fashion, and create a new vector that is a corrupted combination of all three.  We will then use a clean up memory to find the best fitting vector in our vocabulary.\n",
    "\n",
    "In the cell below you will see the definition of `noisy_vector`, your task is to complete the calculation of similarity values for this vector and all default ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "symbol_names = ['fire-fighter','math-teacher','sales-manager']\n",
    "discrete_space = sspspace.DiscreteSPSpace(symbol_names, ssp_dim=1024, optimize=False)\n",
    "\n",
    "vocab = {n:discrete_space.encode(n) for n in symbol_names}\n",
    "\n",
    "noisy_vector = 0.2 * vocab['fire-fighter'] + 0.15 * vocab['math-teacher'] + 0.3 * vocab['sales-manager']\n",
    "\n",
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete derivation of default objects using pseudoinverse.\")\n",
    "###################################################################\n",
    "\n",
    "sims = np.array([noisy_vector | vocab[...] for name in ...]).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_CognitiveStructures/solutions/W2D2_Tutorial1_Solution_0b0b7a2d.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Another graphical way to represent the similarity is by putting similarity value on the y-axis (instead of the box in the grid) and represent each of the objects by line (x-axis stay the same and similarity takes place between corresponding label on x-axis and line-object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "plot_line_similarity_matrix(sims, symbol_names, multiple_objects = False, title = 'Similarity - pre cleanup')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now let's construct a simple neural network that does cleanup.  We will construct the network, instead of learning it.  The input weights will be the vectors in the vocabulary, and we will place a softmax function on the hidden layer (although we can use more biologically plausible activiations) and the output weights will again be the vectors representing the symbols in the vocabulary.\n",
    "\n",
    "For efficient implementation of similarity calculation inside network, we will use `np.einsum()` function. Typically, it is used as `output = np.einsum('dim_inp1, dim_inp2 -> dim_out', input1, input2)`\n",
    "\n",
    "In this notation, `nd,md->nm` is the einsum \"equation\" or \"subscript notation\" which describes what operation should be performed. In this particular case, it states that the first input tensor is of shape `(n, d)` while the second is of shape `(m, d)` and the result of operation is of shape `(n, m)` (note that `n` and `m` can coincide). The operation itself performs the following calcualtion: `output[n, m] = sum(input1[n, d] * input2[m, d])`, meaning that in our case it will calculate all pairwise dot products - exactly what we need for similarity!\n",
    "\n",
    "Your task is to complete `__call__` function. Then we calculate similarity between obtained vector and the ones in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete Cleanup class.\")\n",
    "###################################################################\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "class Cleanup:\n",
    "    def __init__(self, vocab, temperature=1e5):\n",
    "        self.weights = np.array([vocab[k] for k in vocab.keys()]).squeeze()\n",
    "        self.temp = temperature\n",
    "    def __call__(self, x):\n",
    "        sims = np.einsum('nd,md->nm', ..., x)\n",
    "        max_sim = softmax(... * self.temp, axis=0)\n",
    "        return sspspace.SSP(np.einsum('nd,nm->md', self.weights, ...))\n",
    "\n",
    "\n",
    "cleanup = Cleanup(vocab)\n",
    "\n",
    "clean_vector = cleanup(noisy_vector)\n",
    "\n",
    "clean_sims = np.array([clean_vector | vocab[name] for name in symbol_names]).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_CognitiveStructures/solutions/W2D2_Tutorial1_Solution_f12d9c75.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Observe the result with comparison to the pre cleanup metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "plot_double_line_similarity_matrix([sims, clean_sims], symbol_names, ['Noisy Similarity', 'Clean Similarity'], title = 'Similarity - post cleanup')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We can do this cleanup with a single, feed-forward network, and we don't need to learn any of the synaptic weights if we know what the appropriate vocabulary is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_cleanup_memories_to_find_the_best_fit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "\n",
    "# Section 5: Iterated Binding\n",
    "\n",
    "Estimated timing to here from start of tutorial: 50 minutes\n",
    "\n",
    "In this section we will represent numbers with iterated binding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 5: Iterated Binding\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "# video_ids = [('Youtube', '<video_id_1>'), ('Bilibili', '<video_id_2>'), ('Osf', '<video_id_3>')]\n",
    "# tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "# tabs = widgets.Tab()\n",
    "# tabs.children = tab_contents\n",
    "# for i in range(len(tab_contents)):\n",
    "#   tabs.set_title(i, video_ids[i][0])\n",
    "# display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_iterated_binding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding Exercise 6: Representing Numbers\n",
    "\n",
    "It is often useful to be able to represent numbers.  For example, we may want to represent the position of an object in a list, or we may want to represent the coordinates of an object in a grid.  To do this we use the binding operator to construct a vector that represents a number.  We start by picking what we refer to as an \"axis vector\", let's call it $\\texttt{one}$, and then iteratively apply binding, like this:\n",
    "\n",
    "$$\n",
    "\\texttt{two} = \\texttt{one}\\circledast\\texttt{one} \n",
    "$$\n",
    "$$\n",
    "\\texttt{three} = \\texttt{two}\\circledast\\texttt{one} = \\texttt{one}\\circledast\\texttt{one}\\circledast\\texttt{one}\n",
    "$$\n",
    "\n",
    "and so on.  We extend that to arbitrary integers, $n$, by writing:\n",
    "\n",
    "$$\n",
    "\\phi[n] = \\underset{i=1}{\\overset{n}{\\circledast}}\\texttt{one}\n",
    "$$\n",
    "\n",
    "Let's try that now and see how similarity between iteratively bound vectors develops. In the cell below you should complete missing part which implements iterative binding mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "#define axis vector\n",
    "axis_vectors = ['one']\n",
    "\n",
    "encoder = sspspace.DiscreteSPSpace(axis_vectors, ssp_dim=1024, optimize=False)\n",
    "\n",
    "#vocabulary\n",
    "vocab = {w:encoder.encode(w) for w in axis_vectors}\n",
    "\n",
    "#we will add new vectors to this list\n",
    "integers = [vocab['one']]\n",
    "\n",
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete iterated binding.\")\n",
    "###################################################################\n",
    "\n",
    "max_int = 5\n",
    "for i in range(2, ... + 1):\n",
    "    integers.append(integers[...] * vocab[...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_CognitiveStructures/solutions/W2D2_Tutorial1_Solution_cec3cde4.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now, we will observe the similarity metric between the obtained vectors. In order to efficienty implement it, we will use already introduced `np.einsum` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "integers = np.array(integers).squeeze()\n",
    "sims = np.einsum('nd,md->nm',integers,integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "plot_similarity_matrix(sims, [i for i in range(1, 6)], values = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Here, we will take a look at another graphical representation of the similarity through lines (the only difference with the previous section is the fact that here we will have a couple of them, each representing distinct concept)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "plot_line_similarity_matrix(sims, range(1, 6), multiple_objects = True, labels = [f'$\\phi$[{idx+1}]' for idx in range(5)], title = \"Similarity for digits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "What we can see here is that each number acts like it's own vector, they are highly dissimilar, but we can still do arithmetic with them.  Let's see what happens when we unbind $\\texttt{two}$ from $\\texttt{five}$.\n",
    "\n",
    "In the cell below you are invited to complete the missing parts (be attentive! python is zero-indexed, thus you need to choose correct indices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: unbinding of two from five and apply `einsum` function on the correct arrays to receive desired similarity.\")\n",
    "###################################################################\n",
    "\n",
    "five_unbind_two = sspspace.SSP(integers[...]) * ~sspspace.SSP(integers[...])\n",
    "sims = np.einsum('nd,md->nm', ..., ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_CognitiveStructures/solutions/W2D2_Tutorial1_Solution_20834d8b.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "plot_line_similarity_matrix(sims, range(1, 6), multiple_objects = False,  title = '$(\\phi[5]\\circledast \\phi[2]^{-1}) \\cdot \\phi[n]$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We get what we expected - when we removed $\\texttt{two}$ from $\\texttt{five}$ we get a vector that is similar to $\\texttt{three}$.  We can do arithmetic with our vector encoding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_representing_numbers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding Exercise 7: Beyond Binding Integers\n",
    "\n",
    "This is all well and good, but sometimes we want to encode values that are not integers.  Is there an easy way to do this?  You'll be surprised to learn that the answer is: yes.\n",
    "\n",
    "We actually use the same technique, but we recognize that iterated binding can be implemented in the Fourier domain:\n",
    "\n",
    "$$\n",
    "\\phi[n] = \\mathcal{F}^{-1}\\left\\{\\mathcal{F}\\left\\{\\texttt{one}\\right\\}^{n}\\right\\}\n",
    "$$\n",
    "\n",
    "where the power of $n$ in the Fourier domain is applied element-wise to the vector.  To encode real-valued data we simply let the integer value, $n$, be a real-valued vector, $x$, and we let the axis vector be a randomly generated vector, $X$. \n",
    "\n",
    "$$\n",
    "\\phi(x) = \\mathcal{F}^{-1}\\left\\{\\mathcal{F}\\left\\{X\\right\\}^{x}\\right\\}\n",
    "$$\n",
    "\n",
    "We call vectors that represent real-valued data Spatial Semantic Pointers (SSPs).  We can also extend this to multi-dimensional data by binding different SSPs together.\n",
    "\n",
    "$$\n",
    "\\phi(x,y) = \\phi_{X}(x) \\circledast \\phi_{Y}(y)\n",
    "$$\n",
    "\n",
    "\n",
    "In the $\\texttt{sspspace}$ library we provide an encoder for real- and integer-valued data, and we'll demonstrate it next by encoding a bunch of points in the range $[-4,4]$ and comparing their value to $0$, encoded a SSP.\n",
    "\n",
    "In the cell below you should complete similarity calculation by injecting correct index for $0$ element (observe that it is right in the middle of encoded array)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete similarity calculation: correct index for `0` and array.\")\n",
    "###################################################################\n",
    "\n",
    "set_seed(42)\n",
    "encoder = sspspace.RandomSSPSpace(domain_dim=1, ssp_dim=1024)\n",
    "\n",
    "xs = np.linspace(-4,4,401)[:,None] #we expect the encoded values to be two-dimensional in `encoder.encode()` so we add extra dimension\n",
    "phis = encoder.encode(xs)\n",
    "\n",
    "sims = np.einsum('d,md->m', phis[..., :], ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_CognitiveStructures/solutions/W2D2_Tutorial1_Solution_d67b9922.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "plot_real_valued_line_similarity(sims, xs, title = '$\\phi(x)\\cdot\\phi(0)$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "As with the integers, we can update the values, post-encoding through the binding operation.  Let's look at the similarity between all the points in the range $[-4,4]$ this time with the value $\\pi/2$, but we will shift it by binding the origin with the desired shift value.\n",
    "\n",
    "In the cell below you need to provide the value by which we are going to shift the origin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: provide value to shift and observe the usage of the operation.\")\n",
    "###################################################################\n",
    "\n",
    "phi_shifted = phis[200,:][None,:] * encoder.encode([[...]])\n",
    "sims = np.einsum('d,md->m',phi_shifted.flatten(),phis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_CognitiveStructures/solutions/W2D2_Tutorial1_Solution_d21f7575.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "plot_real_valued_line_similarity(sims, xs, title = '$\\phi(x)\\cdot(\\phi(0)\\circledast\\phi(\\pi/2))$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We can then take that vector and shift it again to a new location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "phi_shifted = phis[200,:][None,:] * encoder.encode([[-1.5*np.pi]])\n",
    "sims = np.einsum('d,md->m',phi_shifted.flatten(),phis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "plot_real_valued_line_similarity(sims, xs, title = '$\\phi(x)\\cdot(\\phi(0)\\circledast\\phi(-1.5\\pi))$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We will go on to use these encodings to build spatial maps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Coding Exercise 7 Discussion\n",
    "\n",
    "1. How would you explain the usage of `d,md->m` in `np.einsum()` function in the previous coding exercise?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_CognitiveStructures/solutions/W2D2_Tutorial1_Solution_b91a4ab5.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_beyond_bidning_integers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 6: Iterated Binding Conclusion\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "# video_ids = [('Youtube', '<video_id_1>'), ('Bilibili', '<video_id_2>'), ('Osf', '<video_id_3>')]\n",
    "# tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "# tabs = widgets.Tab()\n",
    "# tabs.children = tab_contents\n",
    "# for i in range(len(tab_contents)):\n",
    "#   tabs.set_title(i, video_ids[i][0])\n",
    "# display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_iterated_binding_conclusion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "\n",
    "# Section 6: Analogies. Part 1\n",
    "\n",
    "Estimated timing to here from start of tutorial: 1 hour 10 minutes\n",
    "\n",
    "In this section we will construct a simple analogy using Vector Symbolic Algebras. The question we are going to try and solve is \"King is to queen as prince is to X\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 7: Analogy 1\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "# video_ids = [('Youtube', '<video_id_1>'), ('Bilibili', '<video_id_2>'), ('Osf', '<video_id_3>')]\n",
    "# tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "# tabs = widgets.Tab()\n",
    "# tabs.children = tab_contents\n",
    "# for i in range(len(tab_contents)):\n",
    "#   tabs.set_title(i, video_ids[i][0])\n",
    "# display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_analogy_one\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding Exercise 8: Royal Relationships\n",
    "\n",
    "We're going to start by considering our vocabulary.  We will use the basic discrete concepts of monarch, heir, male and female."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "symbol_names = ['monarch','heir','male','female']\n",
    "discrete_space = sspspace.DiscreteSPSpace(symbol_names, ssp_dim=1024, optimize=False)\n",
    "\n",
    "objs = {n:discrete_space.encode(n) for n in symbol_names}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now lets create the objects we know about by combinatorally expanding the space: \n",
    "\n",
    "1. King is a male monarch\n",
    "2. Queen is a female monarch\n",
    "3. Prince is a male heir\n",
    "4. Princess is a female heir\n",
    "\n",
    "Complete the missing parts of the code to obtain correct representations of new concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete correct relations for creating new concepts.\")\n",
    "###################################################################\n",
    "\n",
    "objs['king'] = objs['monarch'] * ...\n",
    "objs['queen'] = objs['monarch'] * ...\n",
    "objs['prince'] = ... * objs['male']\n",
    "objs['princess'] = ... * ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_CognitiveStructures/solutions/W2D2_Tutorial1_Solution_ac1b635f.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now we can take an explicit approach. We know that the conversion from king to queen is to unbind male and bind female, so let's apply that to our prince object and see what we uncover. \n",
    "\n",
    "At first, in the cell below, let's recover `queen` from `king` by constructing new `query` concept which represents unbinding of `male` and binding of `female`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete correct relation for creating `query` object to compare with `queen`.\")\n",
    "###################################################################\n",
    "\n",
    "objs['query'] = (... * ~...) * ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_CognitiveStructures/solutions/W2D2_Tutorial1_Solution_f088f722.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Let's see if this new query object bears any similarity to anything in our vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "object_names = list(objs.keys())\n",
    "sims = np.zeros((len(object_names), len(object_names)))\n",
    "\n",
    "for name_idx, name in enumerate(object_names):\n",
    "    for other_idx in range(name_idx, len(object_names)):\n",
    "        sims[name_idx, other_idx] = sims[other_idx, name_idx] = (objs[name] | objs[object_names[other_idx]]).item()\n",
    "\n",
    "plot_similarity_matrix(sims, object_names, values = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "The above similarity plot shows that applying that operation successfully converts king to queen.  Let's apply it to 'prince' and see what happens. Now, `query` should represent `princess` concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "objs['query'] = (objs['prince'] * ~objs['male']) * objs['female']\n",
    "\n",
    "sims = np.zeros((len(object_names), len(object_names)))\n",
    "\n",
    "for name_idx, name in enumerate(object_names):\n",
    "    for other_idx in range(name_idx, len(object_names)):\n",
    "        sims[name_idx, other_idx] = sims[other_idx, name_idx] = (objs[name] | objs[object_names[other_idx]]).item()\n",
    "\n",
    "plot_similarity_matrix(sims, object_names, values = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Here we have successfully recovered princess, completing the analogy.\n",
    "\n",
    "This approach, however, requires explicit knowledge of the construction of the objects.  Let's see if we can just work with the concepts of 'king', 'queen',and 'prince' directly.\n",
    "\n",
    "In the cell below, construct `princess` concept using only `king`, `queen` and `prince`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete correct relation for creating `query` object to compare with `princess`.\")\n",
    "###################################################################\n",
    "\n",
    "objs['query'] = (... * ~...) * ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_CognitiveStructures/solutions/W2D2_Tutorial1_Solution_b682d4ac.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "sims = np.zeros((len(object_names), len(object_names)))\n",
    "\n",
    "for name_idx, name in enumerate(object_names):\n",
    "    for other_idx in range(name_idx, len(object_names)):\n",
    "        sims[name_idx, other_idx] = sims[other_idx, name_idx] = (objs[name] | objs[object_names[other_idx]]).item()\n",
    "\n",
    "plot_similarity_matrix(sims, object_names, values = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Again, we see that we have recovered princess by using our analogy.\n",
    "\n",
    "That said, the above depends on knowning that the representations are constructed using binding.  Can we do a similar thing through the bundling operation?  Let's try that out.\n",
    "\n",
    "Reassing concept definitions using bundling operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete correct relation for creating concepts using bundling operation.\")\n",
    "###################################################################\n",
    "\n",
    "objs['king'] = (objs['monarch'] + ...).normalize()\n",
    "objs['queen'] = (... + objs['female']).normalize()\n",
    "objs['prince'] = (... + ...).normalize()\n",
    "objs['princess'] = (objs['heir'] + ...).normalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_CognitiveStructures/solutions/W2D2_Tutorial1_Solution_99fb441f.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "But now that we are using an additive model, we need to take a different approach.  Instead of unbinding king and binding queen, we subtract king and add queen to find princess from prince.\n",
    "\n",
    "Complete the code to reflect updated mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete correct relation for creating `query` object to compare with `princess`.\")\n",
    "###################################################################\n",
    "\n",
    "objs['query'] = (... - ...) + ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_CognitiveStructures/solutions/W2D2_Tutorial1_Solution_a4fe9181.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "sims = np.zeros((len(object_names), len(object_names)))\n",
    "\n",
    "for name_idx, name in enumerate(object_names):\n",
    "    for other_idx in range(name_idx, len(object_names)):\n",
    "        sims[name_idx, other_idx] = sims[other_idx, name_idx] = (objs[name] | objs[object_names[other_idx]]).item()\n",
    "\n",
    "plot_similarity_matrix(sims, object_names, values = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "This is a messier similarity plot, due to the fact that the bundled representations are interacting with the all their constituent parts in the vocabulary.  That said, we see that 'princess' is still most similar to the query vector. \n",
    "\n",
    "This approach is more like what we would expect from a wordvec embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_royal_relationships\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "\n",
    "# Section 7: Analogies. Part 2\n",
    "\n",
    "Estimated timing to here from start of tutorial: 1 hour 25 minutes\n",
    "\n",
    "In this section we will construct a database of data structures that describe different countries. Materials are adopted from the paper TBR by Pentti Kanerva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 8: Analogy 2\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "# video_ids = [('Youtube', '<video_id_1>'), ('Bilibili', '<video_id_2>'), ('Osf', '<video_id_3>')]\n",
    "# tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "# tabs = widgets.Tab()\n",
    "# tabs.children = tab_contents\n",
    "# for i in range(len(tab_contents)):\n",
    "#   tabs.set_title(i, video_ids[i][0])\n",
    "# display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_analogy_two\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding Exercise 9: Dolar of Mexico\n",
    "\n",
    "This is going to be a little more involved, because to construct the data structure we are going to need vectors that don't just represent values that we are reasoning about, but also vectors that represent different roles data can play. This is sometimes called a slot-filler representation, or a key-value representation.\n",
    "\n",
    "At first, let us define concepts and cleanup object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "symbol_names = ['dollar','peso', 'ottawa','mexico-city','currency','capital']\n",
    "discrete_space = sspspace.DiscreteSPSpace(symbol_names, ssp_dim=1024, optimize=False)\n",
    "\n",
    "\n",
    "objs = {n:discrete_space.encode(n) for n in symbol_names}\n",
    "\n",
    "cleanup = sspspace.Cleanup(objs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now, we will define `canada` and `mexico` concepts by integrating the available information together. You will be provided with `canada` object and your task is to complete for `mexico` one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete `mexico` concept.\")\n",
    "###################################################################\n",
    "\n",
    "objs['canada'] = (objs['currency'] * objs['dollar'] + objs['capital'] * objs['ottawa']).normalize()\n",
    "objs['mexico'] = (... * ... + ... * ...).normalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_CognitiveStructures/solutions/W2D2_Tutorial1_Solution_2bae18ce.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We would like to find out Mexico's currency. Complete the code for constructing `query` which will help us to do that. Note, that we are using cleanup operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete `query` concept which will be similar to currency in Mexico.\")\n",
    "###################################################################\n",
    "\n",
    "objs['query'] = cleanup((... * ~...) * objs['mexico'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_CognitiveStructures/solutions/W2D2_Tutorial1_Solution_bb153726.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "object_names = list(objs.keys())\n",
    "sims = np.zeros((len(object_names), len(object_names)))\n",
    "\n",
    "for name_idx, name in enumerate(object_names[:-1]):\n",
    "    for other_idx in range(name_idx, len(object_names)):\n",
    "        sims[name_idx, other_idx] = sims[other_idx, name_idx] = (objs[name] | objs[object_names[other_idx]]).item()\n",
    "\n",
    "plot_similarity_matrix(sims, object_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "After cleanup, the query vector is the most similar with the 'peso' object in the vocabularly, correctly answering the question.  \n",
    "\n",
    "Note, however, that the similarity is not perfectly equal to 1.  This is due to the scale factors applied to the composite vectors 'canada' and 'mexico', to ensure they remain unit vectors, and due to cross talk. Crosstalk is a symptom of the fact that we are binding and unbinding bundles of vector symbols to produce the resultant query vector. The constituent vectors are not perfectly orthogonal (i.e., having a dot product of zero) and as such the terms in the bundle interact when we measure similarity between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_dolar_of_mexico\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "\n",
    "# Section 8: Generalization - Wason Card Task\n",
    "\n",
    "Estimated timing to here from start of tutorial: 1 hour 35 minutes\n",
    "\n",
    "One of the powerful benefits of using these structured representations is being able to generalize to other circumstances.  To demonstrate this, we are going to show how we can use a simple learning rule to learn to extract a generalized rule to different circumstances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 9: Wason Card Task Intro\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "# video_ids = [('Youtube', '<video_id_1>'), ('Bilibili', '<video_id_2>'), ('Osf', '<video_id_3>')]\n",
    "# tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "# tabs = widgets.Tab()\n",
    "# tabs.children = tab_contents\n",
    "# for i in range(len(tab_contents)):\n",
    "#   tabs.set_title(i, video_ids[i][0])\n",
    "# display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_wason_card_task_intro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding Exercise 10: Wason Card Task\n",
    "\n",
    "We are going to test the generalization property on the Wason Card Task, where a person is told a rule of the form \"if the card is even, then the back is blue\", they are then presented with a number of cards with either an odd number, an even number, a red back, or a blue back.  The participant is asked which cards they have to flip to determine that the rule is true.\n",
    "\n",
    "In this case, the participant needs to flip only the even card(s), as the rule does not state whether or not odd numbers can have blue backs. \n",
    "\n",
    "At first, we will define all needed concepts. For all noun concepts we would also like to have `not smth` concept presented in the space, please complete missing code parts for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "card_states = ['red','blue','odd','even','not','green','prime','implies','ant','relation','cons']\n",
    "encoder = sspspace.DiscreteSPSpace(card_states, ssp_dim=1024, optimize=False)\n",
    "vocab = {c:encoder.encode(c) for c in card_states}\n",
    "\n",
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete creating `not x` concepts.\")\n",
    "###################################################################\n",
    "\n",
    "for a in ['red','blue','odd','even','green','prime']:\n",
    "    vocab[f'not*{a}'] = vocab[...] * vocab[...]\n",
    "\n",
    "action_names = ['red','blue','odd','even','green','prime','not*red','not*blue','not*odd','not*even','not*green','not*prime']\n",
    "action_space = np.array([vocab[x] for x in action_names]).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_CognitiveStructures/solutions/W2D2_Tutorial1_Solution_47654e2f.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now, we are going to set up a simple perceptron-style learning rule, using the HRR (Holographic Reduced Representations) algebra.  We are going to learn a target transformation, $T$, such that given a learning rule, $A^{*} = T\\circledast R$, where $A^{*}$ is the antecedance value bundled with $\\texttt{not}$ bound with the consequent value and $R$ is the learning rule.\n",
    "\n",
    "Rules themselves are going to be composed as country data structures from the previous section. `ant`, `relation` and `cons` are extra concepts which define the structure and which will bind to the specific instances. In the cell below, let us define two rules:\n",
    "\n",
    "$$\\text{blue} \\implies \\text{even}$$\n",
    "$$\\text{odd} \\implies \\text{green}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete creating rules as defined above.\")\n",
    "###################################################################\n",
    "\n",
    "rules = [\n",
    "    (vocab['ant'] * ... + vocab['relation'] * vocab['implies'] + vocab['cons'] * ...).normalize(),\n",
    "    (... * ... + ... * ... + ... * ...).normalize(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_CognitiveStructures/solutions/W2D2_Tutorial1_Solution_150dc068.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now, we are ready to derive the transformation! For that, we will iterate through the rules and solutions for specified number of iterations and update it as the following:\n",
    "\n",
    "$$T \\leftarrow T - \\text{lr}*(A^{*}*~R)$$\n",
    "\n",
    "where $\\text{lr}$ is learning rate constant value.\n",
    "\n",
    "We will also compute loss progression over the time and log loss function between perfect similarity (ones only for antecedance value and not consequent one) and the one we obtain between prediciton for current transformation and full action space. Complete missing parts of the code in the next cell to complete training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete training loop.\")\n",
    "###################################################################\n",
    "\n",
    "num_iters = 500\n",
    "losses = []\n",
    "sims = []\n",
    "lr = 1e-1\n",
    "ant_names = [\"blue\", \"odd\"]\n",
    "cons_names = [\"even\", \"green\"]\n",
    "\n",
    "transform = np.zeros((1,encoder.ssp_dim))\n",
    "for i in range(num_iters):\n",
    "    loss = 0\n",
    "    for rule, ant_name, cons_name in zip(..., ..., ...):\n",
    "        #perfect similarity\n",
    "        y_true = np.eye(len(action_names))[action_names.index(ant_name),:] + np.eye(len(action_names))[4+action_names.index(cons_name),:]\n",
    "\n",
    "        #prediction with current transform\n",
    "        a_hat = sspspace.SSP(...) * ...\n",
    "\n",
    "        #similarity with current transform\n",
    "        sim_mat = np.einsum('nd,md->nm', action_space, ...)\n",
    "        y_hat = softmax(...)\n",
    "\n",
    "        #true solution\n",
    "        a_true = (vocab[...] + vocab['not']*vocab[...]).normalize()\n",
    "\n",
    "        #calculate loss\n",
    "        loss += log_loss(y_true, y_hat)\n",
    "\n",
    "        #update transform\n",
    "        transform -= (lr) * (... - np.array(... * ~...))\n",
    "        transform = transform / np.linalg.norm(transform)\n",
    "\n",
    "        #save predicted similarities if it is last iteration\n",
    "        if i == num_iters - 1:\n",
    "            sims.append(sim_mat)\n",
    "\n",
    "    #save loss\n",
    "    losses.append(np.copy(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_CognitiveStructures/solutions/W2D2_Tutorial1_Solution_cd36fb64.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "plot_training_and_choice(losses, sims, ant_names, cons_names, action_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Let's see what happens when we test it on a new rule it hasn't seen before. This time we will use the rule that $\\text{red} \\implies \\text{prime}$. Your task is to complete new rule in the cell below and observe the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete new rule and predict for it.\")\n",
    "###################################################################\n",
    "\n",
    "new_rule = (vocab['ant'] * ... + vocab['relation'] * ... + vocab['cons'] * ...).normalize()\n",
    "\n",
    "a_hat = sspspace.SSP(...) * ...\n",
    "\n",
    "new_sims = np.einsum('nd,md->nm', action_space, a_hat)\n",
    "y_hat = softmax(new_sims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_CognitiveStructures/solutions/W2D2_Tutorial1_Solution_2d02bd6b.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "plot_choice([new_sims], [\"red\"], [\"prime\"], action_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Let's compare how a standard MLP that isn't aware of the structure in the representation performs. Here, features are going to be the rules and output - solutions. Complete the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete MLP training.\")\n",
    "###################################################################\n",
    "\n",
    "X_train = np.array(...).squeeze()\n",
    "\n",
    "y_train = np.array([\n",
    "    (vocab[ant_names[...]] + vocab['not']*vocab[cons_names[...]]).normalize(),\n",
    "    (vocab[...] + ...*vocab[...]).normalize(),\n",
    "]).squeeze()\n",
    "\n",
    "regr = MLPRegressor(random_state=1, hidden_layer_sizes=(1024,1024), max_iter=1000).fit(..., ...)\n",
    "\n",
    "a_mlp = regr.predict(new_rule)\n",
    "\n",
    "mlp_sims = np.einsum('nd,md->nm', action_space, a_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_CognitiveStructures/solutions/W2D2_Tutorial1_Solution_b41fb927.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "plot_choice([mlp_sims], [\"red\"], [\"prime\"], action_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "As you can see, this model, even though it is a more expressive neural network, simply learns to predict the values it had seen before, when presented with a novel stimulus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 10: Wason Card Task Outro\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "# video_ids = [('Youtube', '<video_id_1>'), ('Bilibili', '<video_id_2>'), ('Osf', '<video_id_3>')]\n",
    "# tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "# tabs = widgets.Tab()\n",
    "# tabs.children = tab_contents\n",
    "# for i in range(len(tab_contents)):\n",
    "#   tabs.set_title(i, video_ids[i][0])\n",
    "# display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_wason_card_task_outro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "\n",
    "# Section 9: Sample Efficient Learning\n",
    "\n",
    "Estimated timing to here from start of tutorial: 2 hours\n",
    "\n",
    "In this section we will take a look at how imposing an inductive bias on our feature space can result in more sample-efficient learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 11: Function Learning and Inductive Bias\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "# video_ids = [('Youtube', '<video_id_1>'), ('Bilibili', '<video_id_2>'), ('Osf', '<video_id_3>')]\n",
    "# tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "# tabs = widgets.Tab()\n",
    "# tabs.children = tab_contents\n",
    "# for i in range(len(tab_contents)):\n",
    "#   tabs.set_title(i, video_ids[i][0])\n",
    "# display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_function_learning_and_inductive_bias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding Exercise 11: Additive Function\n",
    "\n",
    "\n",
    "We will start with an additive function, the Rastrigin function, defined \n",
    "$$\n",
    "f(\\mathbf{x}) = 10*d + \\sum_{i=1}^{d} (x_{i}^{2} - 10 \\cos(2 \\pi x_{i}))\n",
    "$$\n",
    "\n",
    "where $d$ is the dimensionality of the input vector. In the cell below complete missing parts of the function which computes values of the Rastrigin function given the input array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete the Rastrigin function.\")\n",
    "###################################################################\n",
    "\n",
    "def rastrigin(x):\n",
    "    \"\"\"Compute Rastrigin function for given array of d-dimenstional vectors.\n",
    "\n",
    "    Inputs:\n",
    "    - x (np.ndarray of shape (n, d)): n d-dimensional vectors.\n",
    "\n",
    "    Outputs:\n",
    "    - y (np.ndarray of shape (n, 1)): Rastrigin function value for each of the vectors.\n",
    "    \"\"\"\n",
    "    return 10 * ... + np.sum(... - ... * np.cos(2*np.pi*...), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_CognitiveStructures/solutions/W2D2_Tutorial1_Solution_67fd1d5c.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# this code creates 10000 2-dimensional vectors which are going to be served as input to the function (thus, output is of shape (10000, 1))\n",
    "x0 = np.linspace(-5.12, 5.12, 100)\n",
    "X, Y = np.meshgrid(x0,x0)\n",
    "xs = np.vstack((X.flatten(), Y.flatten())).T\n",
    "\n",
    "ys_rastrigin = rastrigin(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "plot_3d_function([X],[Y], [ys_rastrigin.reshape(X.shape)], ['Rastrigin Function'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now, we are going to see which of the inductive biases (suggested mechanism underlying input data) will be more efficient in training the linear regression to get values of the Rastrigin function. For that, we will simply encode 2D input vectors `xs` (we call it 'bound') and with using bundling (encode each of the dimensions separately and then bundle them together). \n",
    "\n",
    "Complete these operations in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete simple encoding and bundling one.\")\n",
    "###################################################################\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "ssp_space = sspspace.RandomSSPSpace(domain_dim=2, ssp_dim=1024)\n",
    "bound_phis = ssp_space.encode(...)\n",
    "\n",
    "ssp_space0 = sspspace.RandomSSPSpace(domain_dim=1, ssp_dim=1024)\n",
    "ssp_space1 = sspspace.RandomSSPSpace(domain_dim=1, ssp_dim=1024)\n",
    "bundle_phis = ssp_space0.encode(xs[:,...][:,None]) + ssp_space1.encode(xs[:,...][:,None]) #remember that input to `encode` should be 2-dimensional, thus we need to create extra dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_CognitiveStructures/solutions/W2D2_Tutorial1_Solution_591afc36.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now, let us define modeling attributes: we will have a couple of different `test_sizes` and we will fit linear regression for each of them right in the loop; then, for each of the models we will evaluate its fit based on RMSE loss.\n",
    "\n",
    "Complete the missing parts of the loss function as well as training and testing one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete modelling utility functions.\")\n",
    "###################################################################\n",
    "\n",
    "def loss(y_true, y_pred):\n",
    "    \"\"\"Calculate RMSE loss between true and predicted values (note, that loss is not normalized by the shape).\n",
    "\n",
    "    Inputs:\n",
    "    - y_true (np.ndarray): true values.\n",
    "    - y_pred (np.ndarray): predicted values.\n",
    "\n",
    "    Outputs:\n",
    "    - loss (float): loss value.\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.mean((... - ...)**...))\n",
    "\n",
    "def test_performance(xs, ys, test_sizes):\n",
    "    \"\"\"Fit linear regression to the provided data and evaluate the performance with RMSE loss for different test sizes.\n",
    "\n",
    "    Inputs:\n",
    "    - xs (np.ndarray): input data.\n",
    "    - ys (np.ndarray): output data.\n",
    "    - test_size (list): list of the test sizes.\n",
    "    \"\"\"\n",
    "    performance = []\n",
    "\n",
    "    for test_size in test_sizes:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(..., ..., random_state=1, test_size=...)\n",
    "        regr = LinearRegression().fit(..., ...)\n",
    "        performance.append(np.copy(loss(..., regr.predict(...))))\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_CognitiveStructures/solutions/W2D2_Tutorial1_Solution_89e521bd.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now we are ready to traing the models on two different inductive biases of the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "test_sizes = np.linspace(0.1,0.75,10)\n",
    "bound_performance = test_performance(bound_phis, ys_rastrigin, test_sizes)\n",
    "bundle_performance = test_performance(bundle_phis, ys_rastrigin, test_sizes)\n",
    "plot_performance(bound_performance, bundle_performance, test_sizes, \"Rastrigin function - RMSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "What a drastic difference! Let us evaluate visually the performance with `test_size = 0.7`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "bound_model = get_model(bound_phis, ys_rastrigin, test_size=0.7)\n",
    "bundled_model = get_model(bundle_phis, ys_rastrigin, test_size=0.7)\n",
    "\n",
    "ys_hat_rastrigin_bound = bound_model.predict(bound_phis)\n",
    "ys_hat_rastrigin_bundled = bundled_model.predict(bundle_phis)\n",
    "\n",
    "plot_3d_function([X, X, X], [Y, Y, Y], [ys_rastrigin.reshape(X.shape), ys_hat_rastrigin_bound.reshape(X.shape), ys_hat_rastrigin_bundled.reshape(X.shape)], ['Rastrigin Function - True', 'Bound', 'Bundled'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Coding Exercise 11 Discussion\n",
    "\n",
    "1. Why do we think bundled representation is superior for Rastrigin function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_CognitiveStructures/solutions/W2D2_Tutorial1_Solution_1896987d.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_additive_function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding Exercise 12: Non-separable Function\n",
    "\n",
    "Now let's consider a non-separable function.  We will examine the function $f(\\mathbf{x}) = \\sin(x_{1}x_{2})$ over the domain $[-4,4]^{2}$.\n",
    "\n",
    "The same exercise goes here - continue missing parts of the code to get the correct calculation of the defined function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete the non-separable function.\")\n",
    "###################################################################\n",
    "\n",
    "def non_separable(x):\n",
    "    \"\"\"Compute non-separable function for given array of 2-dimenstional vectors.\n",
    "\n",
    "    Inputs:\n",
    "    - x (np.ndarray of shape (n, 2)): n 2-dimensional vectors.\n",
    "\n",
    "    Outputs:\n",
    "    - y (np.ndarray of shape (n, 1)): non-separable function value for each of the vectors.\n",
    "    \"\"\"\n",
    "    return np.sin(np.multiply(x[:,...],x[:,...]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_CognitiveStructures/solutions/W2D2_Tutorial1_Solution_1f73f80e.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "x0 = np.linspace(-4, 4, 100)\n",
    "X, Y = np.meshgrid(x0,x0)\n",
    "xs = np.vstack((X.flatten(), Y.flatten())).T\n",
    "\n",
    "ys_non_separable = non_separable(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "plot_3d_function([X],[Y], [ys_non_separable.reshape(X.shape)], ['Nonseparable Function, $f(\\mathbf{x}) = \\sin(x_{1}x_{2})$'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Coding Exercise 12 Discussion\n",
    "\n",
    "1. Can you guess by the nature of the function which of the representations will be more efficient?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_CognitiveStructures/solutions/W2D2_Tutorial1_Solution_d15de3bc.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We will reuse previously defined spaces for encoding bounded and bundling representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "bound_phis = ssp_space.encode(xs)\n",
    "bundle_phis = ssp_space0.encode(xs[:,0][:,None]) + ssp_space1.encode(xs[:,1][:,None])\n",
    "\n",
    "test_sizes = np.linspace(0.1,0.75,10)\n",
    "bound_performance = test_performance(bound_phis, ys_non_separable, test_sizes)\n",
    "bundle_performance = test_performance(bundle_phis, ys_non_separable, test_sizes)\n",
    "plot_performance(bound_performance, bundle_performance, test_sizes, title = \"Non-separable function - RMSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Bundling representation can't achieve the same quality even with the small fraction of test size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "bound_model = get_model(bound_phis, ys_non_separable, 0.75)\n",
    "bundle_model = get_model(bundle_phis, ys_non_separable, 0.1)\n",
    "\n",
    "ys_hat_bound = bound_model.predict(bound_phis)\n",
    "ys_hat_bundle = bundle_model.predict(bundle_phis)\n",
    "\n",
    "plot_3d_function([X, X, X], [Y, Y, Y], [ys_non_separable.reshape(X.shape), ys_hat_bound.reshape(X.shape), ys_hat_bundle.reshape(X.shape)], ['Non-separable Function - True', 'Bound', 'Bundled'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "So as we can see, when we pick the right inductive bias, we can do a better job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_non_separable_function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "\n",
    "# Section 10: Representing Continuous Values\n",
    "\n",
    "Estimated timing to here from start of tutorial: 2 hours 20 minutes\n",
    "\n",
    "In this section we will use a technique called Fractional Binding to represent continuous values to construct a map of objects distributed over a 2D space.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 12: Mapping Intro\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "# video_ids = [('Youtube', '<video_id_1>'), ('Bilibili', '<video_id_2>'), ('Osf', '<video_id_3>')]\n",
    "# tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "# tabs = widgets.Tab()\n",
    "# tabs.children = tab_contents\n",
    "# for i in range(len(tab_contents)):\n",
    "#   tabs.set_title(i, video_ids[i][0])\n",
    "# display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_mapping_intro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding Exercise 13: Mixing Discrete Objects With Continuous Space\n",
    "\n",
    "We are going to store three objects in a vector that represents a map. First we are going to create 3 objects (a circle, square, and triangle) like before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "obj_names = ['circle','square','triangle']\n",
    "discrete_space = sspspace.DiscreteSPSpace(obj_names, ssp_dim=1024)\n",
    "\n",
    "objs = {n:discrete_space.encode(n) for n in obj_names}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Next we are going to create three locations for the objects to reside at and an encoder to transform those coordinates into an SSP representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "ssp_space = sspspace.RandomSSPSpace(domain_dim=2, ssp_dim=1024)\n",
    "positions = np.array([[0,-2],\n",
    "                      [-2,3],\n",
    "                      [3,2]\n",
    "                     ])\n",
    "ssps = {n:ssp_space.encode(x) for n, x in zip(obj_names, positions)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Next, in order to see where things are on the map we are going to compute the similarity between encoded places and points in the space. Your task is to complete calculation of similarity values by proposing correct notation for `np.einsum()` function (remember: we would like to calculate similarity between all grid points with the given one associated with the object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "dim0 = np.linspace(-5,5,101)\n",
    "dim1 = np.linspace(-5,5,101)\n",
    "X,Y = np.meshgrid(dim0,dim1)\n",
    "\n",
    "query_xs = np.vstack((X.flatten(),Y.flatten())).T\n",
    "query_ssps = ssp_space.encode(query_xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete `np.einsum()` function.\")\n",
    "###################################################################\n",
    "\n",
    "sims = []\n",
    "\n",
    "for obj_idx, obj in enumerate(obj_names):\n",
    "    sims.append(np.einsum(..., ..., ssps[obj].flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_CognitiveStructures/solutions/W2D2_Tutorial1_Solution_5087e094.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "plot_2d_similarity(sims, obj_names, (dim0.size,dim1.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now, let's bind these positions with the objects and see how that changes similarity with the map positions. Complete binding operation in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete binding operation for objects and corresponding positions.\")\n",
    "###################################################################\n",
    "\n",
    "bound_objects = [... * ... for n in obj_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_CognitiveStructures/solutions/W2D2_Tutorial1_Solution_f3bc5204.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now we will calculate the similarity in the same way we did it before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "sims = []\n",
    "\n",
    "for obj_idx, obj in enumerate(obj_names):\n",
    "    sims.append(np.einsum('nd,d->n', query_ssps, bound_objects[obj_idx].flatten()))\n",
    "plot_2d_similarity(sims, obj_names, (dim0.size, dim1.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "As you can seem, the similarity is destroyed, which is what we should expect.\n",
    "\n",
    "Next, we are going to create a map out of our bound objects:\n",
    "\n",
    "$$\n",
    "\\mathrm{map} = \\sum_{i=1}^{n} \\phi(x_{i})\\circledast obj_{i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "ssp_map = sspspace.SSP(np.sum(bound_objects, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now we can query the map by unbinding the objects we care about. Your task is to complete the unbinding operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete the unbinding operation.\")\n",
    "###################################################################\n",
    "\n",
    "sims = []\n",
    "\n",
    "for obj_idx, obj_name in enumerate(obj_names):\n",
    "    query_map = ... * ~objs[...] # Query the object name\n",
    "    sims.append(np.einsum('nd,d->n', query_ssps,query_map.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_CognitiveStructures/solutions/W2D2_Tutorial1_Solution_561657d3.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Let's observed the resulting similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "plot_2d_similarity(sims, obj_names, (dim0.size, dim1.size), title_argmax = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Let's look at what happens when we unbind all the symbols at once from the map. Complete bundling and unbinding operations in the following code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete the bundling and unbinding operations.\")\n",
    "###################################################################\n",
    "\n",
    "all_objs = (objs['circle'] + ... + ...).normalize()\n",
    "query_map = ... * ~..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_CognitiveStructures/solutions/W2D2_Tutorial1_Solution_a1031b8a.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "sims = np.einsum('nd,d->n', query_ssps, query_map.flatten())\n",
    "size = (dim0.size,dim1.size)\n",
    "\n",
    "plot_unbinding_objects_map(sims, positions, query_xs, size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "But also, we can unbind positions and see what objects exist there. We will use test positions as the ones where objects are located but also two distinct ones to see what will be the result there. In the final exercise you should complete the unbinding of the position operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete the unbinding operations.\")\n",
    "###################################################################\n",
    "\n",
    "query_objs = np.vstack([objs[n] for n in obj_names])\n",
    "test_positions = np.vstack((positions, [0,0], [0,-1.5]))\n",
    "\n",
    "sims = []\n",
    "\n",
    "for pos_idx, pos in enumerate(test_positions):\n",
    "    position_ssp = ssp_space.encode(pos[None,:]) #remember we need to have 2-dimensional vectors for `encode()` function\n",
    "    query_map = ... * ~...\n",
    "    sims.append(np.einsum('nd,d->n', query_objs,query_map.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W2D2_CognitiveStructures/solutions/W2D2_Tutorial1_Solution_1af8f17d.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "plot_unbinding_positions_map(sims, test_positions, obj_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "As you can see from the above plots, when you query what is at the locations of the particular location, we can clearly identify which object is stored at which location.  \n",
    "\n",
    "When we query at the origin (where no object is present) we see that there is no strong candidate element.  But as we move closer to one of the objects (rightmost plot) the similarity starts to increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_mixing_discrete_objects_with_continuous_space\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 13: Mapping Outro\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "# video_ids = [('Youtube', '<video_id_1>'), ('Bilibili', '<video_id_2>'), ('Osf', '<video_id_3>')]\n",
    "# tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "# tabs = widgets.Tab()\n",
    "# tabs.children = tab_contents\n",
    "# for i in range(len(tab_contents)):\n",
    "#   tabs.set_title(i, video_ids[i][0])\n",
    "# display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_mapping_outro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Summary\n",
    "\n",
    "*Estimated timing of tutorial: 2 hours 40 minutes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 14: Conclusions\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "# video_ids = [('Youtube', '<video_id_1>'), ('Bilibili', '<video_id_2>'), ('Osf', '<video_id_3>')]\n",
    "# tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "# tabs = widgets.Tab()\n",
    "# tabs.children = tab_contents\n",
    "# for i in range(len(tab_contents)):\n",
    "#   tabs.set_title(i, video_ids[i][0])\n",
    "# display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_conclusions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Have a summary of what they learned with specific points.\n",
    "\n",
    "1. Specific point A\n",
    "\n",
    "2. Specific point B\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "W2D2_Tutorial1",
   "provenance": [],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
