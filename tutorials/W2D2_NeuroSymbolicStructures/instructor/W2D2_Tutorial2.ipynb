{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {},
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/neuromatch/NeuroAI_Course/blob/main/tutorials/W2D2_CognitiveStructures/student/W2D2_Tutorial2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> &nbsp; <a href=\"https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/neuromatch/NeuroAI_Course/blob/main/tutorials/W2D2_CognitiveStructures/student/W2D2_Tutorial2.ipynb\" target=\"_parent\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open in Kaggle\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Tutorial 2: Learning from structures\n",
    "\n",
    "**Week 2, Day 2: Neuro-Symbolic Structures**\n",
    "\n",
    "**By Neuromatch Academy**\n",
    "\n",
    "__Content creators:__ Michael Furlong\n",
    "\n",
    "__Content reviewers:__ Hlib Solodzhuk\n",
    "\n",
    "__Production editors:__ Konstantine Tsafatinos, Ella Batty, Spiros Chavlis, Samuele Bolotta, Hlib Solodzhuk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "___\n",
    "\n",
    "\n",
    "# Tutorial Objectives\n",
    "\n",
    "*Estimated timing of tutorial: 50 minutes*\n",
    "\n",
    "This tutorial will present you with a couple of play-examples on the usage of the basic operations while generalizing to the new knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Tutorial slides\n",
    "# @markdown These are the slides for the videos in all tutorials today\n",
    "\n",
    "from IPython.display import IFrame\n",
    "link_id = \"kj6p3\"\n",
    "\n",
    "print(f\"If you want to download the slides: 'https://osf.io/download/{link_id}'\")\n",
    "\n",
    "IFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{link_id}/?direct%26mode=render\", width=854, height=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Install and import feedback gadget\n",
    "\n",
    "# !pip3 install vibecheck datatops --quiet\n",
    "\n",
    "# from vibecheck import DatatopsContentReviewContainer\n",
    "# def content_review(notebook_section: str):\n",
    "#     return DatatopsContentReviewContainer(\n",
    "#         \"\",  # No text prompt - leave this as is\n",
    "#         notebook_section,\n",
    "#         {\n",
    "#             \"url\": \"https://pmyvdlilci.execute-api.us-east-1.amazonaws.com/klab\",\n",
    "#             \"name\": \"sciencematch_sm\", # change the name of the course : neuromatch_dl, climatematch_ct, etc\n",
    "#             \"user_key\": \"y1x3mpx5\",\n",
    "#         },\n",
    "#     ).render()\n",
    "\n",
    "# feedback_prefix = \"W2D2_T2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Install dependencies\n",
    "# @markdown\n",
    "\n",
    "# Install sspspace\n",
    "!pip install git+https://github.com/ctn-waterloo/sspspace@neuromatch --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "#working with data\n",
    "import numpy as np\n",
    "\n",
    "#plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "#interactive display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "#modeling\n",
    "import sspspace\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Figure settings\n",
    "\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' # perfrom high definition rendering for images and plots\n",
    "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/nma.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Plotting functions\n",
    "\n",
    "def plot_similarity_matrix(sim_mat, labels, values = False):\n",
    "    \"\"\"\n",
    "    Plot the similarity matrix between vectors.\n",
    "\n",
    "    Inputs:\n",
    "    - sim_mat (numpy.ndarray): similarity matrix between vectors.\n",
    "    - labels (list of str): list of strings which represent concepts.\n",
    "    - values (bool): True if we would like to plot values of similarity too.\n",
    "    \"\"\"\n",
    "    with plt.xkcd():\n",
    "        plt.imshow(sim_mat, cmap='Greys')\n",
    "        plt.colorbar()\n",
    "        plt.xticks(np.arange(len(labels)), labels, rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "        plt.yticks(np.arange(len(labels)), labels)\n",
    "        if values:\n",
    "            for x in range(sim_mat.shape[1]):\n",
    "                for y in range(sim_mat.shape[0]):\n",
    "                    plt.text(x, y, f\"{sim_mat[y, x]:.2f}\", fontsize = 8, ha=\"center\", va=\"center\", color=\"green\")\n",
    "        plt.title('Similarity between vector-symbols')\n",
    "        plt.xlabel('Symbols')\n",
    "        plt.ylabel('Symbols')\n",
    "        plt.show()\n",
    "\n",
    "def plot_training_and_choice(losses, sims, ant_names, cons_names, action_names):\n",
    "    \"\"\"\n",
    "    Plot loss progression over training as well as predicted similarities for given rules / correct solutions.\n",
    "\n",
    "    Inputs:\n",
    "    - losses (list): list of loss values.\n",
    "    - sims (list): list of similartiy matrices.\n",
    "    - ant_names (list): list of antecedance names.\n",
    "    - cons_names (list): list of consequent names.\n",
    "    - action_names (list): full list of concepts.\n",
    "    \"\"\"\n",
    "    with plt.xkcd():\n",
    "        plt.subplot(1, len(ant_names) + 1, 1)\n",
    "        plt.plot(losses)\n",
    "        plt.xlabel('Training number')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training Error')\n",
    "        index = 1\n",
    "        for ant_name, cons_name, sim in zip(ant_names, cons_names, sims):\n",
    "            index += 1\n",
    "            plt.subplot(1, len(ant_names) + 1, index)\n",
    "            plt.bar(range(len(action_names)), sim.flatten())\n",
    "            plt.gca().set_xticks(range(len(action_names)))\n",
    "            plt.gca().set_xticklabels(action_names, rotation=90)\n",
    "            plt.title(f'{ant_name}, not*{cons_name}')\n",
    "\n",
    "def plot_choice(sims, ant_names, cons_names, action_names):\n",
    "    \"\"\"\n",
    "    Plot predicted similarities for given rules / correct solutions.\n",
    "    \"\"\"\n",
    "    with plt.xkcd():\n",
    "        index = 0\n",
    "        for ant_name, cons_name, sim in zip(ant_names, cons_names, sims):\n",
    "            index += 1\n",
    "            plt.subplot(1, len(ant_names) + 1, index)\n",
    "            plt.bar(range(len(action_names)), sim.flatten())\n",
    "            plt.gca().set_xticks(range(len(action_names)))\n",
    "            plt.gca().set_xticklabels(action_names, rotation=90)\n",
    "            plt.ylabel(\"Similarity\")\n",
    "            plt.title(f'{ant_name}, not*{cons_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Set random seed\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def set_seed(seed=None):\n",
    "  if seed is None:\n",
    "    seed = np.random.choice(2 ** 32)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "\n",
    "set_seed(seed = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "\n",
    "# Section 1: Analogies. Part 1\n",
    "\n",
    "In this section we will construct a simple analogy using Vector Symbolic Algebras. The question we are going to try and solve is \"King is to queen as prince is to X\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 1: Analogy 1\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', 'qOoUEpIkV6w')]\n",
    "tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_analogy_one\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding Exercise 1: Royal Relationships\n",
    "\n",
    "We're going to start by considering our vocabulary.  We will use the basic discrete concepts of monarch, heir, male and female."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "symbol_names = ['monarch','heir','male','female']\n",
    "discrete_space = sspspace.DiscreteSPSpace(symbol_names, ssp_dim=1024, optimize=False)\n",
    "\n",
    "objs = {n:discrete_space.encode(n) for n in symbol_names}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now lets create the objects we know about by combinatorally expanding the space: \n",
    "\n",
    "1. King is a male monarch\n",
    "2. Queen is a female monarch\n",
    "3. Prince is a male heir\n",
    "4. Princess is a female heir\n",
    "\n",
    "Complete the missing parts of the code to obtain correct representations of new concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "```python\n",
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete correct relations for creating new concepts.\")\n",
    "###################################################################\n",
    "\n",
    "objs['king'] = objs['monarch'] * objs['male']\n",
    "objs['queen'] = objs['monarch'] * ...\n",
    "objs['prince'] = objs['heir'] * objs['male']\n",
    "objs['princess'] = ... * objs['female']\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "objs['king'] = objs['monarch'] * objs['male']\n",
    "objs['queen'] = objs['monarch'] * objs['female']\n",
    "objs['prince'] = objs['heir'] * objs['male']\n",
    "objs['princess'] = objs['heir'] * objs['female']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now we can take an explicit approach. We know that the conversion from king to queen is to unbind male and bind female, so let's apply that to our prince object and see what we uncover. \n",
    "\n",
    "At first, in the cell below, let's recover `queen` from `king` by constructing new `query` concept which represents unbinding of `male` and binding of `female`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "```python\n",
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete correct relation for creating `query` object to compare with `queen`.\")\n",
    "###################################################################\n",
    "\n",
    "objs['query'] = (objs[...] * ~objs[...]) * objs[...]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "objs['query'] = (objs['king'] * ~objs['male']) * objs['female']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Let's see if this new query object bears any similarity to anything in our vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "object_names = list(objs.keys())\n",
    "sims = np.zeros((len(object_names), len(object_names)))\n",
    "\n",
    "for name_idx, name in enumerate(object_names):\n",
    "    for other_idx in range(name_idx, len(object_names)):\n",
    "        sims[name_idx, other_idx] = sims[other_idx, name_idx] = (objs[name] | objs[object_names[other_idx]]).item()\n",
    "\n",
    "plot_similarity_matrix(sims, object_names, values = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "The above similarity plot shows that applying that operation successfully converts king to queen.  Let's apply it to 'prince' and see what happens. Now, `query` should represent `princess` concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "objs['query'] = (objs['prince'] * ~objs['male']) * objs['female']\n",
    "\n",
    "sims = np.zeros((len(object_names), len(object_names)))\n",
    "\n",
    "for name_idx, name in enumerate(object_names):\n",
    "    for other_idx in range(name_idx, len(object_names)):\n",
    "        sims[name_idx, other_idx] = sims[other_idx, name_idx] = (objs[name] | objs[object_names[other_idx]]).item()\n",
    "\n",
    "plot_similarity_matrix(sims, object_names, values = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Here we have successfully recovered princess, completing the analogy.\n",
    "\n",
    "This approach, however, requires explicit knowledge of the construction of the objects.  Let's see if we can just work with the concepts of 'king', 'queen',and 'prince' directly.\n",
    "\n",
    "In the cell below, construct `princess` concept using only `king`, `queen` and `prince`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "```python\n",
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete correct relation for creating `query` object to compare with `princess`.\")\n",
    "###################################################################\n",
    "\n",
    "objs['query'] = (objs[...] * ~objs[...]) * objs[...]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "objs['query'] = (objs['prince'] * ~objs['king']) * objs['queen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "sims = np.zeros((len(object_names), len(object_names)))\n",
    "\n",
    "for name_idx, name in enumerate(object_names):\n",
    "    for other_idx in range(name_idx, len(object_names)):\n",
    "        sims[name_idx, other_idx] = sims[other_idx, name_idx] = (objs[name] | objs[object_names[other_idx]]).item()\n",
    "\n",
    "plot_similarity_matrix(sims, object_names, values = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Again, we see that we have recovered princess by using our analogy.\n",
    "\n",
    "That said, the above depends on knowning that the representations are constructed using binding.  Can we do a similar thing through the bundling operation?  Let's try that out.\n",
    "\n",
    "Reassing concept definitions using bundling operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "objs['king'] = (objs['monarch'] + objs['male']).normalize()\n",
    "objs['queen'] = (objs['monarch'] + objs['female']).normalize()\n",
    "objs['prince'] = (objs['heir'] + objs['male']).normalize()\n",
    "objs['princess'] = (objs['heir'] + objs['female']).normalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "But now that we are using an additive model, we need to take a different approach.  Instead of unbinding king and binding queen, we subtract king and add queen to find princess from prince.\n",
    "\n",
    "Complete the code to reflect updated mechanism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "```python\n",
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete correct relation for creating `query` object to compare with `princess`.\")\n",
    "###################################################################\n",
    "\n",
    "objs['query'] = (objs[...] - objs[...]) + objs[...]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "objs['query'] = (objs['prince'] - objs['king']) + objs['queen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "sims = np.zeros((len(object_names), len(object_names)))\n",
    "\n",
    "for name_idx, name in enumerate(object_names):\n",
    "    for other_idx in range(name_idx, len(object_names)):\n",
    "        sims[name_idx, other_idx] = sims[other_idx, name_idx] = (objs[name] | objs[object_names[other_idx]]).item()\n",
    "\n",
    "plot_similarity_matrix(sims, object_names, values = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "This is a messier similarity plot, due to the fact that the bundled representations are interacting with the all their constituent parts in the vocabulary.  That said, we see that 'princess' is still most similar to the query vector. \n",
    "\n",
    "This approach is more like what we would expect from a wordvec embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_royal_relationships\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "\n",
    "# Section 2: Analogies. Part 2\n",
    "\n",
    "Estimated timing to here from start of tutorial: 15 minutes\n",
    "\n",
    "In this section we will construct a database of data structures that describe different countries. Materials are adopted from the paper TBR by Pentti Kanerva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 2: Analogy 2\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', '7RkogP-czNw')]\n",
    "tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_analogy_two\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding Exercise 2: Dolar of Mexico\n",
    "\n",
    "This is going to be a little more involved, because to construct the data structure we are going to need vectors that don't just represent values that we are reasoning about, but also vectors that represent different roles data can play. This is sometimes called a slot-filler representation, or a key-value representation.\n",
    "\n",
    "At first, let us define concepts and cleanup object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "symbol_names = ['dollar','peso', 'ottawa','mexico-city','currency','capital']\n",
    "discrete_space = sspspace.DiscreteSPSpace(symbol_names, ssp_dim=1024, optimize=False)\n",
    "\n",
    "\n",
    "objs = {n:discrete_space.encode(n) for n in symbol_names}\n",
    "\n",
    "cleanup = sspspace.Cleanup(objs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now, we will define `canada` and `mexico` concepts by integrating the available information together. You will be provided with `canada` object and your task is to complete for `mexico` one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "```python\n",
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete `mexico` concept.\")\n",
    "###################################################################\n",
    "\n",
    "objs['canada'] = (objs['currency'] * objs['dollar'] + objs['capital'] * objs['ottawa']).normalize()\n",
    "objs['mexico'] = (objs['currency'] * ... + objs['capital'] * ...).normalize()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "objs['canada'] = (objs['currency'] * objs['dollar'] + objs['capital'] * objs['ottawa']).normalize()\n",
    "objs['mexico'] = (objs['currency'] * objs['peso'] + objs['capital'] * objs['mexico-city']).normalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We would like to find out Mexico's currency. Complete the code for constructing `query` which will help us to do that. Note, that we are using cleanup operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "```python\n",
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete `query` concept which will be similar to currency in Mexico.\")\n",
    "###################################################################\n",
    "\n",
    "objs['query'] = cleanup((objs[...] * ~objs[...]) * objs['mexico'])\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "objs['query'] = cleanup((objs['dollar'] * ~objs['canada']) * objs['mexico'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "object_names = list(objs.keys())\n",
    "sims = np.zeros((len(object_names), len(object_names)))\n",
    "\n",
    "for name_idx, name in enumerate(object_names[:-1]):\n",
    "    for other_idx in range(name_idx, len(object_names)):\n",
    "        sims[name_idx, other_idx] = sims[other_idx, name_idx] = (objs[name] | objs[object_names[other_idx]]).item()\n",
    "\n",
    "plot_similarity_matrix(sims, object_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "After cleanup, the query vector is the most similar with the 'peso' object in the vocabularly, correctly answering the question.  \n",
    "\n",
    "Note, however, that the similarity is not perfectly equal to 1.  This is due to the scale factors applied to the composite vectors 'canada' and 'mexico', to ensure they remain unit vectors, and due to cross talk. Crosstalk is a symptom of the fact that we are binding and unbinding bundles of vector symbols to produce the resultant query vector. The constituent vectors are not perfectly orthogonal (i.e., having a dot product of zero) and as such the terms in the bundle interact when we measure similarity between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_dolar_of_mexico\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "\n",
    "# Section 3: Wason Card Task\n",
    "\n",
    "Estimated timing to here from start of tutorial: 25 minutes\n",
    "\n",
    "One of the powerful benefits of using these structured representations is being able to generalize to other circumstances. To demonstrate this, we are going to show how we can use a simple learning rule to learn to extract a generalized rule to different circumstances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 3: Wason Card Task Intro\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', 'KqMMEDjhbKI')]\n",
    "tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_wason_card_task_intro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding Exercise 3: Wason Card Task\n",
    "\n",
    "We are going to test the generalization property on the Wason Card Task, where a person is told a rule of the form \"if the card is even, then the back is blue\", they are then presented with a number of cards with either an odd number, an even number, a red back, or a blue back. The participant is asked which cards they have to flip to determine that the rule is true.\n",
    "\n",
    "In this case, the participant needs to flip only the even card(s), as the rule does not state whether or not odd numbers can have blue backs. \n",
    "\n",
    "At first, we will define all needed concepts. For all noun concepts we would also like to have `not concept` presented in the space, please complete missing code parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "```python\n",
    "set_seed(42)\n",
    "\n",
    "card_states = ['red','blue','odd','even','not','green','prime','implies','ant','relation','cons']\n",
    "encoder = sspspace.DiscreteSPSpace(card_states, ssp_dim=1024, optimize=False)\n",
    "vocab = {c:encoder.encode(c) for c in card_states}\n",
    "\n",
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete creating `not x` concepts.\")\n",
    "###################################################################\n",
    "\n",
    "for a in ['red','blue','odd','even','green','prime']:\n",
    "    vocab[f'not*{a}'] = vocab[...] * vocab[a]\n",
    "\n",
    "action_names = ['red','blue','odd','even','green','prime','not*red','not*blue','not*odd','not*even','not*green','not*prime']\n",
    "action_space = np.array([vocab[x] for x in action_names]).squeeze()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "card_states = ['red','blue','odd','even','not','green','prime','implies','ant','relation','cons']\n",
    "encoder = sspspace.DiscreteSPSpace(card_states, ssp_dim=1024, optimize=False)\n",
    "vocab = {c:encoder.encode(c) for c in card_states}\n",
    "\n",
    "for a in ['red','blue','odd','even','green','prime']:\n",
    "    vocab[f'not*{a}'] = vocab['not'] * vocab[a]\n",
    "\n",
    "action_names = ['red','blue','odd','even','green','prime','not*red','not*blue','not*odd','not*even','not*green','not*prime']\n",
    "action_space = np.array([vocab[x] for x in action_names]).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now, we are going to set up a simple perceptron-style learning rule, using the HRR (Holographic Reduced Representations) algebra.  We are going to learn a target transformation, $T$, such that given a learning rule, $A^{*} = T\\circledast R$, where $A^{*}$ is the antecedance value bundled with $\\texttt{not}$ bound with the consequent value and $R$ is the learning rule.\n",
    "\n",
    "Rules themselves are going to be composed as country data structures from the previous section. `ant`, `relation` and `cons` are extra concepts which define the structure and which will bind to the specific instances. In the cell below, let us define two rules:\n",
    "\n",
    "$$\\text{blue} \\implies \\text{even}$$\n",
    "$$\\text{odd} \\implies \\text{green}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "```python\n",
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete creating rules as defined above.\")\n",
    "###################################################################\n",
    "\n",
    "rules = [\n",
    "    (vocab['ant'] * vocab['blue'] + vocab['relation'] * vocab['implies'] + vocab['cons'] * vocab[...]).normalize(),\n",
    "    (vocab[...] * vocab[...] + vocab[...] * vocab[...] + vocab[...] * vocab[...]).normalize(),\n",
    "]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "rules = [\n",
    "    (vocab['ant'] * vocab['blue'] + vocab['relation'] * vocab['implies'] + vocab['cons'] * vocab['even']).normalize(),\n",
    "    (vocab['ant'] * vocab['odd'] + vocab['relation'] * vocab['implies'] + vocab['cons'] * vocab['green']).normalize(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now, we are ready to derive the transformation! For that, we will iterate through the rules and solutions for specified number of iterations and update it as the following:\n",
    "\n",
    "$$T \\leftarrow T - \\text{lr}*(A^{*} * \\sim R)$$\n",
    "\n",
    "where $\\text{lr}$ is learning rate constant value. Indeed, as $A^{*} = T\\circledast R$, it makes sense to unbind learning rule to get the current transformation prediction.\n",
    "\n",
    "We will also compute loss progression over the time and log loss function between perfect similarity (ones only for antecedance value and not consequent one) and the one we obtain between prediciton for current transformation and full action space. Complete missing parts of the code in the next cell to complete training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "```python\n",
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete training loop.\")\n",
    "###################################################################\n",
    "\n",
    "num_iters = 500\n",
    "losses = []\n",
    "sims = []\n",
    "lr = 1e-1\n",
    "ant_names = [\"blue\", \"odd\"]\n",
    "cons_names = [\"even\", \"green\"]\n",
    "\n",
    "transform = np.zeros((1,encoder.ssp_dim))\n",
    "for i in range(num_iters):\n",
    "    loss = 0\n",
    "    for rule, ant_name, cons_name in zip(rules, ant_names, cons_names):\n",
    "\n",
    "        #perfect similarity\n",
    "        y_true = np.eye(len(action_names))[action_names.index(ant_name),:] + np.eye(len(action_names))[4+action_names.index(cons_name),:]\n",
    "\n",
    "        #prediction with current transform (a_hat = transform * rule)\n",
    "        a_hat = sspspace.SSP(transform) * ...\n",
    "\n",
    "        #similarity with current transform\n",
    "        sim_mat = np.einsum('nd,md->nm', action_space, a_hat)\n",
    "\n",
    "        #cleanup\n",
    "        y_hat = softmax(sim_mat)\n",
    "\n",
    "        #true solution (a* = ant_name + not * cons_name)\n",
    "        a_true = (vocab[ant_name] + vocab['not']*vocab[...]).normalize()\n",
    "\n",
    "        #calculate loss\n",
    "        loss += log_loss(y_true, y_hat)\n",
    "\n",
    "        #update transform (T <- T - lr * (A* * (~rule)))\n",
    "        transform -= (lr) * (... - np.array(... * ~...))\n",
    "        transform = transform / np.linalg.norm(transform)\n",
    "\n",
    "        #save predicted similarities if it is last iteration\n",
    "        if i == num_iters - 1:\n",
    "            sims.append(sim_mat)\n",
    "\n",
    "    #save loss\n",
    "    losses.append(np.copy(loss))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "num_iters = 500\n",
    "losses = []\n",
    "sims = []\n",
    "lr = 1e-1\n",
    "ant_names = [\"blue\", \"odd\"]\n",
    "cons_names = [\"even\", \"green\"]\n",
    "\n",
    "transform = np.zeros((1,encoder.ssp_dim))\n",
    "for i in range(num_iters):\n",
    "    loss = 0\n",
    "    for rule, ant_name, cons_name in zip(rules, ant_names, cons_names):\n",
    "\n",
    "        #perfect similarity\n",
    "        y_true = np.eye(len(action_names))[action_names.index(ant_name),:] + np.eye(len(action_names))[4+action_names.index(cons_name),:]\n",
    "\n",
    "        #prediction with current transform (a_hat = transform * rule)\n",
    "        a_hat = sspspace.SSP(transform) * rule\n",
    "\n",
    "        #similarity with current transform\n",
    "        sim_mat = np.einsum('nd,md->nm', action_space, a_hat)\n",
    "\n",
    "        #cleanup\n",
    "        y_hat = softmax(sim_mat)\n",
    "\n",
    "        #true solution (a* = ant_name + not * cons_name)\n",
    "        a_true = (vocab[ant_name] + vocab['not']*vocab[cons_name]).normalize()\n",
    "\n",
    "        #calculate loss\n",
    "        loss += log_loss(y_true, y_hat)\n",
    "\n",
    "        #update transform (T <- T - lr * (A* * (~rule)))\n",
    "        transform -= (lr) * (transform - np.array(a_true * ~rule))\n",
    "        transform = transform / np.linalg.norm(transform)\n",
    "\n",
    "        #save predicted similarities if it is last iteration\n",
    "        if i == num_iters - 1:\n",
    "            sims.append(sim_mat)\n",
    "\n",
    "    #save loss\n",
    "    losses.append(np.copy(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "plot_training_and_choice(losses, sims, ant_names, cons_names, action_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Let's see what happens when we test it on a new rule it hasn't seen before. This time we will use the rule that $\\text{red} \\implies \\text{prime}$. Your task is to complete new rule in the cell below and observe the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "```python\n",
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete new rule and predict for it.\")\n",
    "###################################################################\n",
    "\n",
    "new_rule = (vocab['ant'] * vocab[...] + vocab['relation'] * ... + vocab['cons'] * vocab[...]).normalize()\n",
    "\n",
    "#apply transform on new rule to test the generalization of the transform\n",
    "a_hat = sspspace.SSP(transform) * ...\n",
    "\n",
    "new_sims = np.einsum('nd,md->nm', action_space, a_hat)\n",
    "y_hat = softmax(new_sims)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "new_rule = (vocab['ant'] * vocab['red'] + vocab['relation'] * vocab['implies'] + vocab['cons'] * vocab['prime']).normalize()\n",
    "\n",
    "#apply transform on new rule to test the generalization of the transform\n",
    "a_hat = sspspace.SSP(transform) * new_rule\n",
    "\n",
    "new_sims = np.einsum('nd,md->nm', action_space, a_hat)\n",
    "y_hat = softmax(new_sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "plot_choice([new_sims], [\"red\"], [\"prime\"], action_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Let's compare how a standard MLP that isn't aware of the structure in the representation performs. Here, features are going to be the rules and output - solutions. Complete the code below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "```python\n",
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete MLP training.\")\n",
    "###################################################################\n",
    "\n",
    "#features - rules\n",
    "X_train = np.array(...).squeeze()\n",
    "\n",
    "#output - a* for each rule\n",
    "y_train = np.array([\n",
    "    (vocab[ant_names[0]] + vocab['not']*vocab[cons_names[0]]).normalize(),\n",
    "    (vocab[ant_names[1]] + vocab['not']*vocab[cons_names[1]]).normalize(),\n",
    "]).squeeze()\n",
    "\n",
    "regr = MLPRegressor(random_state=1, hidden_layer_sizes=(1024,1024), max_iter=1000).fit(..., ...)\n",
    "\n",
    "a_mlp = regr.predict(new_rule)\n",
    "\n",
    "mlp_sims = np.einsum('nd,md->nm', action_space, a_mlp)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "#features - rules\n",
    "X_train = np.array(rules).squeeze()\n",
    "\n",
    "#output - a* for each rule\n",
    "y_train = np.array([\n",
    "    (vocab[ant_names[0]] + vocab['not']*vocab[cons_names[0]]).normalize(),\n",
    "    (vocab[ant_names[1]] + vocab['not']*vocab[cons_names[1]]).normalize(),\n",
    "]).squeeze()\n",
    "\n",
    "regr = MLPRegressor(random_state=1, hidden_layer_sizes=(1024,1024), max_iter=1000).fit(X_train, y_train)\n",
    "\n",
    "a_mlp = regr.predict(new_rule)\n",
    "\n",
    "mlp_sims = np.einsum('nd,md->nm', action_space, a_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "plot_choice([mlp_sims], [\"red\"], [\"prime\"], action_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "As you can see, this model, even though it is a more expressive neural network, simply learns to predict the values it had seen before, when presented with a novel stimulus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 4: Wason Card Task Outro\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', 'rV3oZXLFrb4')]\n",
    "tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "# content_review(f\"{feedback_prefix}_wason_card_task_outro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Summary\n",
    "\n",
    "*Estimated timing of tutorial: 45 minutes*\n",
    "\n",
    "In this tutorial, we have observed three scenarios where we used basic operations to develop relations between different concepts and derive some useful information about them. The next, enclosing tutorial, proposes even more complicated tasks and develops the true power of the proposed representations."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "W2D2_Tutorial2",
   "provenance": [],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "NeuroAI",
   "language": "python",
   "name": "neuroai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
