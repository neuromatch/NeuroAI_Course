{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0265a08c-d54a-4ade-be7f-170a28a79959",
   "metadata": {
    "execution": {}
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/neuromatch/NeuroAI_Course/blob/main/tutorials/W1D1_Generalization/student/W1D1_Tutorial2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> &nbsp; <a href=\"https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/neuromatch/NeuroAI_Course/main/tutorials/W1D1_Generalization/student/W1D1_Tutorial2.ipynb\" target=\"_parent\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open in Kaggle\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1581e3-dc27-449d-8b2c-58ae24bec2e9",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Tutorial 2: Generalization in Neuroscience\n",
    "\n",
    "**Week 1, Day 1: Generalization**\n",
    "\n",
    "**By Neuromatch Academy**\n",
    "\n",
    "__Content creators:__ Samuele Bolotta, Patrick Mineault and Shreya Saxena\n",
    "\n",
    "__Content reviewers:__ Samuele Bolotta, Lily Chamakura, RyeongKyung Yoon, Yizhou Chen, Ruiyi Zhang, Aakash Agrawal, Alish Dipani, Hossein Rezaei, Yousef Ghanbari, Mostafa Abdollahi, Hlib Solodzhuk\n",
    "\n",
    "__Production editors:__ Konstantine Tsafatinos, Ella Batty, Spiros Chavlis, Samuele Bolotta, Hlib Solodzhuk\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d07f00-daee-4df0-940b-d240e335c3de",
   "metadata": {
    "execution": {}
   },
   "source": [
    "___\n",
    "\n",
    "\n",
    "# Tutorial Objectives\n",
    "\n",
    "*Estimated timing of tutorial: 75 minutes*\n",
    "\n",
    "This tutorial will introduce you to generalization in neuroscience. We'll look at a classic neuroscience paper, [Sussillo et al. (2015)](https://www.nature.com/articles/nn.4042), that compares how artificial and biological neural networks solve different motor tasks. This paper looks at how linear arm movements are generated in motor cortex; later extensions of these ideas (e.g. [Codol et al. 2024](https://elifesciences.org/reviewed-preprints/88591v2); [Almani et al. 2024](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=x-YACVoAAAAJ&sortby=pubdate&citation_for_view=x-YACVoAAAAJ:1yQoGdGgb4wC)) address how more complex skilled movements, including handwriting, can be generated, continuing our theme for today's tutorials. We'll look at a popular AI-derived framework for understanding how the brain solves tasks: task-driven neural networks.\n",
    "\n",
    "Our learning goals for this tutorial are as follows:\n",
    "\n",
    "1. Understand core goals in neuroscience. Examine the fundamental questions that drive neuroscience research, such as the 'What', 'How', and 'Why' behind neurological functions and behaviors.\n",
    "\n",
    "2. Conceptualize generalization in neuroscience. Gain insights into what generalization entails within the field of neuroscience, understanding how principles of neural generalization can inform and be informed by artificial intelligence.\n",
    "\n",
    "3. Evaluate the impact of architectural choices. Discuss how different architectural decisions and the selection of priors in model design can introduce inductive biases, affecting the generalization capabilities of both neural and artificial systems.\n",
    "\n",
    "4. Illustrate robustness in noisy environments. Identify and describe real-world instances where the pursuit of robustness against noise has led to converging strategies in both neuroscience and artificial intelligence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bf0b64-9cff-4e19-a09b-2a578c6ec7e4",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Tutorial slides\n",
    "# @markdown These are the slides for the videos in all tutorials today\n",
    "\n",
    "from IPython.display import IFrame\n",
    "from ipywidgets import widgets\n",
    "out = widgets.Output()\n",
    "\n",
    "link_id = \"79523\"\n",
    "\n",
    "with out:\n",
    "    print(f\"If you want to download the slides: https://osf.io/download/{link_id}/\")\n",
    "    display(IFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/{link_id}/?direct%26mode=render%26action=download%26mode=render\", width=730, height=410))\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a35d5ac-7d05-4686-bf35-bde1bba0016a",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24296ef5-d8f9-438e-9574-08666be4cd5c",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Install and import feedback gadget\n",
    "\n",
    "!pip install numpy scipy matplotlib torch tqdm vibecheck --quiet\n",
    "\n",
    "from vibecheck import DatatopsContentReviewContainer\n",
    "def content_review(notebook_section: str):\n",
    "    return DatatopsContentReviewContainer(\n",
    "        \"\",  # No text prompt\n",
    "        notebook_section,\n",
    "        {\n",
    "            \"url\": \"https://pmyvdlilci.execute-api.us-east-1.amazonaws.com/klab\",\n",
    "            \"name\": \"neuromatch_neuroai\",\n",
    "            \"user_key\": \"wb2cxze8\",\n",
    "        },\n",
    "    ).render()\n",
    "\n",
    "\n",
    "feedback_prefix = \"W1D1_T2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa35e2b",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Import dependencies\n",
    "\n",
    "# Standard Libraries for file and operating system operations, security, and web requests\n",
    "import os\n",
    "import hashlib\n",
    "import requests\n",
    "import random\n",
    "import gc\n",
    "\n",
    "# Core Python data science and visualization libraries\n",
    "import numpy as np\n",
    "import scipy\n",
    "from matplotlib import pyplot as plt\n",
    "import logging\n",
    "from IPython.display import IFrame, display, Image\n",
    "\n",
    "# Deep Learning libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.autograd import profiler\n",
    "\n",
    "# Additional utilities\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2af95e4-b42d-4e65-afff-d77470f1716d",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Figure settings\n",
    "\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' # perform high definition rendering for images and plots\n",
    "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/nma.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bf7d34-d33a-4683-88e8-b27ae830ef73",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Plotting functions\n",
    "\n",
    "xlim = (-1.8, .7)\n",
    "\n",
    "def plot_inputs_over_time(timesteps, avg_inputs, title='Inputs over Time'):\n",
    "    \"\"\"\n",
    "    Plot the inputs over time.\n",
    "\n",
    "    Inputs:\n",
    "    - timesteps (list or array-like): A sequence of time steps at which the inputs were recorded.\n",
    "      This acts as the x-axis in the plot, representing the progression of time.\n",
    "    - avg_inputs (list or array-like): The average values of inputs corresponding to each time step.\n",
    "      These values are plotted on the y-axis, showing the magnitude of inputs over time.\n",
    "    - title (string): The title of the plot\n",
    "\n",
    "    Returns:\n",
    "    This function generates and displays a plot using Matplotlib.\n",
    "    \"\"\"\n",
    "\n",
    "    with plt.xkcd():\n",
    "        plt.figure(figsize=(8, 3))\n",
    "        num_features = avg_inputs.shape[1] if hasattr(avg_inputs, 'shape') else len(avg_inputs[0])\n",
    "\n",
    "        for feature_idx in range(num_features):\n",
    "            current_feature_values = avg_inputs[:, feature_idx] if hasattr(avg_inputs, 'shape') else [row[feature_idx] for row in avg_inputs]\n",
    "            label = f'Feature {feature_idx + 1}' if feature_idx < num_features - 1 else 'Go Cue'\n",
    "            plt.plot(timesteps, current_feature_values, label=label)\n",
    "\n",
    "        plt.title(title)\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Value (A.U.)')\n",
    "        plt.subplots_adjust(right=0.7)\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=8)\n",
    "        plt.tight_layout()\n",
    "        plt.xlim(min(timesteps), max(timesteps))\n",
    "        plt.show()\n",
    "\n",
    "def plot_muscles_over_time(timesteps, avg_output, title='Muscles over Time'):\n",
    "    \"\"\"\n",
    "    Plot the average outputs over time for two muscles to visualize changes in output values.\n",
    "    The avg_output is expected to be a 250x2 array where each column corresponds to a different muscle.\n",
    "\n",
    "    Inputs:\n",
    "    - timesteps (list or array-like): A sequence of time steps at which the outputs were recorded.\n",
    "      This acts as the x-axis in the plot, representing the progression of time.\n",
    "    - avg_output (array-like, shape [250, 2]): The average values of outputs, with each column\n",
    "      representing the output over time for each muscle.\n",
    "    - title (string): The title of the plot\n",
    "\n",
    "    Returns:\n",
    "    This function generates and displays a plot using Matplotlib.\n",
    "    \"\"\"\n",
    "\n",
    "    with plt.xkcd():\n",
    "\n",
    "        plt.figure(figsize=(8, 3))  # Set the figure size\n",
    "        plt.plot(timesteps, avg_output[:, 0], label='Muscle 1')  # Plot for muscle 1\n",
    "        plt.plot(timesteps, avg_output[:, 1], label='Muscle 2')  # Plot for muscle 2\n",
    "        plt.title(title)\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Value (A.U.)')\n",
    "\n",
    "        # Adjust plot margins to provide space for the legend outside the plot\n",
    "        plt.subplots_adjust(right=0.7)\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=8)  # Placing legend outside\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.xlim(min(timesteps), max(timesteps))  # Ensuring x-axis covers the range of timesteps\n",
    "        plt.show()\n",
    "\n",
    "def plot_training_validation_losses(epoch_losses, val_losses, actual_num_epochs, title):\n",
    "\n",
    "    \"\"\"\n",
    "    This function plots the training and validation losses over epochs.\n",
    "\n",
    "    Inputs:\n",
    "    - epoch_losses (list of float): List containing the training loss for each epoch. Each element is a float\n",
    "      representing the loss calculated after each epoch of training.\n",
    "    - val_losses (list of float): List containing the validation loss for each epoch. Similar to `epoch_losses`, but\n",
    "      for the validation set, allowing for the comparison between training and validation performance.\n",
    "    - actual_num_epochs (int): The actual number of epochs the training went through. This could be different from\n",
    "      the initially set number of epochs if early stopping was employed. It determines the range of the x-axis\n",
    "      in the plot.\n",
    "    - title (str): A string that sets the title of the plot. This allows for customization of the plot for better\n",
    "      readability and interpretation.\n",
    "\n",
    "    Outputs:\n",
    "    This function generates and displays a plot using matplotlib.\n",
    "    \"\"\"\n",
    "\n",
    "    with plt.xkcd():\n",
    "\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.plot(range(1, actual_num_epochs + 1), epoch_losses, label='Training Loss')\n",
    "        plt.plot(range(1, actual_num_epochs + 1), val_losses, label='Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title(title)\n",
    "        plt.legend()\n",
    "        plt.xlim(xlim)\n",
    "        plt.show()\n",
    "\n",
    "# Plot hidden units in UnregularizedRNN\n",
    "def plot_hidden_unit_activations(hidden_states, times, neurons_to_plot=5, title='PSTHs of Hidden Units'):\n",
    "    \"\"\"\n",
    "    This function plots the average activation of a specified number of neurons from the hidden layers\n",
    "    of a neural network over a certain number of timesteps.\n",
    "\n",
    "    Inputs:\n",
    "        hidden_states (tensor): A 2D tensor containing the hidden states of a network. The dimensions\n",
    "                                should be (time, features), where 'time' represents the sequence of\n",
    "                                timesteps, 'batch' represents different data samples, and 'features' represents\n",
    "                                the neuron activations or features at each timestep.\n",
    "        times (tensor): The time range that we focus on.\n",
    "        neurons_to_plot (int, optional): The number of neuron activations to plot, starting from the first neuron.\n",
    "                                         Defaults to 5.\n",
    "        title (str, optional): The title of the plot, allowing customization for specific analyses or presentations.\n",
    "                               Defaults to 'PSTHs of Hidden Units'.\n",
    "\n",
    "    This function generates and displays a plot of the average activation of specified\n",
    "    neurons over the selected timesteps, providing a visual analysis of neuron behavior within the network.\n",
    "    \"\"\"\n",
    "    # Apply the nonlinearity to each hidden state before averaging\n",
    "    rectified_tanh = lambda x: np.where(x > 0, np.tanh(x), 0)\n",
    "    hidden_states_rectified = rectified_tanh(np.array(hidden_states))\n",
    "\n",
    "    # Plotting\n",
    "\n",
    "    with plt.xkcd():\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        for i in range(min(neurons_to_plot, hidden_states_rectified.shape[1])):\n",
    "            plt.plot(times, hidden_states_rectified[:, i], label=f'Neuron {i+1}')\n",
    "\n",
    "        plt.xlabel('Time Steps')\n",
    "        plt.ylabel('Activation')\n",
    "        plt.title(title)\n",
    "\n",
    "        # Adjust plot margins to provide space for the legend outside the plot\n",
    "        plt.subplots_adjust(right=0.8)  # Adjust this value to create more or less space on the right\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize='small')  # Placing legend outside\n",
    "\n",
    "        plt.xlim(times[0], times[-1])  # Setting x-axis limits based on the provided time tensor\n",
    "        plt.show()\n",
    "\n",
    "def plot_psth(data, condition=0, neurons_to_plot=5, title='PSTHs of real data'):\n",
    "    \"\"\"\n",
    "    This function plots PSTHs from real neural data\n",
    "\n",
    "    Args:\n",
    "        data (dict): The data from the mat file from Sussillo et al. (2015)\n",
    "        condition (int, optional): The condition (from 0 to 26). Defaults to 0.\n",
    "        neurons_to_plot (int, optional): The number of neuron activations to plot, starting from the first neuron.\n",
    "                                         Defaults to 5.\n",
    "        title (str, optional): The title for the PSTH plot. This allows users to specify the context or the\n",
    "                     experiment from which the data is derived.\n",
    "\n",
    "    Outputs:\n",
    "    This function directly generates and displays a plot using matplotlib\n",
    "    to visually represent the neural activity across time bins.\n",
    "    \"\"\"\n",
    "    # Plot\n",
    "    with plt.xkcd():\n",
    "\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        for neuron_idx in range(neurons_to_plot):  # Iterate over each feature/channel\n",
    "            times_real = data['comboNjs'][0, neuron_idx]['interpTimes'][0]['times'][0].squeeze().astype(float)\n",
    "            t0 = float(data['comboNjs'][0, neuron_idx]['interpTimes'][0]['moveStarts'][0].item())\n",
    "            times_real = (times_real - t0) / 1000.0\n",
    "\n",
    "            spikes_real = data['comboNjs'][0, neuron_idx]['cond'][0]['interpPSTH'][0].squeeze()\n",
    "            plt.plot(times_real, spikes_real, label=f'Neuron {neuron_idx+1}')\n",
    "\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Average Activity (Hz)')\n",
    "        plt.title(title)\n",
    "\n",
    "        # Adjust plot margins and place legend outside the plot\n",
    "        plt.subplots_adjust(right=0.8)\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize='small')\n",
    "\n",
    "        plt.xlim(times_real[0], times_real[-1])  # Assume times_real is defined\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_perturbation_results(perturbation_strengths, results_regularized, results_unregularized, title):\n",
    "    \"\"\"\n",
    "    This function plots the normalized error percentages of two models (regularized and unregularized) under various\n",
    "    perturbation strengths.\n",
    "\n",
    "    Inputs:\n",
    "        perturbation_strengths (list of float): A list of perturbation strengths tested, representing the\n",
    "                                                 magnitude of perturbations applied to the model input or parameters.\n",
    "        results_regularized (list of tuples): Each tuple contains (mean error, standard deviation) for the regularized model\n",
    "                                         at each perturbation strength.\n",
    "        results_unregularized (list of tuples): Each tuple contains (mean error, standard deviation) for the unregularized model\n",
    "                                          at each perturbation strength.\n",
    "        title (str): The title of the plot, allowing for customization to reflect the analysis context.\n",
    "\n",
    "    The function generates and displays a bar plot comparing the normalized error\n",
    "    rates of regularized and unregularized models under different perturbation strengths, with error bars representing the\n",
    "    standard deviation of errors, normalized to percentage scale.\n",
    "    \"\"\"\n",
    "    mean_errors_regularized, std_errors_regularized = zip(*results_regularized)\n",
    "    mean_errors_unregularized, std_errors_unregularized = zip(*results_unregularized)\n",
    "\n",
    "    print(\"mean_errors_regularized\", mean_errors_regularized)\n",
    "    print(\"mean_errors_unregularized\", mean_errors_unregularized)\n",
    "\n",
    "    # Plotting\n",
    "\n",
    "    with plt.xkcd():\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        bar_width = 0.35\n",
    "        bar_positions = np.arange(len(perturbation_strengths))\n",
    "\n",
    "        plt.bar(bar_positions - bar_width/2, mean_errors_regularized, width=bar_width, color='blue', yerr=std_errors_regularized, capsize=5, label='Regularized Model')\n",
    "        plt.bar(bar_positions + bar_width/2, mean_errors_unregularized, width=bar_width, color='red', yerr=std_errors_unregularized, capsize=5, label='Unregularized Model')\n",
    "\n",
    "        plt.xlabel('Perturbation Magnitude')\n",
    "        plt.ylabel('Normalized Error (%)')\n",
    "        plt.title(title)\n",
    "        plt.xticks(bar_positions, [f\"{x:.5f}\" if x < 0.1 else f\"{x}\" for x in perturbation_strengths])\n",
    "        plt.legend()\n",
    "        plt.ylim(0, 100)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70b8e4b-f2ca-42af-bcd1-27fb6cecbc30",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Set device (GPU or CPU). Execute `set_device()`\n",
    "# especially if torch modules used.\n",
    "# @markdown\n",
    "\n",
    "# inform the user if the notebook uses GPU or CPU.\n",
    "\n",
    "def set_device():\n",
    "    \"\"\"\n",
    "    Determines and sets the computational device for PyTorch operations based on the availability of a CUDA-capable GPU.\n",
    "\n",
    "    Outputs:\n",
    "    - device (str): The device that PyTorch will use for computations ('cuda' or 'cpu'). This string can be directly used\n",
    "    in PyTorch operations to specify the device.\n",
    "    \"\"\"\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    if device != \"cuda\":\n",
    "        print(\"GPU is not enabled in this notebook. \\n\"\n",
    "              \"If you want to enable it, in the menu under `Runtime` -> \\n\"\n",
    "              \"`Hardware accelerator.` and select `GPU` from the dropdown menu\")\n",
    "    else:\n",
    "        print(\"GPU is enabled in this notebook. \\n\"\n",
    "              \"If you want to disable it, in the menu under `Runtime` -> \\n\"\n",
    "              \"`Hardware accelerator.` and select `None` from the dropdown menu\")\n",
    "\n",
    "    return device\n",
    "\n",
    "device = set_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654e7c22-bd2a-4a6e-867e-462646e3b496",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Set random seed, when using `pytorch`\n",
    "\n",
    "# @markdown Executing `set_seed(seed=seed)` you are setting the seed\n",
    "\n",
    "# Call `set_seed` function in the exercises to ensure reproducibility.\n",
    "\n",
    "def set_seed(seed=None, seed_torch=True):\n",
    "  if seed is None:\n",
    "    seed = np.random.choice(2 ** 32)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  if seed_torch:\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "  print(f'Random seed {seed} has been set.')\n",
    "\n",
    "# In case that `DataLoader` is used\n",
    "def seed_worker(worker_id):\n",
    "  worker_seed = torch.initial_seed() % 2**32\n",
    "  np.random.seed(worker_seed)\n",
    "  random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fea2ec-e1ee-4ebe-9dff-d3b253c3ba0b",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Data retrieval\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import hashlib\n",
    "\n",
    "def retrieve_file(fname, url, expected_md5):\n",
    "    # Check if the file already exists\n",
    "    if not os.path.isfile(fname):\n",
    "        try:\n",
    "            # Attempt to download the file\n",
    "            response = requests.get(url)\n",
    "        except requests.ConnectionError:\n",
    "            # Handle connection errors during the download\n",
    "            print(\"!!! Failed to download data !!!\")\n",
    "        else:\n",
    "            # No connection errors, proceed to check the response\n",
    "            if response.status_code != requests.codes.ok:\n",
    "                # Check if the HTTP response status code indicates a successful download\n",
    "                print(\"!!! Failed to download data !!!\")\n",
    "            elif hashlib.md5(response.content).hexdigest() != expected_md5:\n",
    "                # Verify the integrity of the downloaded file using MD5 checksum\n",
    "                print(\"!!! Data download appears corrupted !!!\")\n",
    "            else:\n",
    "                # If download is successful and data is not corrupted, save the file\n",
    "                with open(fname, \"wb\") as fid:\n",
    "                    fid.write(response.content) # Write the downloaded content to a file\n",
    "\n",
    "# List of files to be downloaded with their respective URLs and expected MD5 hashes\n",
    "files = [\n",
    "    (\"regularized_model_final.pth\", \"https://osf.io/kc7sb/download\", \"9435a9c2ea75766144bf840b25bfb97e\"),\n",
    "    (\"unregularized_model_final.pth\", \"https://osf.io/9vsy5/download\", \"2e3dc9551b677206e2315788df354a91\"),\n",
    "    (\"condsForSimJ2moMuscles.mat\", \"https://osf.io/wak7e/download\", \"257d16c4d92759d615bf5cac75dd9a1f\"),\n",
    "    (\"m1_reaching_data.mat\", \"https://osf.io/p2x4n/download\", \"6fc65443b9632db47772dd2efaadeee0\")\n",
    "]\n",
    "\n",
    "for fname, url, expected_md5 in files:\n",
    "    retrieve_file(fname, url, expected_md5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b2b4f7-14f6-4374-a8a4-a17799d1f787",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Helper functions\n",
    "\n",
    "# Define a custom Rectified Tanh activation function\n",
    "def rectified_tanh(x):\n",
    "    return torch.where(x > 0, torch.tanh(x), 0)\n",
    "\n",
    "def grad_rectified_tanh(x):\n",
    "    return torch.where(x > 0, 1 - torch.tanh(x)**2, 0)\n",
    "\n",
    "def grad_tanh(x):\n",
    "    return 1 - torch.tanh(x)**2\n",
    "\n",
    "def compute_l2_regularization(parameters, alpha):\n",
    "    l2_reg = sum(p.pow(2.0).sum() for p in parameters)\n",
    "    return alpha * l2_reg\n",
    "\n",
    "def prepare_dataset(file_path, feature_idx=7, muscle_idx=1):\n",
    "    \"\"\"\n",
    "    Load and preprocess data from a .mat file for RNN training.\n",
    "\n",
    "    Args:\n",
    "    - file_path: str, path to the .mat file containing the dataset.\n",
    "    - feature_idx: int, index for individual features for plotting. Max 14.\n",
    "    - muscle_idx: int, index for muscles for plotting. Max 1.\n",
    "\n",
    "    Returns:\n",
    "    - normalised_inputs: Tensor, normalized and concatenated Plan and Go Envelope tensors.\n",
    "    - avg_output: Tensor, average muscle activity across conditions and delays.\n",
    "    - timesteps: np.ndarray, array of time steps for plotting.\n",
    "    \"\"\"\n",
    "    # Load the .mat file\n",
    "    data = scipy.io.loadmat(file_path)\n",
    "\n",
    "    # Extract condsForSim struct\n",
    "    conds_for_sim = data['condsForSim']\n",
    "\n",
    "    # Initialize lists to store data for all conditions\n",
    "    go_envelope_all, plan_all, muscle_all = [], [], []\n",
    "\n",
    "    # Get the number of conditions (rows) and delay durations (columns)\n",
    "    num_conditions, num_delays = conds_for_sim.shape\n",
    "\n",
    "    times = conds_for_sim['timesREmove'][0][0] / 1000.0\n",
    "\n",
    "    # Select the same time period as the PSTHs\n",
    "    rg = slice(46, 296)\n",
    "\n",
    "    for i in range(num_conditions):  # Loop through each condition\n",
    "        go_envelope_condition, plan_condition, muscle_condition = [], [], []\n",
    "\n",
    "        for j in range(num_delays):  # Loop through each delay duration\n",
    "            condition = conds_for_sim[i, j]\n",
    "            go_envelope, plan, muscle = condition['goEnvelope'], condition['plan'], condition['muscle']\n",
    "            selected_muscle_data = muscle[:, [3, 4]]  # Select only specific muscles\n",
    "            go_envelope_condition.append(go_envelope[rg, :])\n",
    "            plan_condition.append(plan[rg, :])\n",
    "            muscle_condition.append(selected_muscle_data[rg, :])\n",
    "\n",
    "        # Convert lists of arrays to tensors and append to all conditions\n",
    "        go_envelope_all.append(torch.tensor(np.array(go_envelope_condition), dtype=torch.float32))\n",
    "        plan_all.append(torch.tensor(np.array(plan_condition), dtype=torch.float32))\n",
    "        muscle_all.append(torch.tensor(np.array(muscle_condition), dtype=torch.float32))\n",
    "\n",
    "    times = times[rg]\n",
    "\n",
    "    # Stack tensors for all conditions\n",
    "    go_envelope_tensor, plan_tensor, output = torch.stack(go_envelope_all), torch.stack(plan_all), torch.stack(muscle_all)\n",
    "\n",
    "    # Cleanup to free memory\n",
    "    del data, conds_for_sim, go_envelope_all, plan_all, muscle_all\n",
    "    gc.collect()\n",
    "\n",
    "    # Normalize and Standardize Plan Tensor\n",
    "    plan_tensor = normalize_and_standardize(plan_tensor)\n",
    "\n",
    "    # Normalise and concatenate Plan and Go Envelope Tensors\n",
    "    normalised_inputs = normalize_and_standardize(torch.cat([plan_tensor, go_envelope_tensor], dim=3))\n",
    "\n",
    "    fixed_delay = 3\n",
    "    inputs_no_delay = normalised_inputs[:, fixed_delay, ...]\n",
    "    output_no_delay = output[:, fixed_delay, ...]\n",
    "    return inputs_no_delay, normalised_inputs, output_no_delay, output, times\n",
    "\n",
    "def normalize_and_standardize(tensor):\n",
    "    \"\"\"\n",
    "    Normalize and standardize a given tensor.\n",
    "\n",
    "    Args:\n",
    "    - tensor: Tensor, the tensor to be normalized and standardized.\n",
    "\n",
    "    Returns:\n",
    "    - standardized_normalized_tensor: Tensor, the normalized and standardized tensor.\n",
    "    \"\"\"\n",
    "    min_val, max_val = tensor.min(), tensor.max()\n",
    "    tensor = (tensor - min_val) / (max_val - min_val)  # Normalize\n",
    "    mean, std = tensor.mean(), tensor.std()\n",
    "    return (tensor - mean) / std  # Standardize\n",
    "\n",
    "def train_val_split():\n",
    "    \"\"\"Split the data into train and validation splits.\n",
    "    \"\"\"\n",
    "    train_split, val_split = random_split(range(27), [20, 7])\n",
    "    return sorted(list(train_split)), sorted(list(val_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291f8880-5449-433c-9d2d-4130be2266f9",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 1: Overview\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', 'lW0U2vv5BmQ'), ('Bilibili', 'BV1g1421C7G4')]\n",
    "tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd640e68-b128-4b37-b922-5f3d73ce45f7",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_overview_video\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417c2110-9f36-49b4-9aca-3bc0df32a1a2",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Section 1: Motivation: How the brain generates motor commands\n",
    "\n",
    "Let's put ourselves in the mindset of a neuroscientist trying to understand how the brain generates motor sequences. A classic example of a complex motor sequence is handwriting, which involves coordinated movement of the arm, wrist and fingers during handwriting. \n",
    "\n",
    "The mapping between the goal (e.g. moving the arm) and the sequence of motor commands that drive different muscles is highly nonlinear and recurrent. Furthermore, the brain must *generalize* beyond its training data; for instance, when the recurrent connections of the brain change due to noise or homeostasis, or when the arm is under load. How does the brain do that?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cc0263-74a3-42a0-ab78-de496172ecd1",
   "metadata": {
    "execution": {}
   },
   "source": [
    "<img src=\"https://github.com/neuromatch/NeuroAI_Course/blob/main/tutorials/W1D1_Generalization/static/setup.png?raw=true\" width=600 />\n",
    "\n",
    "*Image adapted from Rizzoglio et al. (2023). From monkeys to humans: observation-based EMG brainâ€“computer interface decoders for humans with paralysis. Journal of Neural Engineering. 10.1088/1741-2552/ad038e. CC-BY 4.0.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1102b233-748c-4a37-8b40-7f8edc2b2bad",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Our neuroscientist is trying to address a *how* question: how does the brain find solutions to complex control problems that generalize? Recurrent neural networks (RNNs), a type of artificial neural network, have proven a very useful tool to address these *how* questions. They mimic the adaptability and plasticity observed in biological neural networks through interconnected artificial neurons, weights dictating connection strengths, and activation functions triggering neuron responses. **Task-driven neural networks** are trained *in silico* to solve similar tasks to ones that the brain must solve. Properly constrained, they often find solutions to problems that are similar to the ones that the brain seems to find. The trained artificial neural networks can then be used to investigate, mechanistically, how a task is solved. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff10456-56dc-4f64-9d1b-45aa343ecba1",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "source": [
    "![Picture which shows an RNN.](https://github.com/neuromatch/NeuroAI_Course/blob/main/tutorials/W1D1_Generalization/static/rnn.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76206fc7-b2a7-4598-9c4c-450b138e9f5a",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Let's illustrate these ideas with a classic paper in this field: [Sussillo et al. (2015)](https://www.nature.com/articles/nn.4042). They train an RNN to solve a motor task by learning to map commands to arm movements recorded via electromyography (EMG). Looking inside this RNN gives them a platform to investigate questions about generalization. They then compare the data from the RNN to spike data from the motor cortex (M1) of a monkey performing a similar task. Do they perform similarly? Is the RNN performing the same kind of task as the brain, in a similar way?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca34d9d-c42d-4a66-9cdb-640e8ea7136d",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 2: Setup\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', 'AEQJ6e32ZeQ'), ('Bilibili', 'BV1D6421f7vH')]\n",
    "tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa77b4b2-35fb-4de9-8353-15275bbf4fd4",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_setup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c38e8e-55f6-4d83-a863-819174b38d7c",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Section 2: Training an unregularized task-driven neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efadda69-d5fe-4fc8-9bc9-bdc982b7f7de",
   "metadata": {
    "execution": {}
   },
   "source": [
    "In this activity, our goal is to train recurrent neural networks to mimic the muscle activity of monkeys during arm movements. The challenge is to transform simple inputs (task features) into complex patterns of muscle activity over time and space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc16cdcf-d366-452c-ac7d-4fd11221a717",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Define the path to the dataset file containing conditions for simulation of muscles\n",
    "file_path = 'condsForSimJ2moMuscles.mat'\n",
    "\n",
    "# Prepare the dataset by loading and processing it from the specified file path\n",
    "normalised_inputs, normalised_inputs_with_delay, outputs, outputs_with_delay, times = prepare_dataset(file_path)\n",
    "\n",
    "print(\"Shape of the inputs\", normalised_inputs.shape)\n",
    "print(\"Shape of the output\", outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeb718b-f138-463a-bcfb-64fbf6d5c101",
   "metadata": {
    "execution": {}
   },
   "source": [
    "These dimensions correspond to the following:\n",
    "\n",
    "* 27 conditions, one for each reach\n",
    "* 250 time steps at a 100Hz sampling rate (2.5s trials)\n",
    "* The inputs are 16-dimensional, with 15 dimensions corresponding to the reach condition and the 16th dimension corresponding to the go-cue.\n",
    "* The outputs are 2-dimensional, corresponding to the target electromyography (EMG) data for **2** muscles.\n",
    "\n",
    "The inputs are 16-dimensional and indicate to the model **which reach to perform**. Each reach condition is coded as a random 15-dimensional vector which is held constant during the movement preparation period from -1s to 0s. The go-cue in the 16th dimension has a small bump at 0s, indicating to the model that it should generate the output. \n",
    "\n",
    "Let's look at the few of the inputs and outputs to get a better understanding of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd6d286-fc8b-4b1c-babe-c58279781637",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Averaging across conditions and delays\n",
    "reach_directions = [0, 6, 9]\n",
    "for reach in reach_directions:\n",
    "    #Plot inputs and outputs\n",
    "    one_direction = normalised_inputs[reach, ...].clone()\n",
    "    # Exaggerate the go cue\n",
    "    one_direction[:, -1] *= 5\n",
    "    plot_inputs_over_time(times, one_direction, title=f'Inputs over Time, reach direction {reach}')\n",
    "    plot_muscles_over_time(times, outputs[reach, ...], title=f'Outputs over Time, reach direction {reach}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2babbe86-34bb-45e3-9240-2c8165f86b16",
   "metadata": {
    "execution": {}
   },
   "source": [
    "As you can see:\n",
    "\n",
    "* the movement to be generated is encoded by a 16-dimensional signal during the hold period (from -1 to 0s).\n",
    "* the 16-dimensional signal is unique for each reach direction\n",
    "* The go cue (feature 16, time 0) signals that it's time to generate the movement\n",
    "* The movements of the muscles are generated right after the GO cue.\n",
    "\n",
    "Let's create a PyTorch dataset to wrap this raw tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417463ca-29c8-4229-baed-58dcf390747a",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "class TimeseriesDataset(Dataset):\n",
    "    def __init__(self, inputs, targets):\n",
    "        \"\"\"\n",
    "        inputs: Tensor of shape [#examples, time, input_features]\n",
    "        targets: Tensor of shape [#examples, time, output_features]\n",
    "        \"\"\"\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        self.num_conditions = inputs.shape[0]\n",
    "        assert inputs.shape[0] == targets.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_conditions\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_seq = self.inputs[idx]\n",
    "        target_seq = self.targets[idx]\n",
    "        return input_seq, target_seq\n",
    "\n",
    "# Create the dataset with the fixed delay\n",
    "train_idx, val_idx = train_val_split()\n",
    "train_dataset = TimeseriesDataset(normalised_inputs[train_idx], outputs[train_idx])\n",
    "val_dataset = TimeseriesDataset(normalised_inputs[val_idx], outputs[val_idx])\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 20\n",
    "unregularized_train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "unregularized_val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a47a4b-1bf2-4bd8-9d88-14a6ecf899a7",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_Setup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3302fb-cd76-4803-8fbf-5b7baf4409d3",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding exercise 2.1: Defining an unregularized RNN\n",
    "\n",
    "Let's start by defining an unregularized RNN `nn.Module` which takes in the time-varying control inputs and outputs muscle outputs.\n",
    "\n",
    "The model is a single-layer recurrent neural network defined in continuous time. The network takes in an input vector and outputs muscle EMG. The hidden state of the network $\\mathbf{x}$ evolves according to the equation:\n",
    "\n",
    "$$\\tau \\frac{d\\mathbf{x}}{dt} = -\\mathbf{x} + \\mathbf{B}\\mathbf{u} + \\mathbf{J}\\mathbf{r} + \\mathbf{b}$$\n",
    "\n",
    "Here we have:\n",
    "\n",
    "* $\\mathbf{B}\\mathbf{u}$ is the feedforward drive of the neural network, the inputs $\\mathbf{u}$ are linearly projected through a set of weights $\\mathbf{B}$\n",
    "* $\\mathbf{J}\\mathbf{r}$ is the recurrent drive of the neural network, the recurrent activity $\\mathbf{r}$ are linearly projected through a set of weights $\\mathbf{J}$\n",
    "* $\\mathbf{r} = |\\tanh(\\mathbf{x})|$ is the hidden activity passed through a rectifying, saturating nonlinearity\n",
    "* $\\mathbf{b}$ is a constant\n",
    "* $\\tau$ is a scalar corresponding to the time scale of the network, 50 ms\n",
    "\n",
    "To transform this to a standard discrete-time neural network, we use Euler integration, with a time step equal to the resolution of the simulation, 10ms. See the [Comp Neuro W2D2](https://compneuro.neuromatch.io/tutorials/W2D2_LinearSystems/student/W2D2_Tutorial1.html?highlight=euler+integration#coding-exercise-1-forward-euler-integration) to brush up on this idea.\n",
    "\n",
    "Thus, the discretized update equation will be:\n",
    "\n",
    "$$\\mathbf{x_{t+1}} = \\mathbf{x}_{t} + \\Delta t\\frac{d\\mathbf{x_t}}{dt}$$\n",
    "\n",
    "There are a few more parameters to consider:\n",
    "\n",
    "* The scale of the parameters of the input mixing matrix $\\mathbf{B}$ is determined by $h$\n",
    "* The scale of the parameters of the input mixing matrix $\\mathbf{J}$ is determined by $g$. We initialize $g$ to a value larger than 1, so the neural network is in a chaotic regime.\n",
    "* The network start with a hidden state $\\mathbf{x}=0$\n",
    "\n",
    "Finally, the observed EMG activity is given by a linear readout:\n",
    "\n",
    "$$z = \\mathbf{W}\\mathbf{r} + c$$\n",
    "\n",
    "Let's code up this unregularized neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5506de88-628c-49f3-ba31-c77a310ed063",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "class UnregularizedRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, g, h, tau_over_dt=5):\n",
    "        super(UnregularizedRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.tau_over_dt = tau_over_dt\n",
    "        self.output_linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        # Weight initialization\n",
    "        self.J = nn.Parameter(torch.randn(hidden_size, hidden_size) * (g / torch.sqrt(torch.tensor(hidden_size, dtype=torch.float))))\n",
    "        self.B = nn.Parameter(torch.randn(hidden_size, input_size) * (h / torch.sqrt(torch.tensor(input_size, dtype=torch.float))))\n",
    "        self.bx = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "        # Nonlinearity\n",
    "        self.nonlinearity = rectified_tanh\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        #################################################\n",
    "        # TODO for students: fill in the missing variables\n",
    "        # Fill out function and remove\n",
    "        raise NotImplementedError(\"Student exercise: fill in the missing variables\")\n",
    "        #################################################\n",
    "\n",
    "        # Calculate the visible firing rate from the hidden state.\n",
    "        firing_rate_before = ...\n",
    "\n",
    "        # Update hidden state\n",
    "        recurrent_drive = torch.matmul(self.J, firing_rate_before.transpose(0, 1))\n",
    "        input_drive = torch.matmul(self.B, input.transpose(0, 1))\n",
    "        total_drive = recurrent_drive + input_drive + self.bx.unsqueeze(1)\n",
    "        total_drive = total_drive.transpose(0, 1)\n",
    "\n",
    "        # Euler integration for continuous-time update\n",
    "        hidden = hidden + (1 / self.tau_over_dt) * (-hidden + total_drive)\n",
    "\n",
    "        # Calculate the new firing rate given the update.\n",
    "        firing_rate = ...\n",
    "\n",
    "        # Project the firing rate linearly to form the output\n",
    "        output = ...\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(batch_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc083cb-b42c-4b73-bba7-a4ca5e03aaef",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W1D1_Generalization/solutions/W1D1_Tutorial2_Solution_98ebec10.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6ae852-bdb1-40f3-bcff-cbab538aff60",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "input_size = 16\n",
    "hidden_size = 10\n",
    "output_size = 2\n",
    "g = 4\n",
    "h_val = 1.0\n",
    "\n",
    "model = UnregularizedRNN(input_size, hidden_size, output_size, g, h_val)\n",
    "model.to(device)\n",
    "\n",
    "for inputs, targets in unregularized_train_loader:\n",
    "    hidden = model.init_hidden(batch_size)\n",
    "    output, hidden_after = model(inputs[:, 0, :].to(device), hidden.to(device))\n",
    "    assert output.shape == targets[:, 0].shape\n",
    "    assert hidden_after.shape == hidden.shape\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f7f1ca-4eae-430c-b65f-4a8233c2db43",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Great! Now we have the model ready to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8083bc3d-cfbd-43fd-928d-92f82d0eccb9",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_Coding_Exercise_2.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34983335-94bb-4150-836f-2f5db94ae5ad",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding exercise 2.2: Evaluate function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "R6ATQbbbkJDZ",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We'll need a function that can generate an entire trajectory based on a set of inputs. To do that, we'll first initialize the hidden state of the model, then recurrently feed the inputs and the hidden states back into the model. Fill in the missing lines to generate an entire trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58ebe49-25fa-420b-a996-fa9095dbbf1c",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "def generate_trajectory(model, inputs, device):\n",
    "    #################################################\n",
    "    # TODO for students: fill in the missing variables\n",
    "    # Fill out function and remove\n",
    "    raise NotImplementedError(\"Student exercise: fill in the missing variables\")\n",
    "    #################################################\n",
    "    inputs = inputs.to(device)\n",
    "    batch_size = inputs.size(0)\n",
    "    h = ...\n",
    "\n",
    "    loss = 0\n",
    "    outputs = []\n",
    "    hidden_states = []\n",
    "    with torch.no_grad():\n",
    "        for t in range(inputs.shape[1]):\n",
    "            # Forward the model's input and hidden state to obtain the model\n",
    "            # output and hidden state *h*.\n",
    "            # Note that you should index the input tensor by the time dimension\n",
    "            # Capture any additional outputs in 'rest'\n",
    "            output, h, *rest = ...\n",
    "            outputs.append(output)\n",
    "            hidden_states.append(h.detach().clone())\n",
    "\n",
    "    return torch.stack(outputs, axis=1).to(device), torch.stack(hidden_states, axis=1).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QMEldftkmGPK",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W1D1_Generalization/solutions/W1D1_Tutorial2_Solution_dc6b3d2e.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fb2c7c-4aa9-4824-a59c-1c76d8485210",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "trajectory, hidden_states = generate_trajectory(model,\n",
    "                                             inputs[0].unsqueeze(0),\n",
    "                                             device)\n",
    "\n",
    "with plt.xkcd():\n",
    "  plot_hidden_unit_activations(hidden_states=hidden_states.squeeze().detach().cpu().numpy(),\n",
    "                               times=times,\n",
    "                               neurons_to_plot=7,\n",
    "                               title='Hidden units')\n",
    "  plot_muscles_over_time(times, trajectory.squeeze().detach().cpu().numpy(), 'Generated muscle activity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd4f116-09e9-4392-9ea4-1c0cd78be2d0",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Our untrained model generates funky oscillatory activity, but we'll fix that during training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cea1ac-78b6-4704-8cc4-3f6d74921446",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_Coding_Exercise_2.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f006a913-0031-4882-8e87-55a5c30bb763",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Activity 2.1: Evaluating the model\n",
    "\n",
    "Now that we've built up our codebase, we're ready to train our model. This involves:\n",
    "\n",
    "* Loading the data\n",
    "* Instantiating the model\n",
    "* Building a training loop\n",
    "* Using stochastic gradient to train the model\n",
    "\n",
    "To save you time, however, we've trained the model in advance. You'll thus load a trained checkpoint. This trained model can generate the right muscle outputs in response to the right inputs. Let's do a quick sanity check to make sure this is the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e611ab8b-f74f-4370-8dfb-51b00a436258",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Instantiate model\n",
    "input_size = 16\n",
    "hidden_size = 150\n",
    "output_size = 2  # Number of muscles\n",
    "g = 4  # g value\n",
    "h_val = 1.0  # h value\n",
    "\n",
    "unregularized_model = UnregularizedRNN(input_size, hidden_size, output_size, g, h_val)\n",
    "unregularized_model.to(device)  # Move model to the appropriate device\n",
    "\n",
    "# Load the pretrained model\n",
    "model_path = 'unregularized_model_final.pth'\n",
    "model_state_dict = torch.load(model_path, map_location=device)\n",
    "unregularized_model.load_state_dict(model_state_dict)\n",
    "unregularized_model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Example index\n",
    "idx = 0\n",
    "\n",
    "# Ensure data is on the correct device\n",
    "sample_input = normalised_inputs[train_idx[idx], ...].to(device)\n",
    "sample_target = outputs[train_idx[idx], ...].to(device)\n",
    "\n",
    "# Generate trajectory\n",
    "generated_target, hidden_states = generate_trajectory(unregularized_model, sample_input.unsqueeze(0), device)\n",
    "\n",
    "# Plotting\n",
    "plot_inputs_over_time(times, sample_input.cpu())\n",
    "plot_muscles_over_time(times, sample_target.cpu(), 'Targets')\n",
    "plot_muscles_over_time(times, generated_target.squeeze().detach().cpu().numpy(), 'Generated')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a37f05-d8c3-4750-bada-0fbe0c5f11f9",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Looks good! Our trained RNN is able to generate muscle activity similar to the measured activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751f7ddc-4b28-49c8-a3ab-74586b538d03",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_Model_Evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b372fc77-34c5-4f5d-b3bf-17a8adcef4be",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Activity 2.2: Comparing trained RNN with the brain\n",
    "\n",
    "Our trained RNN transforms inputs into muscle activations. In effect, the RNN is a stand-in for motor cortex. The activity of the hidden units of the RNN should thus *look* like motor cortex. We thus plot different PSTHs of real neurons when they perform an animal performs a specific arm movement. Then, we plot different â€œPSTHsâ€ of hidden units of the unregularized RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4656278f-bbaa-4823-ad28-325722a6453c",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "plot_hidden_unit_activations(hidden_states=hidden_states.squeeze().detach().cpu().numpy(),\n",
    "                             times=times,\n",
    "                             neurons_to_plot=10,\n",
    "                             title='PSTHs of Hidden Units in UnregularizedRNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384b08b1-c0f8-48c8-877f-b6c119d70148",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Let's do the same, now with real neural data. We load smoothed spiking data from Susillo et al. (2015). These are PSTHs of monkeys performing the same kind of reaching movement that the artificial neural network is trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442c4a80-abdb-4ca2-9cb1-a9162f30fa69",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat('m1_reaching_data.mat')\n",
    "plot_psth(data, neurons_to_plot=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb5c10a-6c62-443a-b7be-a0e8e50efec7",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Qualitatively, that doesn't look like much of a match. **A trained RNN that performs the same task as the brain can have a very different latent representation**. In later tutorials, we'll cover in detail quantitative methods for evaluating how well representations in artificial and biological neural networks match each other; in particular, it is going to be the main theme of Day 3. For now, let's try to get a qualitative match with better regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe04b3d-26f8-4748-8fe7-8bc14186897e",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_RNN_vs_Brain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cb1867-859d-4de6-91a8-858b8fa4de1f",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 3: Inductive Bias\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', 'O4cM86DcVUw'), ('Bilibili', 'BV1Gb421v7PH')]\n",
    "tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3926aac-d1e6-42fc-8dd0-b275e1b68204",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_inductive_bias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c1598f-aeea-45f2-81ca-afcb0be0c04b",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Section 3: Training a regularized task-driven neural network\n",
    "\n",
    "The previous network found complicated solutions to the problem of generating muscle activity: the hidden activity of the network wasn't matched to what we see in real neurons. We'd like to obtain more **naturalistic solutions** that better match the brain by regularizing this network. Later, we'll test this regularized network for robustness and generalization to see if this also affects the network's ability to extrapolate beyond its training data.\n",
    "\n",
    "Susillo et al. propose to regularize the network in many different ways.\n",
    "\n",
    "**Weight regularization**\n",
    "\n",
    "Synapses are expensive to grow and maintain. The authors thus propose to use a standard L2 penalty on the sum of squares of the weights:\n",
    "\n",
    "$$R_0 = \\sum_{ij} B_{ij}^2 + W_{ij}^2$$\n",
    "\n",
    "Recall that $W$ are the weights that map the latent activity to the EMG data, while $B$ are the weights from the feedforward drive of the system. The penalty limits the size of the weights, potentially leading to more biologically plausible solutions.\n",
    "\n",
    "**Firing rate regularization**\n",
    "\n",
    "Neural activity in biological neural networks is expensive. Thus, we add a penalty for the magnitude of the hidden activity in the network.\n",
    "\n",
    "$$R_1 = \\frac{1}{NT} \\sum_{it} r_{it} ^ 2$$\n",
    "\n",
    "Here $N$ is the number of hidden neurons and $T$ is the total number of discrete time steps in the simulation, and $r{it}$ is the activity of the hidden neurons over time.\n",
    "\n",
    "**Multiple delays**\n",
    "\n",
    "Neural activity should be robust to the exact delays between the preparatory input and the go cue. We augment the dataset with multiple delays between the signal and the go cue.\n",
    "\n",
    "**Less chaotic initialization regime**\n",
    "\n",
    "We initialized the previous RNN with large weights, putting the network in a chaotic regime, with high sensitivity to changes in activity. We'll dial down the initialization range in this network to obtain dynamics at the edge of chaos. In practice, this involves changing the parameter that controls the magnitude of the initial recurrent weights $g$ from 4 to 1.5.\n",
    "\n",
    "With all these changes in mind, we're ready to implement the regularized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ccb5ad-f7f7-46e6-83d7-e6f85818e683",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "class RegularizedRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, g, h, tau_over_dt=5):\n",
    "        super(RegularizedRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.tau_over_dt = tau_over_dt  # Time constant\n",
    "        self.output_linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        # Weight initialization\n",
    "        self.J = nn.Parameter(torch.randn(hidden_size, hidden_size) * (g / torch.sqrt(torch.tensor(hidden_size, dtype=torch.float))))\n",
    "        self.B = nn.Parameter(torch.randn(hidden_size, input_size) * (h / torch.sqrt(torch.tensor(input_size, dtype=torch.float))))\n",
    "        self.bx = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "        # Nonlinearity\n",
    "        self.nonlinearity = rectified_tanh\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # Calculate the visible firing rate from the hidden state.\n",
    "        firing_rate_before = self.nonlinearity(hidden)\n",
    "\n",
    "        # Update hidden state\n",
    "        recurrent_drive = torch.matmul(self.J, firing_rate_before.transpose(0, 1))\n",
    "        input_drive = torch.matmul(self.B, input.transpose(0, 1))\n",
    "        total_drive = recurrent_drive + input_drive + self.bx.unsqueeze(1)\n",
    "        total_drive = total_drive.transpose(0, 1)\n",
    "\n",
    "        # Euler integration for continuous-time update\n",
    "        hidden = hidden + (1 / self.tau_over_dt) * (-hidden + total_drive)\n",
    "\n",
    "        # Calculate the new firing rate given the update.\n",
    "        firing_rate = self.nonlinearity(hidden)\n",
    "\n",
    "        # Project the firing rate linearly to form the output\n",
    "        output = self.output_linear(firing_rate)\n",
    "\n",
    "        # Regularization terms\n",
    "        firing_rate_reg = firing_rate.pow(2).sum()\n",
    "\n",
    "        return output, hidden, firing_rate_reg\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # Initialize hidden state with batch dimension\n",
    "        return torch.zeros(batch_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ac6883-40d7-4426-9949-e30f0e404e86",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We split the dataset into training and validation sets. Importantly, we keep the different delays corresponding to the same condition in the same set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cde5eda-c684-4d3f-87a7-e60a19f8955d",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "train_flattened_inputs = normalised_inputs_with_delay[train_idx].view(-1, *normalised_inputs_with_delay.shape[2:])\n",
    "train_flattened_targets = outputs_with_delay[train_idx].view(-1, *outputs_with_delay.shape[2:])\n",
    "\n",
    "val_flattened_inputs = normalised_inputs_with_delay[val_idx].view(-1, *normalised_inputs_with_delay.shape[2:])\n",
    "val_flattened_targets = outputs_with_delay[val_idx].view(-1, *outputs_with_delay.shape[2:])\n",
    "\n",
    "# Create the dataset with the fixed delay\n",
    "train_dataset = TimeseriesDataset(train_flattened_inputs, train_flattened_targets)\n",
    "val_dataset = TimeseriesDataset(val_flattened_inputs, val_flattened_targets)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 20\n",
    "regularized_train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "regularized_val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb0d107-0ff6-44a6-9017-8246b232e82c",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Activity 3.1: Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a273ae-dc6c-4d09-bee0-85ab251dec86",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Let's evaluate the model by looking at its generated activity! Once again, we skip the training of the model and load a model that has been trained previously, for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc591d7-e210-4920-ac32-aee771ea1cc7",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Instantiate model\n",
    "input_size = 16 # Features + Go Cue\n",
    "hidden_size = 150\n",
    "output_size = 2  # Number of muscles\n",
    "g = 1.5  # g value\n",
    "h_val = 1.0  # h value\n",
    "\n",
    "regularized_model = RegularizedRNN(input_size, hidden_size, output_size, g, h_val)\n",
    "regularized_model.to(device)  # Move model to the appropriate device\n",
    "\n",
    "# Load the pretrained model\n",
    "model_path = 'regularized_model_final.pth'\n",
    "model_state_dict = torch.load(model_path, map_location=device)\n",
    "regularized_model.load_state_dict(model_state_dict)\n",
    "regularized_model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Example index\n",
    "idx = 0\n",
    "\n",
    "# Ensure data is on the correct device\n",
    "sample_input = normalised_inputs[train_idx[idx], ...].to(device)\n",
    "sample_target = outputs[train_idx[idx], ...].to(device)\n",
    "\n",
    "# Generate trajectory\n",
    "generated_target, hidden_states = generate_trajectory(regularized_model, sample_input.unsqueeze(0), device)\n",
    "\n",
    "# Plotting\n",
    "plot_inputs_over_time(times, sample_input.cpu())\n",
    "plot_muscles_over_time(times, sample_target.cpu(), 'Targets')\n",
    "plot_muscles_over_time(times, generated_target.squeeze().detach().cpu().numpy(), 'Generated')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5963c61d-96fe-4613-b6cb-466d9b38440f",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Looks promisingâ€“but how does the internal activity look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb65cba-8003-40e8-ae95-1401cfc6f5ca",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_Regularized_Model_Evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e85237-251e-4282-8442-5bad0793872d",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Activity 3.2: Comparing trained RNN with real data\n",
    "\n",
    "Let's see if this regularized network's activity is aligned with the brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d669ec7-9a47-450f-a4c9-080c1169833d",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "plot_hidden_unit_activations(hidden_states=hidden_states.squeeze().detach().cpu().numpy(),\n",
    "                             times=times,\n",
    "                             neurons_to_plot=10,\n",
    "                             title='PSTHs of Hidden Units in RegularizedRNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bd5cbe-6441-44a7-95e2-3f7c24da0949",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "plot_psth(data, neurons_to_plot=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b990c0a7-2eea-4445-bf33-74d4a45fa46f",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_Regularized_RNN_vs_Brain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445e313b-8209-4553-bd47-5ba6a331af17",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Discussion point\n",
    "\n",
    "1. Which one looks more like the brain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca1a56a-5269-4ad8-9263-065323ed0640",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_Discussion_Point\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99f992e-4379-40c6-af6d-8680595dfb01",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 4: A brain-like network\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', '45gbldrYfHo'), ('Bilibili', 'BV1er421c7Uu')]\n",
    "tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd7fb29-d7a8-424b-afc3-cbc9cabbd249",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_a_brain_like_network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e552086-0cbc-4f39-8e87-6bce1a05a43f",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Section 4: Robustness to change in RNNs and the brain\n",
    "\n",
    "In this section, we perturb our regularized and unregularized model's inputs and structural connectivity. Will regularization help the neural network be more resilient?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f917781-b109-4f70-8424-2d9647d20ec9",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Let's start with perturbing the inputs. For this purpose, we use the smaller train dataset without delay augmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750ee71a-25d9-4042-a0de-cc6db1c7bdde",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "test_dataset = TimeseriesDataset(normalised_inputs[train_idx], outputs[train_idx])\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ee0281-a790-4cce-b4f2-2bd0e8da93a6",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "def perturb_inputs(model, inputs, perturbation_strength):\n",
    "    device = inputs.device\n",
    "    # Perturb the inputs by adding random noise scaled by the perturbation strength and input strength\n",
    "    input_strength = torch.norm(inputs, p=2, dim=-1, keepdim=True)  # Calculate the L2 norm of inputs\n",
    "    noise = torch.rand(inputs.shape[0], 1, inputs.shape[2], device=device) * perturbation_strength * input_strength\n",
    "    perturbed_inputs = inputs + noise\n",
    "    return perturbed_inputs\n",
    "\n",
    "def compute_loss(model, inputs, targets, criterion, device):\n",
    "    batch_size = inputs.size(0)\n",
    "    h = model.init_hidden(batch_size).to(device)  # Initialize hidden state\n",
    "    losses = []\n",
    "    for t in range(inputs.shape[1]):  # Iterate over time steps\n",
    "        model_output = model(inputs[:, t, :], h)\n",
    "        output, h, *rest = model_output[:2]\n",
    "        loss = criterion(output, targets[:, t])  # Assume targets is a sequence of same length as inputs\n",
    "        losses.append(loss)\n",
    "    mean_loss = torch.mean(torch.stack(losses)).item()\n",
    "    return mean_loss\n",
    "\n",
    "def test_perturbed_inputs(model, perturbation_strengths, test_loader, criterion, device, max_error):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    perturbation_results = []\n",
    "\n",
    "    for strength in perturbation_strengths:\n",
    "        all_errors = []  # Store all errors for each perturbation strength to compute mean and s.d.\n",
    "        print(f\"Testing perturbation strength {strength}\")\n",
    "        for iteration in tqdm(range(30)):  # Repeat the procedure 30 times\n",
    "            batch_errors = []  # Store errors for each batch\n",
    "\n",
    "            for inputs, targets in test_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                # Compute error for original inputs\n",
    "                # original_loss = compute_loss(model, inputs, targets, criterion, device)\n",
    "                # Compute error for perturbed inputs\n",
    "\n",
    "                perturbed_inputs = perturb_inputs(model, inputs, strength)\n",
    "                perturbed_loss = compute_loss(model, perturbed_inputs, targets, criterion, device)\n",
    "\n",
    "                # Store the normalized error.\n",
    "                rel_error = perturbed_loss / max_error * 100\n",
    "                batch_errors.append(rel_error)\n",
    "\n",
    "            all_errors.extend(batch_errors)\n",
    "\n",
    "        mean_error = np.mean(all_errors)\n",
    "        std_error = np.std(all_errors)\n",
    "        perturbation_results.append((mean_error, std_error))\n",
    "        print(f\"Completed testing for perturbation strength {strength}.\")\n",
    "\n",
    "    return perturbation_results\n",
    "\n",
    "# Calculate the maximum error for a null model, the error when the output is constant.\n",
    "max_error = ((outputs - outputs.mean(axis=[0, 1], keepdims=True)) ** 2).mean()\n",
    "\n",
    "perturbation_strengths = [0.0125, 0.025, 0.05, 0.1, 0.2]\n",
    "results_unregularized = test_perturbed_inputs(unregularized_model, perturbation_strengths, test_loader, nn.MSELoss(), device, max_error)\n",
    "results_regularized = test_perturbed_inputs(regularized_model, perturbation_strengths, test_loader, nn.MSELoss(), device, max_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1268bf57-9f00-4acb-b181-f025c65b3b38",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#Plot perturbation results\n",
    "plot_perturbation_results(perturbation_strengths, results_regularized, results_unregularized, \"Perturbation of the inputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e354427f-f371-4fff-aecd-8c835e2a6c63",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now, we proceed to do the same with the weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b31e7ef-e4dc-472a-98f8-251f82a6b2ca",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding exercise 4.1: Weights perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043936ab-106f-49fa-98e0-68833273c903",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "def calculate_mean_absolute_strength(model):\n",
    "    # Calculate the mean absolute connection strength of the recurrent weight matrix\n",
    "    return torch.mean(torch.abs(model.J)).item()\n",
    "\n",
    "def perturb_recurrent_weights(model, mean_strength, perturbation_percentage):\n",
    "    ###########################################################\n",
    "    # Fill in the missing lines to complete the exercise\n",
    "    raise NotImplementedError(\"Student exercise\")\n",
    "    ###########################################################\n",
    "    perturbation_strength = ... * ...\n",
    "    with torch.no_grad():\n",
    "        noise = torch.randn_like(model.J) * perturbation_strength\n",
    "        perturbed_weights = model.J + noise\n",
    "        return perturbed_weights\n",
    "\n",
    "def test_perturbed_structure(model, perturbation_percentages, test_loader, criterion, device, max_error):\n",
    "    ###########################################################\n",
    "    # Fill in the missing lines to complete the exercise\n",
    "    raise NotImplementedError(\"Student exercise\")\n",
    "    ###########################################################\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    mean_strength = calculate_mean_absolute_strength(model)\n",
    "    perturbation_results = []  # List to store (mean error, std dev) tuples\n",
    "\n",
    "    original_weights = model.J.data.clone()  # Save the original weights\n",
    "\n",
    "    for percentage in ...:\n",
    "        multiple_perturbations_error = []\n",
    "        print(f\"Testing perturbation percentage {percentage:.4f}\")\n",
    "\n",
    "        for perturbation in tqdm(range(30)):  # Perturb 30 times for each strength\n",
    "            batch_errors = []\n",
    "            perturbed_weights = perturb_recurrent_weights(model, mean_strength, percentage)\n",
    "            model.J.data = perturbed_weights.data\n",
    "\n",
    "            for inputs, targets in test_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                batch_size = inputs.size(0)\n",
    "                h = model.init_hidden(batch_size).to(device)\n",
    "\n",
    "                outputs = torch.zeros_like(targets).to(device)\n",
    "                for t in range(inputs.shape[1]):\n",
    "                    output, h, *rest = ...\n",
    "                    outputs[:, t, :] = output\n",
    "\n",
    "                loss = criterion(outputs, targets).item()\n",
    "                batch_errors.append(loss)\n",
    "\n",
    "            # Reset to original weights after each perturbation\n",
    "            model.J.data = original_weights.data\n",
    "            multiple_perturbations_error.append(np.mean(batch_errors))\n",
    "\n",
    "        mean_error = np.mean(multiple_perturbations_error)  # Average over the 50 perturbations\n",
    "        std_dev_error = np.std(multiple_perturbations_error)  # Standard deviation for error bars\n",
    "        perturbation_results.append((100 * mean_error / max_error, 100 * std_dev_error / max_error))\n",
    "\n",
    "        # Normalize the errors\n",
    "        print(f\"Completed testing for perturbation percentage {percentage:.4f}. Mean error: {mean_error:.4f}, Std. dev.: {std_dev_error:.4f}\\n\")\n",
    "\n",
    "    return perturbation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb42315-b28f-4d77-a550-e2644f26c207",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/NeuroAI_Course/tree/main/tutorials/W1D1_Generalization/solutions/W1D1_Tutorial2_Solution_90edb742.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88117520-dcf8-4c8e-9874-2834ee451a1c",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Calculate the maximum error for a null model, the error when the output is constant.\n",
    "max_error = ((outputs - outputs.mean(axis=[0, 1], keepdims=True)) ** 2).mean()\n",
    "\n",
    "# Define perturbation strengths as percentages\n",
    "perturbation_strengths = [0.01, .1, .2, .4, .8]\n",
    "\n",
    "# Function calls for regularized and unregularized models\n",
    "results_regularized_weights = test_perturbed_structure(regularized_model, perturbation_strengths, test_loader, nn.MSELoss(), device, max_error)\n",
    "results_unregularized_weights = test_perturbed_structure(unregularized_model, perturbation_strengths, test_loader, nn.MSELoss(), device, max_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f40c9a9-3429-4b69-a693-5016c9c3319c",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Plot perturbation results\n",
    "plot_perturbation_results(perturbation_strengths, results_regularized_weights, results_unregularized_weights, \"Perturbation of the weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9218f3e2-9029-4317-a9ed-03bd3ea80f54",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_Weights_Perturbation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3447c1f5-31b2-4bce-ad0c-f4ce2e05f70b",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Discussion point 1\n",
    "\n",
    "Why is the regularized RNN more resistant to noise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8867a817-c05c-4a61-97d4-7cd8adb3e3ab",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_Discussion_Point_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcc771e-7e6a-4c83-a481-943e14e401bc",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Discussion point 2\n",
    "\n",
    "Is the regularized RNN â€œhow the brain worksâ€ in the motor cortex? If not, why is it useful to model this way? Does this experiment suggest that a system that can perform a task and generalize well is necessarily brain-like? If not, what else is required? Plasticity? Complex decision-making? Sensory integration? Agency? Autonomy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63306328-47a4-458e-9df1-b6341ede66c2",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_Discussion_Point_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d19e8b-6bd4-4f2b-8f8a-c699ac9e57ee",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 5: Final Thoughts\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', 'iIjGOqc8lLw'), ('Bilibili', 'BV1CS411P77f')]\n",
    "tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdcec9f-8918-4e51-a317-ab123e220f5c",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_final_thoughts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5a94df-de87-4e42-b65b-a292cfaad9b0",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Summary\n",
    "\n",
    "* Neuroscientists often aim to uncover *how* the brain performs a task.\n",
    "* Artificial neural networks are a useful tool for investigating how a computation might be performed.\n",
    "  * We often care about biological plausibility: the operations performed by the network should roughly match those that the brain can perform. For instance, while RNNs have been surpassed by transformers for natural language processing, they remain popular in neuroscience.\n",
    "* Neuroscientists often care about whether a model generalizes across circumstances that an organism might face.\n",
    "  * We tested robustness to noise (e.g. neural noise) and robustness to weight changes (e.g. rollover in synapses) across different models and found regularized models offered a useful **inductive bias** which generalized better.\n",
    "* The tools to improve generalization in task-driven neural networks are similar to the ones used in AI more generally: regularization, augmentations, but also potentially pretraining the model and transfer learning.\n",
    "* Networks that perform similar tasks to the brain and generalize well *sometimes* converge to similar solutions to the brain. We don't fully understand this phenomenon, and we'll introduce tools throughout the course to more quantitatively assess the correspondence."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "gpuType": "T4",
   "include_colab_link": true,
   "name": "W1D1_Tutorial2",
   "provenance": [],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
