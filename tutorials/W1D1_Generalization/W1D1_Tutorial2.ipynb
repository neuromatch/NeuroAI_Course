{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f1581e3-dc27-449d-8b2c-58ae24bec2e9",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Tutorial 2: Generalization in Neuroscience\n",
    "\n",
    "**Week 1, Day 1: Generalization**\n",
    "\n",
    "**By Neuromatch Academy**\n",
    "\n",
    "__Content creators:__ Names & Surnames\n",
    "\n",
    "__Content reviewers:__ Names & Surnames\n",
    "\n",
    "__Production editors:__ Names & Surnames\n",
    "\n",
    "<br>\n",
    "\n",
    "Acknowledgments: [ACKNOWLEDGMENT_INFORMATION]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d07f00-daee-4df0-940b-d240e335c3de",
   "metadata": {
    "execution": {}
   },
   "source": [
    "___\n",
    "\n",
    "\n",
    "# Tutorial Objectives\n",
    "\n",
    "*Estimated timing of tutorial: [insert estimated duration of whole tutorial in minutes]*\n",
    "\n",
    "By the end of this tutorial, participants will be able to:\n",
    "\n",
    "1. Understand core goals in neuroscience. Examine the fundamental questions that drive neuroscience research, such as the 'What', 'How', and particularly the 'Why' behind neurological functions and behaviors.\n",
    "\n",
    "2. Conceptualize generalization in neuroscience. Gain insights into what generalization entails within the field of neuroscience, understanding how principles of neural generalization can inform and be informed by artificial intelligence.\n",
    "\n",
    "3. Evaluate the impact of architectural choices. Discuss how different architectural decisions and the selection of priors in model design can introduce inductive biases, affecting the generalization capabilities of both neural and artificial systems.\n",
    "\n",
    "4. Illustrate robustness in noisy environments. Identify and describe real-world instances where the pursuit of robustness against noise has led to converging strategies in both neuroscience and artificial intelligence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b2bf54-2d06-44ac-929e-22e591de915e",
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Tutorial slides\n",
    "\n",
    "# @markdown These are the slides for the videos in all tutorials today\n",
    "\n",
    "\n",
    "## Uncomment the code below to test your function\n",
    "\n",
    "#from IPython.display import IFrame\n",
    "#link_id = \"<YOUR_LINK_ID_HERE>\"\n",
    "\n",
    "print(\"If you want to download the slides: 'Link to the slides'\")\n",
    "      # Example: https://osf.io/download/{link_id}/\n",
    "\n",
    "#IFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{link_id}/?direct%26mode=render\", width=854, height=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a35d5ac-7d05-4686-bf35-bde1bba0016a",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24296ef5-d8f9-438e-9574-08666be4cd5c",
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Install dependencies\n",
    "# @markdown\n",
    "\n",
    "#!pip install numpy scipy matplotlib torch tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa35e2b",
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Import dependencies\n",
    "# @markdown\n",
    "\n",
    "# Standard Libraries for file and operating system operations, security, and web requests\n",
    "import os\n",
    "import hashlib\n",
    "import requests\n",
    "import random\n",
    "import gc\n",
    "\n",
    "# Core Python data science and visualization libraries\n",
    "import numpy as np\n",
    "import scipy\n",
    "from matplotlib import pyplot as plt\n",
    "import logging\n",
    "\n",
    "# Deep Learning libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, TensorDataset\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.autograd import profiler\n",
    "\n",
    "# Additional utilities\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2af95e4-b42d-4e65-afff-d77470f1716d",
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Figure settings\n",
    "# @markdown\n",
    "\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' # perform high definition rendering for images and plots\n",
    "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/nma.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bf7d34-d33a-4683-88e8-b27ae830ef73",
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Plotting functions\n",
    "# @markdown\n",
    "\n",
    "def plot_inputs_over_time(timesteps, avg_inputs):\n",
    "\n",
    "    \"\"\"\n",
    "    Plot the average inputs over time to visualize changes in input values.\n",
    "\n",
    "    Inputs:\n",
    "    - timesteps (list or array-like): A sequence of time steps at which the inputs were recorded.\n",
    "      This acts as the x-axis in the plot, representing the progression of time.\n",
    "    - avg_inputs (list or array-like): The average values of inputs corresponding to each time step.\n",
    "      These values are plotted on the y-axis, showing the magnitude of inputs over time.\n",
    "\n",
    "    Returns:\n",
    "    This function generates and displays a plot using Matplotlib.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Assuming avg_inputs is a 2D array-like structure where each column is a feature\n",
    "    num_features = avg_inputs.shape[1] if hasattr(avg_inputs, 'shape') else len(avg_inputs[0])\n",
    "\n",
    "    for feature_idx in range(num_features):\n",
    "        # Extract the current feature across all timesteps\n",
    "        current_feature_values = avg_inputs[:, feature_idx] if hasattr(avg_inputs, 'shape') else [row[feature_idx] for row in avg_inputs]\n",
    "\n",
    "        # Plot the current feature\n",
    "        plt.plot(timesteps, current_feature_values, label=f'Feature {feature_idx + 1}')\n",
    "\n",
    "    plt.title('Inputs over Time')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Average Value')\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.2, 1.1), ncol=2)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_muscles_over_time(timesteps, avg_output):\n",
    "\n",
    "    \"\"\"\n",
    "    Plot the average outputs over time to visualize changes in output values.\n",
    "\n",
    "    Inputs:\n",
    "    - timesteps (list or array-like): A sequence of time steps at which the outputs were recorded.\n",
    "      This acts as the x-axis in the plot, representing the progression of time.\n",
    "    - avg_outputs (list or array-like): The average values of outputs corresponding to each time step.\n",
    "      These values are plotted on the y-axis, showing the magnitude of outputs over time.\n",
    "\n",
    "    Returns:\n",
    "    This function generates and displays a plot using Matplotlib.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(timesteps, avg_output, label='Muscle')\n",
    "    plt.title('Muscles over Time')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Average Value')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_training_validation_losses(epoch_losses, val_losses, actual_num_epochs, title):\n",
    "\n",
    "    \"\"\"\n",
    "    This function plots the training and validation losses over epochs.\n",
    "\n",
    "    Inputs:\n",
    "    - epoch_losses (list of float): List containing the training loss for each epoch. Each element is a float\n",
    "      representing the loss calculated after each epoch of training.\n",
    "    - val_losses (list of float): List containing the validation loss for each epoch. Similar to `epoch_losses`, but\n",
    "      for the validation set, allowing for the comparison between training and validation performance.\n",
    "    - actual_num_epochs (int): The actual number of epochs the training went through. This could be different from\n",
    "      the initially set number of epochs if early stopping was employed. It determines the range of the x-axis\n",
    "      in the plot.\n",
    "    - title (str): A string that sets the title of the plot. This allows for customization of the plot for better\n",
    "      readability and interpretation.\n",
    "\n",
    "    Outputs:\n",
    "    This function generates and displays a plot using matplotlib.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, actual_num_epochs + 1), epoch_losses, label='Training Loss')\n",
    "    plt.plot(range(1, actual_num_epochs + 1), val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_psth(data, title, bin_size=10):\n",
    "    \"\"\"\n",
    "    This function takes neural data, averages it across conditions\n",
    "    and time delays for each time bin, and plots the averaged neural activity for each feature\n",
    "    across time bins.\n",
    "\n",
    "    Args:\n",
    "        data (Tensor): A 4D tensor containing the neural data with dimensions corresponding to\n",
    "                       [conditions, delays, time, features].\n",
    "        title (str): The title for the PSTH plot. This allows users to specify the context or the\n",
    "                     experiment from which the data is derived.\n",
    "        bin_size (int, optional): The size of the time bins in units of the 'time' dimension. This\n",
    "                                  parameter allows the user to specify how much temporal data should\n",
    "                                  be averaged together to calculate the mean activity. Default is 10.\n",
    "\n",
    "    Outputs:\n",
    "    This function directly generates and displays a plot using matplotlib\n",
    "    to visually represent the averaged neural activity across time bins for each feature.\n",
    "    \"\"\"\n",
    "    # Averaging neural activity across conditions, delays for each time bin\n",
    "    mean_data = data.mean(dim=(0, 1))  # Mean across conditions and delays\n",
    "\n",
    "    # Number of bins\n",
    "    n_bins = mean_data.shape[0] // bin_size\n",
    "\n",
    "    # Prepare the data for plotting\n",
    "    binned_data = mean_data[:n_bins*bin_size].unfold(0, bin_size, bin_size).mean(dim=2)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(binned_data.shape[1]):  # Iterate over each feature/channel\n",
    "        plt.plot(binned_data[:, i], label=f'Feature {i+1}')\n",
    "    plt.xlabel('Time (bins)')\n",
    "    plt.ylabel('Average Activity')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_hidden_unit_activations(hidden_states, timesteps, neurons_to_plot=5, title='PSTHs of Hidden Units'):\n",
    "    \"\"\"\n",
    "    This function plots the average activation of a specified number of neurons from the hidden layers\n",
    "    of a neural network over a certain number of timesteps.\n",
    "\n",
    "    Inputs:\n",
    "        hidden_states (np.ndarray): A 3D numpy array containing the hidden states of a network. The dimensions\n",
    "                                     should be (time, batch, features), where 'time' represents the sequence of\n",
    "                                     timesteps, 'batch' represents different data samples, and 'features' represents\n",
    "                                     the neuron activations or features at each timestep.\n",
    "        timesteps (int): The number of timesteps to consider from the end of the hidden states array. This allows\n",
    "                         focusing on the recent activity by looking at the last 'timesteps' number of steps.\n",
    "        neurons_to_plot (int, optional): The number of neuron activations to plot, starting from the first neuron.\n",
    "                                         Defaults to 5.\n",
    "        title (str, optional): The title of the plot, allowing customization for specific analyses or presentations.\n",
    "                               Defaults to 'PSTHs of Hidden Units'.\n",
    "\n",
    "    This function generates and displays a plot of the average activation of specified\n",
    "    neurons over the selected timesteps, providing a visual analysis of neuron behavior within the network.\n",
    "    \"\"\"\n",
    "    # Slicing to take only the last 'timesteps' timesteps\n",
    "    last_hidden_states = hidden_states[-timesteps:]\n",
    "\n",
    "    # Apply the nonlinearity to each hidden state before averaging\n",
    "    rectified_tanh = lambda x: np.where(x > 0, np.tanh(x), 0)\n",
    "    hidden_states_rectified = rectified_tanh(np.array(last_hidden_states))\n",
    "\n",
    "    # Calculate the mean across all batches for each time step\n",
    "    mean_activations = np.mean(hidden_states_rectified, axis=1)\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for i in range(min(neurons_to_plot, hidden_states_rectified.shape[2])):\n",
    "        plt.plot(range(timesteps), mean_activations[:, i], label=f'Neuron {i+1}')\n",
    "\n",
    "    plt.xlabel('Time Steps')\n",
    "    plt.ylabel('Average Activation')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_perturbation_results(perturbation_strengths, results_simple, results_complex, title):\n",
    "    \"\"\"\n",
    "    This function plots the normalized error percentages of two models (simple and complex) under various\n",
    "    perturbation strengths.\n",
    "\n",
    "    Inputs:\n",
    "        perturbation_strengths (list of float): A list of perturbation strengths tested, representing the\n",
    "                                                 magnitude of perturbations applied to the model input or parameters.\n",
    "        results_simple (list of tuples): Each tuple contains (mean error, standard deviation) for the simple model\n",
    "                                         at each perturbation strength.\n",
    "        results_complex (list of tuples): Each tuple contains (mean error, standard deviation) for the complex model\n",
    "                                          at each perturbation strength.\n",
    "        title (str): The title of the plot, allowing for customization to reflect the analysis context.\n",
    "\n",
    "    The function generates and displays a bar plot comparing the normalized error\n",
    "    rates of simple and complex models under different perturbation strengths, with error bars representing the\n",
    "    standard deviation of errors, normalized to percentage scale.\n",
    "    \"\"\"\n",
    "    mean_errors_simple, std_errors_simple = zip(*results_simple)\n",
    "    mean_errors_complex, std_errors_complex = zip(*results_complex)\n",
    "\n",
    "    # Normalizing errors and standard deviations\n",
    "    max_error_simple = max(mean_errors_simple)\n",
    "    max_error_complex = max(mean_errors_complex)\n",
    "\n",
    "    print(\"mean_errors_simple\", mean_errors_simple)\n",
    "    print(\"mean_errors_complex\", mean_errors_complex)\n",
    "\n",
    "    normalized_mean_errors_simple = [(x / max_error_simple) * 100 for x in mean_errors_simple]\n",
    "    normalized_std_errors_simple = [(y / max_error_simple) * 100 for y in std_errors_simple]\n",
    "\n",
    "    normalized_mean_errors_complex = [(x / max_error_complex) * 100 for x in mean_errors_complex]\n",
    "    normalized_std_errors_complex = [(y / max_error_complex) * 100 for y in std_errors_complex]\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    bar_width = 0.35\n",
    "    bar_positions = np.arange(len(perturbation_strengths))\n",
    "\n",
    "    plt.bar(bar_positions - bar_width/2, normalized_mean_errors_simple, width=bar_width, color='blue', yerr=normalized_std_errors_simple, capsize=5, label='Simple Model')\n",
    "    plt.bar(bar_positions + bar_width/2, normalized_mean_errors_complex, width=bar_width, color='red', yerr=normalized_std_errors_complex, capsize=5, label='Complex Model')\n",
    "\n",
    "    plt.xlabel('Perturbation Magnitude')\n",
    "    plt.ylabel('Normalized Error (%)')\n",
    "    plt.title(title)\n",
    "    plt.xticks(bar_positions, [f\"{x:.5f}\" if x < 0.1 else f\"{x}\" for x in perturbation_strengths])\n",
    "    plt.legend()\n",
    "    plt.ylim(0, 100)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70b8e4b-f2ca-42af-bcd1-27fb6cecbc30",
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Set device (GPU or CPU). Execute `set_device()`\n",
    "# especially if torch modules used.\n",
    "# @markdown\n",
    "\n",
    "# inform the user if the notebook uses GPU or CPU.\n",
    "\n",
    "def set_device():\n",
    "    \"\"\"\n",
    "    Determines and sets the computational device for PyTorch operations based on the availability of a CUDA-capable GPU.\n",
    "\n",
    "    Outputs:\n",
    "    - device (str): The device that PyTorch will use for computations ('cuda' or 'cpu'). This string can be directly used\n",
    "    in PyTorch operations to specify the device.\n",
    "    \"\"\"\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    if device != \"cuda\":\n",
    "        print(\"GPU is not enabled in this notebook. \\n\"\n",
    "              \"If you want to enable it, in the menu under `Runtime` -> \\n\"\n",
    "              \"`Hardware accelerator.` and select `GPU` from the dropdown menu\")\n",
    "    else:\n",
    "        print(\"GPU is enabled in this notebook. \\n\"\n",
    "              \"If you want to disable it, in the menu under `Runtime` -> \\n\"\n",
    "              \"`Hardware accelerator.` and select `None` from the dropdown menu\")\n",
    "\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654e7c22-bd2a-4a6e-867e-462646e3b496",
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Set random seed, when using `pytorch`\n",
    "\n",
    "# @markdown Executing `set_seed(seed=seed)` you are setting the seed\n",
    "\n",
    "# Call `set_seed` function in the exercises to ensure reproducibility.\n",
    "\n",
    "def set_seed(seed=None, seed_torch=True):\n",
    "  if seed is None:\n",
    "    seed = np.random.choice(2 ** 32)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  if seed_torch:\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "  print(f'Random seed {seed} has been set.')\n",
    "\n",
    "# In case that `DataLoader` is used\n",
    "def seed_worker(worker_id):\n",
    "  worker_seed = torch.initial_seed() % 2**32\n",
    "  np.random.seed(worker_seed)\n",
    "  random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fea2ec-e1ee-4ebe-9dff-d3b253c3ba0b",
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title Data retrieval\n",
    "# @markdown\n",
    "\n",
    "# Variables for file and download URL\n",
    "fname = \"condsForSimJ2moMuscles.mat\"  # The name of the file to be downloaded\n",
    "url = \"https://osf.io/wak7e/download\" # URL from where the file will be downloaded\n",
    "expected_md5 = \"257d16c4d92759d615bf5cac75dd9a1f\" # MD5 hash for verifying file integrity\n",
    "\n",
    "# Check if the file already exists\n",
    "if not os.path.isfile(fname):\n",
    "    try:\n",
    "        # Attempt to download the file\n",
    "        r = requests.get(url) # Make a GET request to the specified URL\n",
    "    except requests.ConnectionError:\n",
    "        # Handle connection errors during the download\n",
    "        print(\"!!! Failed to download data !!!\")\n",
    "    else:\n",
    "        # No connection errors, proceed to check the response\n",
    "        if r.status_code != requests.codes.ok:\n",
    "            # Check if the HTTP response status code indicates a successful download\n",
    "            print(\"!!! Failed to download data !!!\")\n",
    "        elif hashlib.md5(r.content).hexdigest() != expected_md5:\n",
    "            # Verify the integrity of the downloaded file using MD5 checksum\n",
    "            print(\"!!! Data download appears corrupted !!!\")\n",
    "        else:\n",
    "            # If download is successful and data is not corrupted, save the file\n",
    "            with open(fname, \"wb\") as fid:\n",
    "                fid.write(r.content) # Write the downloaded content to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b2b4f7-14f6-4374-a8a4-a17799d1f787",
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title Helper functions\n",
    "# @markdown\n",
    "\n",
    "# Define a custom Rectified Tanh activation function\n",
    "def rectified_tanh(x):\n",
    "    return torch.where(x > 0, torch.tanh(x), 0)\n",
    "    \n",
    "def grad_rectified_tanh(x):\n",
    "    return torch.where(x > 0, 1 - torch.tanh(x)**2, 0)\n",
    "    \n",
    "def grad_tanh(x):\n",
    "    return 1 - torch.tanh(x)**2\n",
    "    \n",
    "def compute_l2_regularization(parameters, alpha):\n",
    "    l2_reg = sum(p.pow(2.0).sum() for p in parameters)\n",
    "    return alpha * l2_reg\n",
    "\n",
    "def prepare_dataset(file_path, feature_idx=7, muscle_idx=1):\n",
    "    \"\"\"\n",
    "    Load and preprocess data from a .mat file for RNN training.\n",
    "\n",
    "    Args:\n",
    "    - file_path: str, path to the .mat file containing the dataset.\n",
    "    - feature_idx: int, index for individual features for plotting. Max 14.\n",
    "    - muscle_idx: int, index for muscles for plotting. Max 1.\n",
    "\n",
    "    Returns:\n",
    "    - normalised_inputs: Tensor, normalized and concatenated Plan and Go Envelope tensors.\n",
    "    - avg_output: Tensor, average muscle activity across conditions and delays.\n",
    "    - timesteps: np.ndarray, array of time steps for plotting.\n",
    "    \"\"\"\n",
    "    # Load the .mat file\n",
    "    data = scipy.io.loadmat(file_path)\n",
    "\n",
    "    # Extract condsForSim struct\n",
    "    conds_for_sim = data['condsForSim']\n",
    "\n",
    "    # Initialize lists to store data for all conditions\n",
    "    go_envelope_all, plan_all, muscle_all = [], [], []\n",
    "\n",
    "    # Get the number of conditions (rows) and delay durations (columns)\n",
    "    num_conditions, num_delays = conds_for_sim.shape\n",
    "\n",
    "    for i in range(num_conditions):  # Loop through each condition\n",
    "        go_envelope_condition, plan_condition, muscle_condition = [], [], []\n",
    "\n",
    "        for j in range(num_delays):  # Loop through each delay duration\n",
    "            condition = conds_for_sim[i, j]\n",
    "            go_envelope, plan, muscle = condition['goEnvelope'], condition['plan'], condition['muscle']\n",
    "            selected_muscle_data = muscle[:, [3, 4]]  # Select only specific muscles\n",
    "            go_envelope_condition.append(go_envelope)\n",
    "            plan_condition.append(plan)\n",
    "            muscle_condition.append(selected_muscle_data)\n",
    "\n",
    "        # Convert lists of arrays to tensors and append to all conditions\n",
    "        go_envelope_all.append(torch.tensor(np.array(go_envelope_condition), dtype=torch.float32))\n",
    "        plan_all.append(torch.tensor(np.array(plan_condition), dtype=torch.float32))\n",
    "        muscle_all.append(torch.tensor(np.array(muscle_condition), dtype=torch.float32))\n",
    "\n",
    "    # Stack tensors for all conditions\n",
    "    go_envelope_tensor, plan_tensor, output = torch.stack(go_envelope_all), torch.stack(plan_all), torch.stack(muscle_all)\n",
    "\n",
    "    # Cleanup to free memory\n",
    "    del data, conds_for_sim, go_envelope_all, plan_all, muscle_all\n",
    "    gc.collect()\n",
    "\n",
    "    # Normalize and Standardize Plan Tensor\n",
    "    plan_tensor = normalize_and_standardize(plan_tensor)\n",
    "\n",
    "    # Normalise and concatenate Plan and Go Envelope Tensors\n",
    "    normalised_inputs = normalize_and_standardize(torch.cat([plan_tensor, go_envelope_tensor], dim=3))\n",
    "\n",
    "    return normalised_inputs, output, num_conditions, num_delays\n",
    "\n",
    "def normalize_and_standardize(tensor):\n",
    "    \"\"\"\n",
    "    Normalize and standardize a given tensor.\n",
    "\n",
    "    Args:\n",
    "    - tensor: Tensor, the tensor to be normalized and standardized.\n",
    "\n",
    "    Returns:\n",
    "    - standardized_normalized_tensor: Tensor, the normalized and standardized tensor.\n",
    "    \"\"\"\n",
    "    min_val, max_val = tensor.min(), tensor.max()\n",
    "    tensor = (tensor - min_val) / (max_val - min_val)  # Normalize\n",
    "    mean, std = tensor.mean(), tensor.std()\n",
    "    return (tensor - mean) / std  # Standardize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0f7855-566e-4a50-82ae-6b188c74c4cf",
   "metadata": {},
   "source": [
    "## Video and background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c73af28-ab4e-4809-bfd7-b0c15d678f5d",
   "metadata": {},
   "source": [
    "### Missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76206fc7-b2a7-4598-9c4c-450b138e9f5a",
   "metadata": {},
   "source": [
    "In the provided script, we begin with a discussion on generalization and regularization in artificial neural networks (ANNs), drawing parallels to the adaptability and plasticity observed in biological neural networks. ANNs, such as recurrent neural networks (RNNs), mimic this adaptability through interconnected artificial neurons, weights dictating connection strengths, and activation functions triggering neuron responses.\n",
    "\n",
    "## Generalization and Regularization in ANNs\n",
    "\n",
    "Generalization enables the brain to adapt to both external and internal changes. Artificial Neural Networks (ANNs), inspired by the human brain, embody this adaptability through interconnected artificial neurons that process and transmit information. In ANNs, learning occurs through the adjustment of connection weights, akin to the brain's synaptic plasticity, which is crucial for generalizing to new scenarios. Inductive biases in these networks facilitate predictions on unseen data, underscoring their importance for effective generalization. Task-specific networks further illustrate the significance of these biases, offering insights into both artificial and biological intelligence.\n",
    "\n",
    "However, while generalization allows a model to adapt to new data, regularization is essential for preventing overfitting by limiting model complexity. For example, a Regularized Recurrent Neural Network (SimpleRNN) can find solutions efficiently, mirroring the brain's adaptability. In contrast, an RNN without regularization (ComplicatedRNN) may overfit, losing its ability to generalize. This underscores the importance of regularization in making ANNs resemble human neural processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c38e8e-55f6-4d83-a863-819174b38d7c",
   "metadata": {},
   "source": [
    "## Activity 1: Training RNNs to generate a full sequence of arm movements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efadda69-d5fe-4fc8-9bc9-bdc982b7f7de",
   "metadata": {
    "execution": {}
   },
   "source": [
    "In this activity, our goal is to train recurrent neural networks to mimic the muscle activity of monkeys during arm movements. The challenge is to transform simple inputs into complex patterns of muscle activity over time and space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc16cdcf-d366-452c-ac7d-4fd11221a717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the dataset file containing conditions for simulation of muscles\n",
    "file_path = 'condsForSimJ2moMuscles.mat'\n",
    "\n",
    "# Prepare the dataset by loading and processing it from the specified file path\n",
    "normalised_inputs, output, num_conditions, num_delays = prepare_dataset(file_path)\n",
    "\n",
    "print(\"Shape of the inputs\", normalised_inputs.shape)\n",
    "print(\"Shape of the output\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeb718b-f138-463a-bcfb-64fbf6d5c101",
   "metadata": {},
   "source": [
    "Upon loading and processing the dataset, we observe the data structure: 27 conditions (different reaches), 8 delay durations, 296 time steps, and for inputs, 16 features including the go cue. For outputs, 2 features correspond to target Electromyography (EMG) data for two muscles. Now, let's visualize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd6d286-fc8b-4b1c-babe-c58279781637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaging across conditions and delays\n",
    "avg_inputs = normalised_inputs.mean(dim=[0, 1]).squeeze()\n",
    "avg_output = output.mean(dim=[0, 1])\n",
    "\n",
    "# Time steps\n",
    "timesteps = np.arange(296)\n",
    "avg_inputs[:, -1] *= 20\n",
    "\n",
    "#Plot inputs and outputs\n",
    "plot_inputs_over_time(timesteps, avg_inputs)\n",
    "plot_muscles_over_time(timesteps, avg_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dd6ea9-237c-455b-b003-ccd09a836c94",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Importantly, the regularized models employ multiple delays between the onset of the preparatory input and the onset of the hold cue. This feature was added to avoid concerns about implicit time locking of model activity to the beginning of the simulation, and to ensure that the model was in fact producing EMG in response to the offset of the hold cue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cde5eda-c684-4d3f-87a7-e60a19f8955d",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_inputs = normalised_inputs.view(-1, *normalised_inputs.shape[2:])\n",
    "flattened_targets = output.view(-1, *output.shape[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6486d0cc-32bf-4849-a027-66e9b24b0f08",
   "metadata": {},
   "source": [
    "Now, it's time to build two datasets. Let's start with the one for SimpleRNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aec07a1-d43a-4ba4-ac21-3bb34a35490c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTimeseriesDataset(Dataset):\n",
    "    def __init__(self, inputs, targets):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        print(\"Shape of inputs - SimpleRNN\", self.inputs.shape)\n",
    "        print(\"Shape of targets - SimpleRNN\", self.targets.shape)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.inputs.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_seq = self.inputs[idx]\n",
    "        target_seq = self.targets[idx]\n",
    "        return input_seq, target_seq\n",
    "\n",
    "# Create the SimpleRNN dataset\n",
    "simple_dataset = SimpleTimeseriesDataset(flattened_inputs, flattened_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ac6883-40d7-4426-9949-e30f0e404e86",
   "metadata": {},
   "source": [
    "We split the dataset in training, validation and test sets. Then, we create the DataLoaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46473b52-f2c3-414b-811b-0c882afacc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "simple_train_size = int(0.6 * len(simple_dataset))\n",
    "simple_val_size = int(0.2 * len(simple_dataset))\n",
    "simple_test_size = len(simple_dataset) - simple_train_size - simple_val_size\n",
    "\n",
    "simple_train_dataset, simple_val_dataset, simple_test_dataset = random_split(simple_dataset, [simple_train_size, simple_val_size, simple_test_size])\n",
    "\n",
    "batch_size = 31\n",
    "\n",
    "# Create DataLoaders\n",
    "simple_train_loader = DataLoader(simple_train_dataset, batch_size=batch_size, shuffle=True, worker_init_fn=seed_worker)\n",
    "simple_val_loader = DataLoader(simple_val_dataset, batch_size=batch_size, shuffle=False, worker_init_fn=seed_worker)\n",
    "simple_test_loader = DataLoader(simple_test_dataset, batch_size=batch_size, shuffle=False, worker_init_fn=seed_worker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbae53e-d84c-4a08-b4df-962aadc49874",
   "metadata": {},
   "source": [
    "Same procedure for ComplicatedRNN. The only difference is that the shape is going to be different: there are no multiple delays. For this reason, we choose a fixed delay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417463ca-29c8-4229-baed-58dcf390747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplicatedTimeseriesDataset(Dataset):\n",
    "    def __init__(self, inputs, targets, delay_idx):\n",
    "        \"\"\"\n",
    "        inputs: Tensor of shape [27, 8, 296, input_features]\n",
    "        targets: Tensor of shape [27, 8, 296, output_features]\n",
    "        delay_idx: Fixed index of the delay to be used\n",
    "        \"\"\"\n",
    "        self.inputs = inputs[:, delay_idx]\n",
    "        self.targets = targets[:, delay_idx]\n",
    "        self.num_conditions = inputs.shape[0]\n",
    "\n",
    "        print(\"Shape of inputs - ComplicatedRNN\", self.inputs.shape)\n",
    "        print(\"Shape of targets - ComplicatedRNN\", self.targets.shape)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_conditions\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_seq = self.inputs[idx]\n",
    "        target_seq = self.targets[idx]\n",
    "        return input_seq, target_seq\n",
    "\n",
    "# Choose the delay index\n",
    "fixed_delay_idx = 3\n",
    "\n",
    "# Create the dataset with the fixed delay\n",
    "complicated_dataset = ComplicatedTimeseriesDataset(normalised_inputs, output, fixed_delay_idx)\n",
    "\n",
    "# Split the dataset\n",
    "train_size = int(0.6 * len(complicated_dataset))\n",
    "val_size = int(0.2 * len(complicated_dataset))\n",
    "test_size = len(complicated_dataset) - train_size - val_size\n",
    "\n",
    "complicated_train_dataset, complicated_val_dataset, complicated_test_dataset = random_split(complicated_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 1\n",
    "complicated_train_loader = DataLoader(complicated_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "complicated_val_loader = DataLoader(complicated_val_dataset, batch_size=batch_size, shuffle=False)\n",
    "complicated_test_loader = DataLoader(complicated_test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd4f116-09e9-4392-9ea4-1c0cd78be2d0",
   "metadata": {},
   "source": [
    "Before we start training, we also need two functions to validate and to test the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c841c9a-27b3-414d-b406-56547c285e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, val_loader, criterion, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_val_loss = 0.0\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            batch_size = inputs.size(0)\n",
    "            h = model.init_hidden(batch_size).to(device)\n",
    "\n",
    "            for t in range(inputs.shape[1]):\n",
    "                # Capture any additional outputs in 'rest'\n",
    "                output, h, *rest = model(inputs[:, t, :], h)\n",
    "\n",
    "            loss = criterion(output, targets[:, -1, :])\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    return avg_val_loss\n",
    "\n",
    "def test_model(model, test_loader, criterion, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_test_loss = 0.0\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            batch_size = inputs.size(0)\n",
    "            h = model.init_hidden(batch_size).to(device)\n",
    "\n",
    "            for t in range(inputs.shape[1]):\n",
    "                # Capture any additional outputs in 'rest'\n",
    "                output, h, *rest = model(inputs[:, t, :], h)\n",
    "\n",
    "            loss = criterion(output, targets[:, -1, :])\n",
    "            total_test_loss += loss.item()\n",
    "\n",
    "    avg_test_loss = total_test_loss / len(test_loader)\n",
    "    return avg_test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310988a8-f180-4d32-aa11-f7ffde276055",
   "metadata": {},
   "source": [
    "Now we're ready to start training. We will start with SimpleRNN.\n",
    "\n",
    "The crucial aspect you have to notice is that it is heavily regularized to encourage extremely simple solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2b6a95-49a0-4f10-8f63-3b85a7f7d7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, g, h, tau=50):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.tau = tau  # Time constant\n",
    "        self.output_linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        # Weight initialization\n",
    "        self.J = nn.Parameter(torch.randn(hidden_size, hidden_size) * (g / torch.sqrt(torch.tensor(hidden_size, dtype=torch.float))))\n",
    "        self.B = nn.Parameter(torch.randn(hidden_size, input_size) * (h / torch.sqrt(torch.tensor(input_size, dtype=torch.float))))\n",
    "        self.bx = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "        # Nonlinearity\n",
    "        self.nonlinearity = rectified_tanh\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        hidden_prev = hidden.clone()\n",
    "        timestep = self.tau / 10  # Timestep for Euler integration\n",
    "        # Update hidden state\n",
    "        firing_rate = self.nonlinearity(hidden)\n",
    "        hidden_update = torch.matmul(self.J, firing_rate.transpose(0, 1))\n",
    "        input_update = torch.matmul(self.B, x.transpose(0, 1))\n",
    "        new_hidden = hidden_update + input_update + self.bx.unsqueeze(1)\n",
    "        new_hidden = new_hidden.transpose(0, 1)\n",
    "        # Euler integration for continuous-time update\n",
    "        hidden = hidden + (timestep / self.tau) * (-hidden_prev + new_hidden)\n",
    "        # Output calculation\n",
    "        output = self.output_linear(firing_rate)\n",
    "        # Regularization terms\n",
    "        firing_rate_reg = hidden.pow(2).sum()\n",
    "        dynamic_reg = torch.linalg.norm(torch.matmul(self.J, grad_rectified_tanh(hidden.transpose(0, 1))), ord='fro', dim=(-2, -1)).sum()\n",
    "\n",
    "        return output, hidden, firing_rate_reg, dynamic_reg\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # Initialize hidden state with batch dimension\n",
    "        return torch.zeros(batch_size, self.hidden_size)\n",
    "        \n",
    "# Hyperparameters\n",
    "input_size = 16 # Features + Go Cue\n",
    "hidden_size = 150\n",
    "output_size = 2  # Number of muscles\n",
    "g = 1.5  # g value\n",
    "h_val = 1.0  # h value\n",
    "\n",
    "# Hyperparameters for regularization\n",
    "alpha = 1e-5\n",
    "beta = 0.003\n",
    "gamma = 1e-6\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 100\n",
    "epoch_losses = []\n",
    "val_losses = []\n",
    "\n",
    "patience = 10  # Number of epochs to wait for improvement\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "early_stop = False\n",
    "\n",
    "# get available device\n",
    "device = set_device()\n",
    "\n",
    "# Model instantiation\n",
    "set_seed(seed=2024)\n",
    "model = SimpleRNN(input_size, hidden_size, output_size, g, h_val)\n",
    "model.to(device)\n",
    "\n",
    "# Loss Function and Optimizer\n",
    "criterion = nn.MSELoss()  # MSE Loss for regression tasks\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0)\n",
    "scaler = GradScaler()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    model.train()  # Set the model to training mode\n",
    "\n",
    "    # Initialize hidden states\n",
    "    hidden_states_for_plot = []\n",
    "\n",
    "    for inputs, targets in simple_train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        batch_size = inputs.size(0)\n",
    "        h = model.init_hidden(batch_size).to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_firing_rate_reg = 0\n",
    "        total_dynamic_reg = 0\n",
    "\n",
    "        with autocast():  # Enable automatic mixed precision\n",
    "            for t in range(inputs.shape[1]):\n",
    "                output, h, firing_rate_reg, dynamic_reg = model(inputs[:, t, :], h)\n",
    "                hidden_states_for_plot.append(h.detach().cpu().numpy())\n",
    "                total_firing_rate_reg += firing_rate_reg\n",
    "                total_dynamic_reg += dynamic_reg\n",
    "\n",
    "            # Compute loss and regularization terms\n",
    "            loss = criterion(output, targets[:, -1, :])\n",
    "            l2_reg = compute_l2_regularization(model.parameters(), alpha)\n",
    "            rfr_reg = beta * total_firing_rate_reg / inputs.shape[1] / hidden_size / num_conditions #CNT - C is 27 conditions, N is 300 neurons and T is 296 timesteps\n",
    "            rj_reg = gamma * total_dynamic_reg / inputs.shape[1] / num_conditions #CT\n",
    "            total_loss = loss + l2_reg + rfr_reg + rj_reg\n",
    "\n",
    "        scaler.scale(total_loss).backward()  # Scale loss and perform backward pass\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        scaler.step(optimizer)  # Update optimizer\n",
    "        scaler.update()  # Update scaler\n",
    "\n",
    "        running_loss += total_loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(simple_train_loader)\n",
    "    epoch_losses.append(avg_loss)\n",
    "    print(f'Epoch {epoch + 1}, Training Loss: {avg_loss}')\n",
    "\n",
    "    # Validation phase after completing the training for one epoch\n",
    "    val_loss = validate_model(model, simple_val_loader, criterion, device)\n",
    "    val_losses.append(val_loss)\n",
    "    print(f'Epoch {epoch + 1}, Validation Loss: {val_loss}')\n",
    "\n",
    "    # Early stopping check\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(\"Early stopping triggered at epoch\", epoch + 1)\n",
    "        early_stop = True\n",
    "        break\n",
    "\n",
    "    # Clear CUDA cache if needed\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# Check if training was stopped by early stopping\n",
    "if early_stop:\n",
    "    print('Training stopped due to early stopping at epoch', epoch + 1)\n",
    "else:\n",
    "    print('Finished Training')\n",
    "\n",
    "# Testing phase\n",
    "test_loss = test_model(model, simple_test_loader, criterion, device)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "\n",
    "# Clear cache after training\n",
    "if device == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Determine the number of epochs for which you have loss data\n",
    "actual_num_epochs = len(epoch_losses)  # This will be less than num_epochs if early stopping was triggered\n",
    "\n",
    "# Call the plotting function\n",
    "plot_training_validation_losses(epoch_losses, val_losses, actual_num_epochs, \"SimpleRNN: Training and Validation Losses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8489c2-0463-48b8-a7bf-c34a851d2bc5",
   "metadata": {},
   "source": [
    "Training is done. Let's now do the same with ComplicatedRNN! The regularization is absent here: this will lead to interesting results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dd9a5b-0e80-4464-aa8e-9ec54d225646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ComplicatedRNN class\n",
    "class ComplicatedRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, g, h, tau=50):\n",
    "        super(ComplicatedRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.tau = tau\n",
    "        self.output_linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        # Weight initialization (unchanged)\n",
    "        self.J = nn.Parameter(torch.randn(hidden_size, hidden_size) * (g / torch.sqrt(torch.tensor(hidden_size, dtype=torch.float))))\n",
    "        self.B = nn.Parameter(torch.randn(hidden_size, input_size) * (h / torch.sqrt(torch.tensor(input_size, dtype=torch.float))))\n",
    "        self.bx = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "        # Nonlinearity (unchanged)\n",
    "        self.nonlinearity = rectified_tanh\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        # Forward pass logic (same as SimpleRNN but without regularization terms)\n",
    "        hidden_prev = hidden.clone()\n",
    "        timestep = self.tau / 10\n",
    "        #Update hidden state\n",
    "        firing_rate = self.nonlinearity(hidden)\n",
    "        hidden_update = torch.matmul(self.J, firing_rate.transpose(0, 1))\n",
    "        input_update = torch.matmul(self.B, x.transpose(0, 1))\n",
    "        new_hidden = hidden_update + input_update + self.bx.unsqueeze(1)\n",
    "        new_hidden = new_hidden.transpose(0, 1)\n",
    "        # Euler integration for continuous-time update\n",
    "        hidden = hidden + (timestep / self.tau) * (-hidden_prev + new_hidden)\n",
    "        output = self.output_linear(firing_rate)\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(batch_size, self.hidden_size)\n",
    "\n",
    "# Training loop\n",
    "# Hyperparameters\n",
    "input_size = 16\n",
    "hidden_size = 300\n",
    "output_size = 2  # Number of muscles\n",
    "g = 4  # g value\n",
    "h_val = 1.0  # h value\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 100\n",
    "epoch_losses = []\n",
    "val_losses = []\n",
    "\n",
    "patience = 10  # Number of epochs to wait for improvement\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "early_stop = False\n",
    "\n",
    "# get available device\n",
    "device = set_device()\n",
    "\n",
    "# Model instantiation\n",
    "complicated_model = ComplicatedRNN(input_size, hidden_size, output_size, g, h_val)\n",
    "complicated_model.to(device)\n",
    "\n",
    "# Loss function and optimizer (no weight decay)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(complicated_model.parameters(), lr=0.001, weight_decay=0)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    hidden_states_for_plot_cm = []\n",
    "\n",
    "    complicated_model.train()  # Set the model to training mode\n",
    "    for inputs, targets in complicated_train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        batch_size = inputs.size(0)\n",
    "        h = complicated_model.init_hidden(batch_size).to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast():  # Apply automatic mixed precision\n",
    "            for t in range(inputs.shape[1]):\n",
    "                output, h = complicated_model(inputs[:, t, :], h)\n",
    "                hidden_states_for_plot_cm.append(h.detach().cpu().numpy())\n",
    "\n",
    "            loss = criterion(output, targets[:, -1, :])\n",
    "\n",
    "        scaler.scale(loss).backward()  # Scale loss for backward pass\n",
    "        scaler.step(optimizer)  # Update optimizer with scaled gradients\n",
    "        scaler.update()  # Update the scaler\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(complicated_train_loader)\n",
    "    epoch_losses.append(avg_loss)\n",
    "    print(f'Epoch {epoch + 1}, Training Loss: {avg_loss}')\n",
    "\n",
    "    # Validation phase after completing the training for one epoch\n",
    "    val_loss = validate_model(complicated_model, complicated_val_loader, criterion, device)\n",
    "    val_losses.append(val_loss)\n",
    "    print(f'Epoch {epoch + 1}, Validation Loss: {val_loss}')\n",
    "\n",
    "    # Early stopping check\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(\"Early stopping triggered at epoch\", epoch + 1)\n",
    "        early_stop = True\n",
    "        break\n",
    "\n",
    "    # Clear CUDA cache if needed\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# Check if training was stopped by early stopping\n",
    "if early_stop:\n",
    "    print('Training stopped due to early stopping at epoch', epoch + 1)\n",
    "else:\n",
    "    print('Finished Training')\n",
    "\n",
    "# Testing phase\n",
    "test_loss = test_model(complicated_model, complicated_test_loader, criterion, device)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "\n",
    "# Clear cache after training\n",
    "if device == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Determine the number of epochs for which you have loss data\n",
    "actual_num_epochs = len(epoch_losses)  # This will be less than num_epochs if early stopping was triggered\n",
    "\n",
    "# Call the plotting function\n",
    "plot_training_validation_losses(epoch_losses, val_losses, actual_num_epochs, \"ComplicatedRNN - Training and validation losses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c130a00d-4d8c-43a3-a01f-576b5512a7f9",
   "metadata": {},
   "source": [
    "Interestingly, we can observe that SimpleRNN appears to converge slower than the model in the second scenario. This can be inferred from the initial values of training and validation losses, which decrease more rapidly in the second scenario. Moreover, the first scenario shows a consistent decrease in both training and validation losses, with very low final values, indicating good generalization. The second scenario, on the other hand, demonstrates a slight increase in validation loss at certain points, suggesting potential overfitting or instability in learning. Importantly, the test loss is a measure of how well the model performs on a completely unseen dataset after training. SimpleRNN achieves a significantly lower test loss compared to ComplicatedRNN, indicating better generalization capability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b372fc77-34c5-4f5d-b3bf-17a8adcef4be",
   "metadata": {},
   "source": [
    "## Activity 2: Comparing trained RNNs with the brain\n",
    "\n",
    "In this section, we compare trained RNNs with the brain. \n",
    "\n",
    "We plot different PSTHs of real brains in the context of arm movement. Then, we plot different PSTHs of hidden units of RNNs (simple and complicated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cd598c-a42e-4219-aa9b-5b7e54710749",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'condsForSimJ2moMuscles.mat'\n",
    "normalised_inputs, output, num_conditions, num_delays = prepare_dataset(file_path)\n",
    "\n",
    "# Plot PSTH for arm movement\n",
    "plot_psth(output, \"PSTH for Arm Movement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5362de-9acf-4380-af3b-68acded8eb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot hidden units in SimpleRNN\n",
    "plot_hidden_unit_activations(hidden_states=hidden_states_for_plot, timesteps=296, neurons_to_plot=5, title='PSTHs of Hidden Units in SimpleRNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825b011e-0fa3-4e5f-a423-0074f069f30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot hidden units in ComplicatedRNN\n",
    "plot_hidden_unit_activations(hidden_states=hidden_states_for_plot_cm, timesteps=296, neurons_to_plot=5, title='PSTHs of Hidden Units in ComplicatedRNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445e313b-8209-4553-bd47-5ba6a331af17",
   "metadata": {},
   "source": [
    "## Discussion point\n",
    "\n",
    "Which one looks more like the brain?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e552086-0cbc-4f39-8e87-6bce1a05a43f",
   "metadata": {},
   "source": [
    "## Activity 3: Robustness to change in RNNs and the brain\n",
    "\n",
    "In this section, we perturb the simple model's and the complex model's inputs and structural connectivity. Will regularization help the neural network be more resilient?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f917781-b109-4f70-8424-2d9647d20ec9",
   "metadata": {},
   "source": [
    "Let's start with perturbing the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ee0281-a790-4cce-b4f2-2bd0e8da93a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_inputs(model, inputs, perturbation_strength):\n",
    "    device = inputs.device\n",
    "    # Perturb the inputs by adding random noise scaled by the perturbation strength and input strength\n",
    "    input_strength = torch.norm(inputs, p=2, dim=-1, keepdim=True)  # Calculate the L2 norm of inputs\n",
    "    noise = torch.rand(inputs.shape[0], 1, inputs.shape[2], device=device) * perturbation_strength * input_strength\n",
    "    perturbed_inputs = inputs + noise\n",
    "    return perturbed_inputs\n",
    "\n",
    "def compute_loss(model, inputs, targets, criterion, device):\n",
    "    batch_size = inputs.size(0)\n",
    "    h = model.init_hidden(batch_size).to(device)  # Initialize hidden state\n",
    "    losses = []\n",
    "    for t in range(inputs.shape[1]):  # Iterate over time steps\n",
    "        model_output = model(inputs[:, t, :], h)\n",
    "        output, h, *rest = model_output[:2]\n",
    "        loss = criterion(output, targets[:, t])  # Assume targets is a sequence of same length as inputs\n",
    "        losses.append(loss)\n",
    "    mean_loss = torch.mean(torch.stack(losses)).item()\n",
    "    return mean_loss\n",
    "\n",
    "def test_perturbed_inputs(model, perturbation_strengths, test_loader, criterion, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    perturbation_results = []\n",
    "\n",
    "    for strength in perturbation_strengths:\n",
    "        all_errors = []  # Store all errors for each perturbation strength to compute mean and s.d.\n",
    "        print(f\"Testing perturbation strength {strength}\")\n",
    "        for iteration in range(30):  # Repeat the procedure 20 times\n",
    "            batch_errors = []  # Store errors for each batch\n",
    "            print(f\" Iteration {iteration+1}/50\")\n",
    "\n",
    "            for inputs, targets in test_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                # Compute error for original inputs\n",
    "                original_loss = compute_loss(model, inputs, targets, criterion, device)\n",
    "                # Compute error for perturbed inputs\n",
    "                perturbed_inputs = perturb_inputs(model, inputs, strength)\n",
    "                perturbed_loss = compute_loss(model, perturbed_inputs, targets, criterion, device)\n",
    "\n",
    "                # Store the normalized error difference\n",
    "                error_diff = abs(perturbed_loss - original_loss) / original_loss * 100  # Normalize as percentage\n",
    "                error_diff = min(error_diff, 100)  # Truncate at 100%\n",
    "                batch_errors.append(error_diff)\n",
    "\n",
    "            all_errors.extend(batch_errors)\n",
    "\n",
    "        mean_error = np.mean(all_errors)\n",
    "        std_error = np.std(all_errors)\n",
    "        perturbation_results.append((mean_error, std_error))\n",
    "        print(f\"Completed testing for perturbation strength {strength}.\")\n",
    "\n",
    "    return perturbation_results\n",
    "    \n",
    "perturbation_strengths = [0.01, 0.1, 1]\n",
    "results_complex = test_perturbed_inputs(complicated_model, perturbation_strengths, complicated_train_loader, criterion, device)\n",
    "results_simple = test_perturbed_inputs(model, perturbation_strengths, simple_train_loader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1268bf57-9f00-4acb-b181-f025c65b3b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot perturbation results\n",
    "plot_perturbation_results(perturbation_strengths, results_simple, results_complex, \"Perturbation of the inputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e354427f-f371-4fff-aecd-8c835e2a6c63",
   "metadata": {},
   "source": [
    "Now, we proceed to do the same with the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73366bc5-4ce8-4ad0-8eef-9da6044deef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_absolute_strength(model):\n",
    "    # Calculate the mean absolute connection strength of the recurrent weight matrix\n",
    "    return torch.mean(torch.abs(model.J)).item()\n",
    "\n",
    "def perturb_recurrent_weights(model, mean_strength, perturbation_percentage):\n",
    "    # Perturb the recurrent weight matrix J according to a normalized percentage of the mean absolute strength\n",
    "    perturbation_strength = mean_strength * perturbation_percentage\n",
    "    with torch.no_grad():\n",
    "        noise = torch.randn_like(model.J) * perturbation_strength\n",
    "        perturbed_weights = model.J + noise\n",
    "        return perturbed_weights\n",
    "\n",
    "def test_perturbed_structure(model, perturbation_percentages, test_loader, criterion, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    mean_strength = calculate_mean_absolute_strength(model)\n",
    "    perturbation_results = []  # List to store (mean error, std dev) tuples\n",
    "\n",
    "    original_weights = model.J.data.clone()  # Save the original weights\n",
    "\n",
    "    for percentage in perturbation_percentages:\n",
    "        multiple_perturbations_error = []\n",
    "        print(f\"Testing perturbation percentage {percentage:.4f}\")\n",
    "\n",
    "        for perturbation in range(30):  # Perturb 50 times for each strength\n",
    "            batch_errors = []\n",
    "            perturbed_weights = perturb_recurrent_weights(model, mean_strength, percentage)\n",
    "            model.J.data = perturbed_weights.data\n",
    "            print(f\" Perturbation {perturbation+1}/50\")\n",
    "\n",
    "            for inputs, targets in test_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                batch_size = inputs.size(0)\n",
    "                h = model.init_hidden(batch_size).to(device)\n",
    "\n",
    "                for t in range(inputs.shape[1]):\n",
    "                    model_output = model(inputs[:, t, :], h)\n",
    "                    output, h = model_output[:2]\n",
    "\n",
    "                loss = criterion(output, targets[:, -1, :]).item()\n",
    "                batch_errors.append(loss)\n",
    "\n",
    "            model.J.data = original_weights.data  # Reset to original weights after each perturbation\n",
    "            multiple_perturbations_error.append(np.mean(batch_errors))\n",
    "\n",
    "        mean_error = np.mean(multiple_perturbations_error)  # Average over the 50 perturbations\n",
    "        std_dev_error = np.std(multiple_perturbations_error)  # Standard deviation for error bars\n",
    "        perturbation_results.append((mean_error, std_dev_error))\n",
    "        print(f\"Completed testing for perturbation percentage {percentage:.4f}. Mean error: {mean_error:.4f}, Std. dev.: {std_dev_error:.4f}\\n\")\n",
    "\n",
    "    return perturbation_results\n",
    "\n",
    "# Define perturbation strengths as percentages\n",
    "perturbation_strengths = [0.01, 0.1, 1]\n",
    "\n",
    "# Function calls for simple and complex models\n",
    "simple_model_errors_2 = test_perturbed_structure(model, perturbation_strengths, simple_train_loader, criterion, device)\n",
    "complex_model_errors_2 = test_perturbed_structure(complicated_model, perturbation_strengths, complicated_train_loader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257161c9-9155-4dfd-b089-b12ac2725dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot perturbation results\n",
    "plot_perturbation_results(perturbation_strengths, simple_model_errors_2, complex_model_errors_2, \"Perturbation of the weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3447c1f5-31b2-4bce-ad0c-f4ce2e05f70b",
   "metadata": {},
   "source": [
    "## Discussion point \n",
    "\n",
    "Why is SimpleRNN more robust to noise?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa60379-4f5e-4afc-8365-066bd2267ec9",
   "metadata": {},
   "source": [
    "This design philosophy aligns with the principle of Occam's razor, where simpler models are preferred\n",
    "for their generalizability and robustness. By focusing on simple solutions, Simple RNNs can effectively\n",
    "capture the essential patterns in the data without overfitting to the noise or specific details,\n",
    "making them more resilient to changes or errors in the input data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcc771e-7e6a-4c83-a481-943e14e401bc",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Discussion point \n",
    "\n",
    "Is the SimpleRNN how the brain works in motor cortex? If not, why is it useful to model this way? Does this experiment suggest any equally generalizing system would be similarly brain-like? If not, what else is required? Plasticity? Complex decision-making? Sensory integration? Agency | Autonomy?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "W1D1_Tutorial2",
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
