{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0265a08c-d54a-4ade-be7f-170a28a79959",
   "metadata": {
    "execution": {}
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/neuromatch/NeuroAI_Course/blob/main/tutorials/W1D1_Generalization/student/W1D1_Tutorial2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> &nbsp; <a href=\"https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/neuromatch/NeuroAI_Course/main/tutorials/W1D1_Generalization/student/W1D1_Tutorial2.ipynb\" target=\"_parent\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open in Kaggle\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1581e3-dc27-449d-8b2c-58ae24bec2e9",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Tutorial 2: Generalization in Neuroscience\n",
    "\n",
    "**Week 1, Day 1: Generalization**\n",
    "\n",
    "**By Neuromatch Academy**\n",
    "\n",
    "__Content creators:__ Samuele Bolotta, Patrick Mineault and Shreya Saxena\n",
    "\n",
    "__Content reviewers:__ Samuele Bolotta, Lily Chamakura, RyeongKyung Yoon, Yizhou Chen, Ruiyi Zhang, Aakash Agrawal, Alish Dipani, Hossein Rezaei, Yousef Ghanbari, Mostafa Abdollahi, Hlib Solodzhuk, Alex Murphy\n",
    "\n",
    "__Production editors:__ Konstantine Tsafatinos, Ella Batty, Spiros Chavlis, Samuele Bolotta, Hlib Solodzhuk, Alex Murphy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d07f00-daee-4df0-940b-d240e335c3de",
   "metadata": {
    "execution": {}
   },
   "source": [
    "___\n",
    "\n",
    "\n",
    "# Tutorial Objectives\n",
    "\n",
    "*Estimated timing of tutorial: 75 minutes*\n",
    "\n",
    "This tutorial will introduce you to generalization in neuroscience. We'll look at a classic neuroscience paper, [Sussillo et al. (2015)](https://www.nature.com/articles/nn.4042), that compares how artificial and biological neural networks solve different motor tasks. This paper looks at how linear arm movements are generated in motor cortex; later extensions of these ideas (e.g. [Codol et al. 2024](https://elifesciences.org/reviewed-preprints/88591v2); [Almani et al. 2024](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=x-YACVoAAAAJ&sortby=pubdate&citation_for_view=x-YACVoAAAAJ:1yQoGdGgb4wC)) address how more complex skilled movements, including handwriting, can be generated, continuing our theme for today's tutorials. We'll look at a popular AI-derived framework for understanding how the brain solves tasks: task-driven neural networks.\n",
    "\n",
    "Our learning goals for this tutorial are as follows:\n",
    "\n",
    "1. Understand core goals in neuroscience. Examine the fundamental questions that drive neuroscience research, such as the 'What', 'How', and 'Why' behind neurological functions and behaviors.\n",
    "\n",
    "2. Conceptualize what **generalization** means in the context of neuroscience, understanding how principles of neural generalization can inform and be informed by artificial intelligence.\n",
    "\n",
    "3. Evaluate the impact of architectural choices. Discuss how different architectural decisions and the selection of priors in model design can introduce inductive biases, affecting the generalization capabilities of both neural and artificial systems.\n",
    "\n",
    "4. Illustrate robustness in noisy environments. Identify and describe real-world instances where the pursuit of robustness against noise has led to converging strategies in both neuroscience and artificial intelligence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bf0b64-9cff-4e19-a09b-2a578c6ec7e4",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Tutorial slides\n",
    "# @markdown These are the slides for the videos in all tutorials today\n",
    "\n",
    "from IPython.display import IFrame\n",
    "from ipywidgets import widgets\n",
    "out = widgets.Output()\n",
    "\n",
    "link_id = \"79523\"\n",
    "\n",
    "with out:\n",
    "    print(f\"If you want to download the slides: https://osf.io/download/{link_id}/\")\n",
    "    display(IFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/{link_id}/?direct%26mode=render%26action=download%26mode=render\", width=730, height=410))\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a35d5ac-7d05-4686-bf35-bde1bba0016a",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24296ef5-d8f9-438e-9574-08666be4cd5c",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Install and import feedback gadget\n",
    "\n",
    "!pip install numpy scipy matplotlib torch tqdm vibecheck --quiet\n",
    "\n",
    "from vibecheck import DatatopsContentReviewContainer\n",
    "def content_review(notebook_section: str):\n",
    "    return DatatopsContentReviewContainer(\n",
    "        \"\",  # No text prompt\n",
    "        notebook_section,\n",
    "        {\n",
    "            \"url\": \"https://pmyvdlilci.execute-api.us-east-1.amazonaws.com/klab\",\n",
    "            \"name\": \"neuromatch_neuroai\",\n",
    "            \"user_key\": \"wb2cxze8\",\n",
    "        },\n",
    "    ).render()\n",
    "\n",
    "\n",
    "feedback_prefix = \"W1D1_T2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa35e2b",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Import dependencies\n",
    "\n",
    "# Standard Libraries for file and operating system operations, security, and web requests\n",
    "import os\n",
    "import hashlib\n",
    "import requests\n",
    "import random\n",
    "import gc\n",
    "\n",
    "# Core Python data science and visualization libraries\n",
    "import numpy as np\n",
    "import scipy\n",
    "from matplotlib import pyplot as plt\n",
    "import logging\n",
    "from IPython.display import IFrame, display, Image\n",
    "\n",
    "# Deep Learning libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.autograd import profiler\n",
    "\n",
    "# Additional utilities\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2af95e4-b42d-4e65-afff-d77470f1716d",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Figure settings\n",
    "\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' # perform high definition rendering for images and plots\n",
    "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/nma.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bf7d34-d33a-4683-88e8-b27ae830ef73",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Plotting functions\n",
    "\n",
    "xlim = (-1.8, .7)\n",
    "\n",
    "def plot_inputs_over_time(timesteps, avg_inputs, title='Inputs over Time'):\n",
    "    \"\"\"\n",
    "    Plot the inputs over time.\n",
    "\n",
    "    Inputs:\n",
    "    - timesteps (list or array-like): A sequence of time steps at which the inputs were recorded.\n",
    "      This acts as the x-axis in the plot, representing the progression of time.\n",
    "    - avg_inputs (list or array-like): The average values of inputs corresponding to each time step.\n",
    "      These values are plotted on the y-axis, showing the magnitude of inputs over time.\n",
    "    - title (string): The title of the plot\n",
    "\n",
    "    Returns:\n",
    "    This function generates and displays a plot using Matplotlib.\n",
    "    \"\"\"\n",
    "\n",
    "    with plt.xkcd():\n",
    "        plt.figure(figsize=(8, 3))\n",
    "        num_features = avg_inputs.shape[1] if hasattr(avg_inputs, 'shape') else len(avg_inputs[0])\n",
    "\n",
    "        for feature_idx in range(num_features):\n",
    "            current_feature_values = avg_inputs[:, feature_idx] if hasattr(avg_inputs, 'shape') else [row[feature_idx] for row in avg_inputs]\n",
    "            label = f'Feature {feature_idx + 1}' if feature_idx < num_features - 1 else 'Go Cue'\n",
    "            plt.plot(timesteps, current_feature_values, label=label)\n",
    "\n",
    "        plt.title(title)\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Value (A.U.)')\n",
    "        plt.subplots_adjust(right=0.7)\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=8)\n",
    "        plt.tight_layout()\n",
    "        plt.xlim(min(timesteps), max(timesteps))\n",
    "        plt.show()\n",
    "\n",
    "def plot_muscles_over_time(timesteps, avg_output, title='Muscles over Time'):\n",
    "    \"\"\"\n",
    "    Plot the average outputs over time for two muscles to visualize changes in output values.\n",
    "    The avg_output is expected to be a 250x2 array where each column corresponds to a different muscle.\n",
    "\n",
    "    Inputs:\n",
    "    - timesteps (list or array-like): A sequence of time steps at which the outputs were recorded.\n",
    "      This acts as the x-axis in the plot, representing the progression of time.\n",
    "    - avg_output (array-like, shape [250, 2]): The average values of outputs, with each column\n",
    "      representing the output over time for each muscle.\n",
    "    - title (string): The title of the plot\n",
    "\n",
    "    Returns:\n",
    "    This function generates and displays a plot using Matplotlib.\n",
    "    \"\"\"\n",
    "\n",
    "    with plt.xkcd():\n",
    "\n",
    "        plt.figure(figsize=(8, 3))  # Set the figure size\n",
    "        plt.plot(timesteps, avg_output[:, 0], label='Muscle 1')  # Plot for muscle 1\n",
    "        plt.plot(timesteps, avg_output[:, 1], label='Muscle 2')  # Plot for muscle 2\n",
    "        plt.title(title)\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Value (A.U.)')\n",
    "\n",
    "        # Adjust plot margins to provide space for the legend outside the plot\n",
    "        plt.subplots_adjust(right=0.7)\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=8)  # Placing legend outside\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.xlim(min(timesteps), max(timesteps))  # Ensuring x-axis covers the range of timesteps\n",
    "        plt.show()\n",
    "\n",
    "def plot_training_validation_losses(epoch_losses, val_losses, actual_num_epochs, title):\n",
    "\n",
    "    \"\"\"\n",
    "    This function plots the training and validation losses over epochs.\n",
    "\n",
    "    Inputs:\n",
    "    - epoch_losses (list of float): List containing the training loss for each epoch. Each element is a float\n",
    "      representing the loss calculated after each epoch of training.\n",
    "    - val_losses (list of float): List containing the validation loss for each epoch. Similar to `epoch_losses`, but\n",
    "      for the validation set, allowing for the comparison between training and validation performance.\n",
    "    - actual_num_epochs (int): The actual number of epochs the training went through. This could be different from\n",
    "      the initially set number of epochs if early stopping was employed. It determines the range of the x-axis\n",
    "      in the plot.\n",
    "    - title (str): A string that sets the title of the plot. This allows for customization of the plot for better\n",
    "      readability and interpretation.\n",
    "\n",
    "    Outputs:\n",
    "    This function generates and displays a plot using matplotlib.\n",
    "    \"\"\"\n",
    "\n",
    "    with plt.xkcd():\n",
    "\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.plot(range(1, actual_num_epochs + 1), epoch_losses, label='Training Loss')\n",
    "        plt.plot(range(1, actual_num_epochs + 1), val_losses, label='Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title(title)\n",
    "        plt.legend()\n",
    "        plt.xlim(xlim)\n",
    "        plt.show()\n",
    "\n",
    "# Plot hidden units in UnregularizedRNN\n",
    "def plot_hidden_unit_activations(hidden_states, times, neurons_to_plot=5, title='PSTHs of Hidden Units'):\n",
    "    \"\"\"\n",
    "    This function plots the average activation of a specified number of neurons from the hidden layers\n",
    "    of a neural network over a certain number of timesteps.\n",
    "\n",
    "    Inputs:\n",
    "        hidden_states (tensor): A 2D tensor containing the hidden states of a network. The dimensions\n",
    "                                should be (time, features), where 'time' represents the sequence of\n",
    "                                timesteps, 'batch' represents different data samples, and 'features' represents\n",
    "                                the neuron activations or features at each timestep.\n",
    "        times (tensor): The time range that we focus on.\n",
    "        neurons_to_plot (int, optional): The number of neuron activations to plot, starting from the first neuron.\n",
    "                                         Defaults to 5.\n",
    "        title (str, optional): The title of the plot, allowing customization for specific analyses or presentations.\n",
    "                               Defaults to 'PSTHs of Hidden Units'.\n",
    "\n",
    "    This function generates and displays a plot of the average activation of specified\n",
    "    neurons over the selected timesteps, providing a visual analysis of neuron behavior within the network.\n",
    "    \"\"\"\n",
    "    # Apply the nonlinearity to each hidden state before averaging\n",
    "    rectified_tanh = lambda x: np.where(x > 0, np.tanh(x), 0)\n",
    "    hidden_states_rectified = rectified_tanh(np.array(hidden_states))\n",
    "\n",
    "    # Plotting\n",
    "\n",
    "    with plt.xkcd():\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        for i in range(min(neurons_to_plot, hidden_states_rectified.shape[1])):\n",
    "            plt.plot(times, hidden_states_rectified[:, i], label=f'Neuron {i+1}')\n",
    "\n",
    "        plt.xlabel('Time Steps')\n",
    "        plt.ylabel('Activation')\n",
    "        plt.title(title)\n",
    "\n",
    "        # Adjust plot margins to provide space for the legend outside the plot\n",
    "        plt.subplots_adjust(right=0.8)  # Adjust this value to create more or less space on the right\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize='small')  # Placing legend outside\n",
    "\n",
    "        plt.xlim(times[0], times[-1])  # Setting x-axis limits based on the provided time tensor\n",
    "        plt.show()\n",
    "\n",
    "def plot_psth(data, condition=0, neurons_to_plot=5, title='PSTHs of real data'):\n",
    "    \"\"\"\n",
    "    This function plots PSTHs from real neural data\n",
    "\n",
    "    Args:\n",
    "        data (dict): The data from the mat file from Sussillo et al. (2015)\n",
    "        condition (int, optional): The condition (from 0 to 26). Defaults to 0.\n",
    "        neurons_to_plot (int, optional): The number of neuron activations to plot, starting from the first neuron.\n",
    "                                         Defaults to 5.\n",
    "        title (str, optional): The title for the PSTH plot. This allows users to specify the context or the\n",
    "                     experiment from which the data is derived.\n",
    "\n",
    "    Outputs:\n",
    "    This function directly generates and displays a plot using matplotlib\n",
    "    to visually represent the neural activity across time bins.\n",
    "    \"\"\"\n",
    "    # Plot\n",
    "    with plt.xkcd():\n",
    "\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        for neuron_idx in range(neurons_to_plot):  # Iterate over each feature/channel\n",
    "            times_real = data['comboNjs'][0, neuron_idx]['interpTimes'][0]['times'][0].squeeze().astype(float)\n",
    "            t0 = float(data['comboNjs'][0, neuron_idx]['interpTimes'][0]['moveStarts'][0].item())\n",
    "            times_real = (times_real - t0) / 1000.0\n",
    "\n",
    "            spikes_real = data['comboNjs'][0, neuron_idx]['cond'][0]['interpPSTH'][0].squeeze()\n",
    "            plt.plot(times_real, spikes_real, label=f'Neuron {neuron_idx+1}')\n",
    "\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Average Activity (Hz)')\n",
    "        plt.title(title)\n",
    "\n",
    "        # Adjust plot margins and place legend outside the plot\n",
    "        plt.subplots_adjust(right=0.8)\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize='small')\n",
    "\n",
    "        plt.xlim(times_real[0], times_real[-1])  # Assume times_real is defined\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_perturbation_results(perturbation_strengths, results_regularized, results_unregularized, title):\n",
    "    \"\"\"\n",
    "    This function plots the normalized error percentages of two models (regularized and unregularized) under various\n",
    "    perturbation strengths.\n",
    "\n",
    "    Inputs:\n",
    "        perturbation_strengths (list of float): A list of perturbation strengths tested, representing the\n",
    "                                                 magnitude of perturbations applied to the model input or parameters.\n",
    "        results_regularized (list of tuples): Each tuple contains (mean error, standard deviation) for the regularized model\n",
    "                                         at each perturbation strength.\n",
    "        results_unregularized (list of tuples): Each tuple contains (mean error, standard deviation) for the unregularized model\n",
    "                                          at each perturbation strength.\n",
    "        title (str): The title of the plot, allowing for customization to reflect the analysis context.\n",
    "\n",
    "    The function generates and displays a bar plot comparing the normalized error\n",
    "    rates of regularized and unregularized models under different perturbation strengths, with error bars representing the\n",
    "    standard deviation of errors, normalized to percentage scale.\n",
    "    \"\"\"\n",
    "    mean_errors_regularized, std_errors_regularized = zip(*results_regularized)\n",
    "    mean_errors_unregularized, std_errors_unregularized = zip(*results_unregularized)\n",
    "\n",
    "    print(\"mean_errors_regularized\", mean_errors_regularized)\n",
    "    print(\"mean_errors_unregularized\", mean_errors_unregularized)\n",
    "\n",
    "    # Plotting\n",
    "\n",
    "    with plt.xkcd():\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        bar_width = 0.35\n",
    "        bar_positions = np.arange(len(perturbation_strengths))\n",
    "\n",
    "        plt.bar(bar_positions - bar_width/2, mean_errors_regularized, width=bar_width, color='blue', yerr=std_errors_regularized, capsize=5, label='Regularized Model')\n",
    "        plt.bar(bar_positions + bar_width/2, mean_errors_unregularized, width=bar_width, color='red', yerr=std_errors_unregularized, capsize=5, label='Unregularized Model')\n",
    "\n",
    "        plt.xlabel('Perturbation Magnitude')\n",
    "        plt.ylabel('Normalized Error (%)')\n",
    "        plt.title(title)\n",
    "        plt.xticks(bar_positions, [f\"{x:.5f}\" if x < 0.1 else f\"{x}\" for x in perturbation_strengths])\n",
    "        plt.legend()\n",
    "        plt.ylim(0, 100)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70b8e4b-f2ca-42af-bcd1-27fb6cecbc30",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Set device (GPU or CPU). Execute `set_device()`\n",
    "# especially if torch modules used.\n",
    "# @markdown\n",
    "\n",
    "# inform the user if the notebook uses GPU or CPU.\n",
    "\n",
    "def set_device():\n",
    "    \"\"\"\n",
    "    Determines and sets the computational device for PyTorch operations based on the availability of a CUDA-capable GPU.\n",
    "\n",
    "    Outputs:\n",
    "    - device (str): The device that PyTorch will use for computations ('cuda' or 'cpu'). This string can be directly used\n",
    "    in PyTorch operations to specify the device.\n",
    "    \"\"\"\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    if device != \"cuda\":\n",
    "        print(\"GPU is not enabled in this notebook. \\n\"\n",
    "              \"If you want to enable it, in the menu under `Runtime` -> \\n\"\n",
    "              \"`Hardware accelerator.` and select `GPU` from the dropdown menu\")\n",
    "    else:\n",
    "        print(\"GPU is enabled in this notebook. \\n\"\n",
    "              \"If you want to disable it, in the menu under `Runtime` -> \\n\"\n",
    "              \"`Hardware accelerator.` and select `None` from the dropdown menu\")\n",
    "\n",
    "    return device\n",
    "\n",
    "device = set_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654e7c22-bd2a-4a6e-867e-462646e3b496",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Set random seed, when using `pytorch`\n",
    "\n",
    "# @markdown Executing `set_seed(seed=seed)` will specify the exact random seed to use\n",
    "\n",
    "# Call `set_seed` function in the exercises to ensure reproducibility.\n",
    "\n",
    "def set_seed(seed=None, seed_torch=True):\n",
    "  if seed is None:\n",
    "    seed = np.random.choice(2 ** 32)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  if seed_torch:\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "  print(f'Random seed {seed} has been set.')\n",
    "\n",
    "# In case that `DataLoader` is used\n",
    "def seed_worker(worker_id):\n",
    "  worker_seed = torch.initial_seed() % 2**32\n",
    "  np.random.seed(worker_seed)\n",
    "  random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fea2ec-e1ee-4ebe-9dff-d3b253c3ba0b",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Data retrieval\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import hashlib\n",
    "\n",
    "def retrieve_file(fname, url, expected_md5):\n",
    "    # Check if the file already exists\n",
    "    if not os.path.isfile(fname):\n",
    "        try:\n",
    "            # Attempt to download the file\n",
    "            response = requests.get(url)\n",
    "        except requests.ConnectionError:\n",
    "            # Handle connection errors during the download\n",
    "            print(\"!!! Failed to download data !!!\")\n",
    "        else:\n",
    "            # No connection errors, proceed to check the response\n",
    "            if response.status_code != requests.codes.ok:\n",
    "                # Check if the HTTP response status code indicates a successful download\n",
    "                print(\"!!! Failed to download data !!!\")\n",
    "            elif hashlib.md5(response.content).hexdigest() != expected_md5:\n",
    "                # Verify the integrity of the downloaded file using MD5 checksum\n",
    "                print(\"!!! Data download appears corrupted !!!\")\n",
    "            else:\n",
    "                # If download is successful and data is not corrupted, save the file\n",
    "                with open(fname, \"wb\") as fid:\n",
    "                    fid.write(response.content) # Write the downloaded content to a file\n",
    "\n",
    "# List of files to be downloaded with their respective URLs and expected MD5 hashes\n",
    "files = [\n",
    "    (\"regularized_model_final.pth\", \"https://osf.io/kc7sb/download\", \"9435a9c2ea75766144bf840b25bfb97e\"),\n",
    "    (\"unregularized_model_final.pth\", \"https://osf.io/9vsy5/download\", \"2e3dc9551b677206e2315788df354a91\"),\n",
    "    (\"condsForSimJ2moMuscles.mat\", \"https://osf.io/wak7e/download\", \"257d16c4d92759d615bf5cac75dd9a1f\"),\n",
    "    (\"m1_reaching_data.mat\", \"https://osf.io/p2x4n/download\", \"6fc65443b9632db47772dd2efaadeee0\")\n",
    "]\n",
    "\n",
    "for fname, url, expected_md5 in files:\n",
    "    retrieve_file(fname, url, expected_md5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b2b4f7-14f6-4374-a8a4-a17799d1f787",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Helper functions\n",
    "\n",
    "# Define a custom Rectified Tanh activation function\n",
    "def rectified_tanh(x):\n",
    "    return torch.where(x > 0, torch.tanh(x), 0)\n",
    "\n",
    "def grad_rectified_tanh(x):\n",
    "    return torch.where(x > 0, 1 - torch.tanh(x)**2, 0)\n",
    "\n",
    "def grad_tanh(x):\n",
    "    return 1 - torch.tanh(x)**2\n",
    "\n",
    "def compute_l2_regularization(parameters, alpha):\n",
    "    l2_reg = sum(p.pow(2.0).sum() for p in parameters)\n",
    "    return alpha * l2_reg\n",
    "\n",
    "def prepare_dataset(file_path, feature_idx=7, muscle_idx=1):\n",
    "    \"\"\"\n",
    "    Load and preprocess data from a .mat file for RNN training.\n",
    "\n",
    "    Args:\n",
    "    - file_path: str, path to the .mat file containing the dataset.\n",
    "    - feature_idx: int, index for individual features for plotting. Max 14.\n",
    "    - muscle_idx: int, index for muscles for plotting. Max 1.\n",
    "\n",
    "    Returns:\n",
    "    - normalised_inputs: Tensor, normalized and concatenated Plan and Go Envelope tensors.\n",
    "    - avg_output: Tensor, average muscle activity across conditions and delays.\n",
    "    - timesteps: np.ndarray, array of time steps for plotting.\n",
    "    \"\"\"\n",
    "    # Load the .mat file\n",
    "    data = scipy.io.loadmat(file_path)\n",
    "\n",
    "    # Extract condsForSim struct\n",
    "    conds_for_sim = data['condsForSim']\n",
    "\n",
    "    # Initialize lists to store data for all conditions\n",
    "    go_envelope_all, plan_all, muscle_all = [], [], []\n",
    "\n",
    "    # Get the number of conditions (rows) and delay durations (columns)\n",
    "    num_conditions, num_delays = conds_for_sim.shape\n",
    "\n",
    "    times = conds_for_sim['timesREmove'][0][0] / 1000.0\n",
    "\n",
    "    # Select the same time period as the PSTHs\n",
    "    rg = slice(46, 296)\n",
    "\n",
    "    for i in range(num_conditions):  # Loop through each condition\n",
    "        go_envelope_condition, plan_condition, muscle_condition = [], [], []\n",
    "\n",
    "        for j in range(num_delays):  # Loop through each delay duration\n",
    "            condition = conds_for_sim[i, j]\n",
    "            go_envelope, plan, muscle = condition['goEnvelope'], condition['plan'], condition['muscle']\n",
    "            selected_muscle_data = muscle[:, [3, 4]]  # Select only specific muscles\n",
    "            go_envelope_condition.append(go_envelope[rg, :])\n",
    "            plan_condition.append(plan[rg, :])\n",
    "            muscle_condition.append(selected_muscle_data[rg, :])\n",
    "\n",
    "        # Convert lists of arrays to tensors and append to all conditions\n",
    "        go_envelope_all.append(torch.tensor(np.array(go_envelope_condition), dtype=torch.float32))\n",
    "        plan_all.append(torch.tensor(np.array(plan_condition), dtype=torch.float32))\n",
    "        muscle_all.append(torch.tensor(np.array(muscle_condition), dtype=torch.float32))\n",
    "\n",
    "    times = times[rg]\n",
    "\n",
    "    # Stack tensors for all conditions\n",
    "    go_envelope_tensor, plan_tensor, output = torch.stack(go_envelope_all), torch.stack(plan_all), torch.stack(muscle_all)\n",
    "\n",
    "    # Cleanup to free memory\n",
    "    del data, conds_for_sim, go_envelope_all, plan_all, muscle_all\n",
    "    gc.collect()\n",
    "\n",
    "    # Normalize and Standardize Plan Tensor\n",
    "    plan_tensor = normalize_and_standardize(plan_tensor)\n",
    "\n",
    "    # Normalise and concatenate Plan and Go Envelope Tensors\n",
    "    normalised_inputs = normalize_and_standardize(torch.cat([plan_tensor, go_envelope_tensor], dim=3))\n",
    "\n",
    "    fixed_delay = 3\n",
    "    inputs_no_delay = normalised_inputs[:, fixed_delay, ...]\n",
    "    output_no_delay = output[:, fixed_delay, ...]\n",
    "    return inputs_no_delay, normalised_inputs, output_no_delay, output, times\n",
    "\n",
    "def normalize_and_standardize(tensor):\n",
    "    \"\"\"\n",
    "    Normalize and standardize a given tensor.\n",
    "\n",
    "    Args:\n",
    "    - tensor: Tensor, the tensor to be normalized and standardized.\n",
    "\n",
    "    Returns:\n",
    "    - standardized_normalized_tensor: Tensor, the normalized and standardized tensor.\n",
    "    \"\"\"\n",
    "    min_val, max_val = tensor.min(), tensor.max()\n",
    "    tensor = (tensor - min_val) / (max_val - min_val)  # Normalize\n",
    "    mean, std = tensor.mean(), tensor.std()\n",
    "    return (tensor - mean) / std  # Standardize\n",
    "\n",
    "def train_val_split():\n",
    "    \"\"\"Split the data into train and validation splits.\n",
    "    \"\"\"\n",
    "    train_split, val_split = random_split(range(27), [20, 7])\n",
    "    return sorted(list(train_split)), sorted(list(val_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291f8880-5449-433c-9d2d-4130be2266f9",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 1: Overview\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', 'lW0U2vv5BmQ'), ('Bilibili', 'BV1g1421C7G4')]\n",
    "tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd640e68-b128-4b37-b922-5f3d73ce45f7",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_overview_video\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342a9ef5",
   "metadata": {},
   "source": [
    "# Definitions\n",
    "\n",
    "* Peristimulus Time Histogram (PSTH) - A visualization tool to temporally display neuronal firing rates around an external stimulus event"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417c2110-9f36-49b4-9aca-3bc0df32a1a2",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Section 1: Motivation: How the brain generates motor commands\n",
    "\n",
    "Let's put ourselves in the mindset of a neuroscientist trying to understand how the brain generates motor sequences. A classic example of a complex motor sequence is handwriting, which we looked at in the last tutorial. This skill involves coordinated movement of the arm, wrist and fingers. \n",
    "\n",
    "The mapping between the goal (e.g. moving the arm) and the sequence of motor commands that drive different muscles is highly nonlinear and recurrent. Furthermore, the brain must *generalize* beyond its training data; for instance, when the recurrent connections of the brain attempt to maintain stability in the face of noise in the environment (homeostasis effects), or when the arm is under different pressures. How does the brain do that?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cc0263-74a3-42a0-ab78-de496172ecd1",
   "metadata": {
    "execution": {}
   },
   "source": [
    "<img src=\"https://github.com/neuromatch/NeuroAI_Course/blob/main/tutorials/W1D1_Generalization/static/setup.png?raw=true\" width=600 />\n",
    "\n",
    "*Image adapted from Rizzoglio et al. (2023). From monkeys to humans: observation-based EMG brain–computer interface decoders for humans with paralysis. Journal of Neural Engineering. 10.1088/1741-2552/ad038e. CC-BY 4.0.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1102b233-748c-4a37-8b40-7f8edc2b2bad",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Our neuroscientist is trying to address a *how* question: how does the brain find solutions to complex control problems that generalize? Recurrent neural networks (RNNs) are a type of artificial neural network that have proven to be a very useful tool to address these *how* questions. They mimic the adaptability and plasticity observed in biological neural networks through interconnected artificial neurons, weights dictating connection strengths, and activation functions triggering neuron responses. **Task-driven neural networks** are trained *in silico* (using computers) to solve similar tasks to ones that the brain must solve. With the specification to prefer simple solutions over more complex solutions, model representations are often similar to the ones that the brain seems to find. The trained artificial neural networks can then be used to investigate, mechanistically, how a task is solved in the brain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff10456-56dc-4f64-9d1b-45aa343ecba1",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "source": [
    "![Picture which shows an RNN.](https://github.com/neuromatch/NeuroAI_Course/blob/main/tutorials/W1D1_Generalization/static/rnn.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76206fc7-b2a7-4598-9c4c-450b138e9f5a",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Let's illustrate these ideas with a classic paper in this field: [Sussillo et al. (2015)](https://www.nature.com/articles/nn.4042). They train an RNN to solve a motor task by learning to map movement direction commands to arm movements recorded via electromyography (EMG). Looking inside this RNN gives them the ability to ask questions about generalization. They then compare the model representations from the RNN to spike data from the motor cortex (M1) of a monkey performing a similar task. Do they perform similarly? Is the RNN performing the same kind of task as the brain, in a similar way?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca34d9d-c42d-4a66-9cdb-640e8ea7136d",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 2: Setup\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', 'AEQJ6e32ZeQ'), ('Bilibili', 'BV1D6421f7vH')]\n",
    "tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa77b4b2-35fb-4de9-8353-15275bbf4fd4",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_setup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c38e8e-55f6-4d83-a863-819174b38d7c",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Section 2: Training an unregularized task-driven neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efadda69-d5fe-4fc8-9bc9-bdc982b7f7de",
   "metadata": {
    "execution": {}
   },
   "source": [
    "In this activity, our goal is to train recurrent neural networks to mimic the muscle activity (EMG) of monkeys during arm movements. The challenge is to transform simple inputs (task features) into complex patterns of muscle activity over time and space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc16cdcf-d366-452c-ac7d-4fd11221a717",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Define the path to the dataset file containing conditions for simulation of muscles\n",
    "file_path = 'condsForSimJ2moMuscles.mat'\n",
    "\n",
    "# Prepare the dataset by loading and processing it from the specified file path\n",
    "normalised_inputs, normalised_inputs_with_delay, outputs, outputs_with_delay, times = prepare_dataset(file_path)\n",
    "\n",
    "print(\"Shape of the inputs\", normalised_inputs.shape)\n",
    "print(\"Shape of the output\", outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeb718b-f138-463a-bcfb-64fbf6d5c101",
   "metadata": {
    "execution": {}
   },
   "source": [
    "These dimensions correspond to the following:\n",
    "\n",
    "* 27 conditions, one for each trial in the data\n",
    "* 250 time steps (each trial was 2.5 seconds in length, measured at 100 Hz)\n",
    "* The inputs are 16-dimensional, with 15 dimensions corresponding to the reach condition (explained below) and the 16th dimension corresponding to the Go Cue.\n",
    "* The outputs are 2-dimensional, corresponding to the target electromyography (EMG) data for **2** muscles.\n",
    "\n",
    "The inputs to the model are 16-dimensional vectors that specify which reach to perform. Each reach condition is represented by a unique 15-dimensional vector, which remains constant during the movement preparation period from -1s to 0s. The 16th dimension, a Go Cue, features a small bump at 0s, signaling the model to start generating the output.\n",
    "\n",
    "To illustrate, consider a robot arm that needs to reach different objects positioned in various locations. The condition-specific inputs would guide the robot on which object to reach for (e.g., left, right, up, down). Prior to each reach, the robot's \"brain\" (neural activity) prepares in a particular manner, and this readiness is recorded. These readiness signals are then fed into the RNN, helping it understand and prepare for the specific reach.\n",
    "\n",
    "Initially, the robot remains still (hold cue). Following a brief delay, it receives a signal to begin the reach. These delays and specific inputs train the robot to accurately perform the reach for each condition.\n",
    "\n",
    "Take a look at the output shapes printed above and mentally visualize the structure of the array. \n",
    "Let's look at the few of the inputs and outputs to get a better understanding of the data. Note that \"Reach direction $N$\" refers to one of the reach conditions (e.g. move down / up / left / right). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd6d286-fc8b-4b1c-babe-c58279781637",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Averaging across conditions and delays\n",
    "reach_directions = [0, 6, 9]\n",
    "for reach in reach_directions:\n",
    "    # Plot inputs and outputs\n",
    "    one_direction = normalised_inputs[reach, ...].clone()\n",
    "    # Exaggerate the Go Cue for visualization purposes\n",
    "    one_direction[:, -1] *= 5\n",
    "    plot_inputs_over_time(times, one_direction, title=f'Inputs over Time, reach direction {reach}')\n",
    "    plot_muscles_over_time(times, outputs[reach, ...], title=f'Outputs over Time, reach direction {reach}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2babbe86-34bb-45e3-9240-2c8165f86b16",
   "metadata": {
    "execution": {}
   },
   "source": [
    "As you can see:\n",
    "\n",
    "* the movement (reach condition) to be generated is encoded by a 16-dimensional signal during the hold period (from -1 to 0s).\n",
    "* the 16-dimensional signal is unique for each reach direction\n",
    "* The Go Cue (feature 16, timepoint 0) signals that it's time to start generating the movement\n",
    "* The movements of the muscles are generated right after the GO Cue.\n",
    "\n",
    "Let's create a PyTorch `Dataset` object to hold the data we just described."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417463ca-29c8-4229-baed-58dcf390747a",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "class TimeseriesDataset(Dataset):\n",
    "    def __init__(self, inputs, targets):\n",
    "        \"\"\"\n",
    "        inputs: Tensor of shape [num_examples, time, input_features]\n",
    "        targets: Tensor of shape [num_examples, time, output_features]\n",
    "        \"\"\"\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        self.num_conditions = inputs.shape[0]\n",
    "        assert inputs.shape[0] == targets.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_conditions\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_seq = self.inputs[idx]\n",
    "        target_seq = self.targets[idx]\n",
    "        return input_seq, target_seq\n",
    "\n",
    "# Create the dataset with the fixed delay\n",
    "train_idx, val_idx = train_val_split()\n",
    "train_dataset = TimeseriesDataset(normalised_inputs[train_idx], outputs[train_idx])\n",
    "val_dataset = TimeseriesDataset(normalised_inputs[val_idx], outputs[val_idx])\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 20\n",
    "unregularized_train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "unregularized_val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a47a4b-1bf2-4bd8-9d88-14a6ecf899a7",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_Setup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3302fb-cd76-4803-8fbf-5b7baf4409d3",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding exercise 2.1: Defining an unregularized RNN\n",
    "\n",
    "Let's start by defining an unregularized RNN by inheriting from `nn.Module`. This RNN takes in the time-varying control inputs and outputs muscle outputs.\n",
    "\n",
    "The model is a single-layer recurrent neural network defined in continuous time. The network takes in an input vector (all timepoints) and outputs muscle EMG (also for all timepoints). The hidden state of the network $\\mathbf{x}$ evolves according to the equation:\n",
    "\n",
    "$$\\tau \\frac{d\\mathbf{x}}{dt} = -\\mathbf{x} + \\mathbf{B}\\mathbf{u} + \\mathbf{J}\\mathbf{r} + \\mathbf{b}$$\n",
    "\n",
    "Here we have:\n",
    "\n",
    "* $\\mathbf{u}$ is the stimulus input at the current timestep\n",
    "* $\\mathbf{B}\\mathbf{u}$ is the feedforward drive (activity) of the neural network, the inputs $\\mathbf{u}$ are linearly projected through a set of weights $\\mathbf{B}$\n",
    "* $\\mathbf{r} = |\\tanh(\\mathbf{x})|$ is the hidden activity passed through a rectifying, saturating non-linear activation function\n",
    "* $\\mathbf{J}\\mathbf{r}$ is the recurrent drive (activity) of the neural network, the recurrent activity $\\mathbf{r}$ is linearly projected through a set of weights $\\mathbf{J}$\n",
    "* $\\mathbf{b}$ is a constant\n",
    "* $\\tau$ is a scalar corresponding to the time scale of the network, 50 ms\n",
    "\n",
    "To transform this to a standard discrete-time neural network, we use Euler integration with a time step equal to the resolution of the simulation, 10ms. See the [Comp Neuro W2D2](https://compneuro.neuromatch.io/tutorials/W2D2_LinearSystems/student/W2D2_Tutorial1.html?highlight=euler+integration#coding-exercise-1-forward-euler-integration) to brush up on this idea if this idea is not clear.\n",
    "\n",
    "Thus, the discretized update equation will be:\n",
    "\n",
    "$$\\mathbf{x_{t+1}} = \\mathbf{x}_{t} + \\Delta t\\frac{d\\mathbf{x_t}}{dt}$$\n",
    "\n",
    "There are a few more parameters to consider:\n",
    "\n",
    "* The scale of the parameters of the input mixing matrix $\\mathbf{B}$ is determined by $h$ (not shown in equation)\n",
    "* The scale of the parameters of the input mixing matrix $\\mathbf{J}$ is determined by $g$ (not shown in equation).\n",
    "* We initialize $g$ to a value larger than 1, so the neural network is in a so-called *chaotic regime*.\n",
    "* The network is initialized with hidden state $\\mathbf{x}=0$\n",
    "\n",
    "Finally, the model's predicted EMG activity is given by a linear readout:\n",
    "\n",
    "$$z = \\mathbf{W}\\mathbf{r} + c$$\n",
    "\n",
    "In this notation, we can interpret $\\mathbf{r}$ as the firing rates of the neurons. Take a look at the equation above: the hidden state, $\\mathbf{x}$ (representation of stimuli in the brain), is evolving over time and is driven by current stimuli input $\\mathbf{u}$ and firing rates of neurons in the previous time step, $\\mathbf{r}$. EMG activity, $z$, is a direct linear projection from firing rates. \n",
    "\n",
    "Let's code up this unregularized neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5506de88-628c-49f3-ba31-c77a310ed063",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "class UnregularizedRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, g, h, tau_over_dt=5):\n",
    "        super(UnregularizedRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.tau_over_dt = tau_over_dt\n",
    "        self.output_linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        # Weight initialization\n",
    "        self.J = nn.Parameter(torch.randn(hidden_size, hidden_size) * (g / torch.sqrt(torch.tensor(hidden_size, dtype=torch.float))))\n",
    "        self.B = nn.Parameter(torch.randn(hidden_size, input_size) * (h / torch.sqrt(torch.tensor(input_size, dtype=torch.float))))\n",
    "        self.bx = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "        # Nonlinearity\n",
    "        self.nonlinearity = rectified_tanh\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        #################################################\n",
    "        # TODO for students: fill in the missing variables\n",
    "        # Fill out function and remove\n",
    "        raise NotImplementedError(\"Student exercise: fill in the missing variables\")\n",
    "        #################################################\n",
    "\n",
    "        # Calculate the visible firing rate from the hidden state.\n",
    "        firing_rate_before = ...\n",
    "\n",
    "        # Update hidden state\n",
    "        recurrent_drive = torch.matmul(self.J, firing_rate_before.transpose(0, 1))\n",
    "        input_drive = torch.matmul(self.B, input.transpose(0, 1))\n",
    "        total_drive = recurrent_drive + input_drive + self.bx.unsqueeze(1)\n",
    "        total_drive = total_drive.transpose(0, 1)\n",
    "\n",
    "        # Euler integration for continuous-time update\n",
    "        hidden = hidden + (1 / self.tau_over_dt) * (-hidden + total_drive)\n",
    "\n",
    "        # Calculate the new firing rate given the update.\n",
    "        firing_rate = ...\n",
    "\n",
    "        # Project the firing rate linearly to form the output\n",
    "        output = ...\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(batch_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc083cb-b42c-4b73-bba7-a4ca5e03aaef",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# to_remove solution\n",
    "class UnregularizedRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, g, h, tau_over_dt=5):\n",
    "        super(UnregularizedRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.tau_over_dt = tau_over_dt\n",
    "        self.output_linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        # Weight initialization\n",
    "        self.J = nn.Parameter(torch.randn(hidden_size, hidden_size) * (g / torch.sqrt(torch.tensor(hidden_size, dtype=torch.float))))\n",
    "        self.B = nn.Parameter(torch.randn(hidden_size, input_size) * (h / torch.sqrt(torch.tensor(input_size, dtype=torch.float))))\n",
    "        self.bx = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "        # Nonlinearity\n",
    "        self.nonlinearity = rectified_tanh\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "\n",
    "        # Calculate the visible firing rate from the hidden state.\n",
    "        firing_rate_before = self.nonlinearity(hidden)\n",
    "\n",
    "        # Update hidden state\n",
    "        recurrent_drive = torch.matmul(self.J, firing_rate_before.transpose(0, 1))\n",
    "        input_drive = torch.matmul(self.B, input.transpose(0, 1))\n",
    "        total_drive = recurrent_drive + input_drive + self.bx.unsqueeze(1)\n",
    "        total_drive = total_drive.transpose(0, 1)\n",
    "\n",
    "        # Euler integration for continuous-time update\n",
    "        hidden = hidden + (1 / self.tau_over_dt) * (-hidden + total_drive)\n",
    "\n",
    "        # Calculate the new firing rate given the update.\n",
    "        firing_rate = self.nonlinearity(hidden)\n",
    "\n",
    "        # Project the firing rate linearly to form the output\n",
    "        output = self.output_linear(firing_rate)\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(batch_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6ae852-bdb1-40f3-bcff-cbab538aff60",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "input_size = 16\n",
    "hidden_size = 10\n",
    "output_size = 2\n",
    "g = 4\n",
    "h_val = 1.0\n",
    "\n",
    "model = UnregularizedRNN(input_size, hidden_size, output_size, g, h_val)\n",
    "model.to(device)\n",
    "\n",
    "for inputs, targets in unregularized_train_loader:\n",
    "    hidden = model.init_hidden(batch_size)\n",
    "    output, hidden_after = model(inputs[:, 0, :].to(device), hidden.to(device))\n",
    "    assert output.shape == targets[:, 0].shape\n",
    "    assert hidden_after.shape == hidden.shape\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f7f1ca-4eae-430c-b65f-4a8233c2db43",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Great! Now we have the model ready to go. \n",
    "\n",
    "Note: In further code below, we'll reference the `inputs` variable generated in the cell above (it will be from the last unpacking operation in `unregularized_train_loader`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8083bc3d-cfbd-43fd-928d-92f82d0eccb9",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_Coding_Exercise_2.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34983335-94bb-4150-836f-2f5db94ae5ad",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding exercise 2.2: Evaluate function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "R6ATQbbbkJDZ",
   "metadata": {
    "execution": {}
   },
   "source": [
    "A **trajectory** in the current context means a complete temporal sequence over the duration of each trial. We'll need a function that can generate an entire trajectory based on a set of inputs. To do that, we'll first initialize the hidden state of the model, then recurrently feed the inputs and the hidden states back into the model. Fill in the missing lines to generate an entire trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58ebe49-25fa-420b-a996-fa9095dbbf1c",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "def generate_trajectory(model, inputs, device):\n",
    "    #################################################\n",
    "    # TODO for students: fill in the missing variables\n",
    "    # Fill out function and remove\n",
    "    raise NotImplementedError(\"Student exercise: fill in the missing variables\")\n",
    "    #################################################\n",
    "    inputs = inputs.to(device)\n",
    "    batch_size = inputs.size(0)\n",
    "    h = ... #note that `UnregularizedRNN` has a specific method for that\n",
    "\n",
    "    loss = 0\n",
    "    outputs = []\n",
    "    hidden_states = []\n",
    "    with torch.no_grad():\n",
    "        for t in range(inputs.shape[1]):\n",
    "            # Forward the model's input and hidden state to obtain the model\n",
    "            # output and hidden state *h*.\n",
    "            # Note that you should index the input tensor by the time dimension\n",
    "            # Capture any additional outputs in 'rest'\n",
    "            output, h, *rest = ...\n",
    "            outputs.append(output)\n",
    "            hidden_states.append(h.detach().clone())\n",
    "\n",
    "    return torch.stack(outputs, axis=1).to(device), torch.stack(hidden_states, axis=1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QMEldftkmGPK",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "def generate_trajectory(model, inputs, device):\n",
    "    inputs = inputs.to(device)\n",
    "    batch_size = inputs.size(0)\n",
    "    h = model.init_hidden(batch_size).to(device) #note that `UnregularizedRNN` has a specific method for that\n",
    "\n",
    "    loss = 0\n",
    "    outputs = []\n",
    "    hidden_states = []\n",
    "    with torch.no_grad():\n",
    "        for t in range(inputs.shape[1]):\n",
    "            # Forward the model's input and hidden state to obtain the model\n",
    "            # output and hidden state *h*.\n",
    "            # Note that you should index the input tensor by the time dimension\n",
    "            # Capture any additional outputs in 'rest'\n",
    "            output, h, *rest = model(inputs[:, t], h)\n",
    "            outputs.append(output)\n",
    "            hidden_states.append(h.detach().clone())\n",
    "\n",
    "    return torch.stack(outputs, axis=1).to(device), torch.stack(hidden_states, axis=1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fb2c7c-4aa9-4824-a59c-1c76d8485210",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "trajectory, hidden_states = generate_trajectory(model,\n",
    "                                             inputs[0].unsqueeze(0),\n",
    "                                             device)\n",
    "\n",
    "with plt.xkcd():\n",
    "\n",
    "  # Remove unitary dimension, detach from PyTorch computational\n",
    "  # graph, move to the CPU and convert to a numpy array\n",
    "  hidden_states = hidden_states.squeeze().detach().cpu().numpy()\n",
    "  trajectory = trajectory.squeeze().detach().cpu().numpy()\n",
    "\n",
    "  plot_hidden_unit_activations(hidden_states=hidden_states,\n",
    "                               times=times,\n",
    "                               neurons_to_plot=7,\n",
    "                               title='Hidden units')\n",
    "  plot_muscles_over_time(times, trajectory, 'Generated muscle activity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd4f116-09e9-4392-9ea4-1c0cd78be2d0",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Remember, our model is untrained. It's not supposed to give great results yet. However, it's very good practice to see the outputs of an untrained network to get a sense of the starting position the model is at before any training has occurred. In some NeuroAI applications, untrained models can generate activity that is surprisingly similar to some brain activity in some scenarios, so it pays to know what your model *looks like* not only after training, but also before.\n",
    "\n",
    "This untrained model generates funky oscillatory activity, but we'll fix that during training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cea1ac-78b6-4704-8cc4-3f6d74921446",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_Coding_Exercise_2.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f006a913-0031-4882-8e87-55a5c30bb763",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Activity 2.1: Evaluating the model\n",
    "\n",
    "We're now ready to train our model. This involves:\n",
    "\n",
    "* Loading the data\n",
    "* Instantiating the model\n",
    "* Building a training loop\n",
    "* Using stochastic gradient descent (SGD) to train the model\n",
    "\n",
    "To save you time, however, we've trained the model in advance. You'll load a trained checkpoint. This trained model can generate the right muscle outputs in response to the right inputs. Let's do a quick check to make sure this is the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e611ab8b-f74f-4370-8dfb-51b00a436258",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "input_size  = 16\n",
    "hidden_size = 150\n",
    "output_size = 2  # Number of muscles\n",
    "g           = 4  # g value\n",
    "h_val       = 1.0  # h value\n",
    "\n",
    "unregularized_model = UnregularizedRNN(input_size, hidden_size, output_size, g, h_val)\n",
    "unregularized_model.to(device)  # Move model to the appropriate device\n",
    "\n",
    "# Load the pretrained model\n",
    "model_path = 'unregularized_model_final.pth'\n",
    "model_state_dict = torch.load(model_path, map_location=device)\n",
    "unregularized_model.load_state_dict(model_state_dict)\n",
    "unregularized_model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Example index\n",
    "idx = 0\n",
    "\n",
    "# Ensure data is on the correct device\n",
    "sample_input = normalised_inputs[train_idx[idx], ...].to(device)\n",
    "sample_target = outputs[train_idx[idx], ...].to(device)\n",
    "\n",
    "# Generate trajectory\n",
    "generated_target, hidden_states = generate_trajectory(unregularized_model, sample_input.unsqueeze(0), device)\n",
    "\n",
    "# Plotting\n",
    "plot_inputs_over_time(times, sample_input.cpu())\n",
    "plot_muscles_over_time(times, sample_target.cpu(), 'Targets')\n",
    "plot_muscles_over_time(times, generated_target.squeeze().detach().cpu().numpy(), 'Generated')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a37f05-d8c3-4750-bada-0fbe0c5f11f9",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Earlier, we just plotted the time course of the hidden activity and generated muscle activity. Now, we do the same but we also include the observed muscle activity, which is the target of our training procedure. This is so we can compare how good the model is at capturing the dynamics of the muscle data when the monkey performed the task.\n",
    "\n",
    "And as we can see, it does a pretty good job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751f7ddc-4b28-49c8-a3ab-74586b538d03",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_Model_Evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b372fc77-34c5-4f5d-b3bf-17a8adcef4be",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Activity 2.2: Comparing trained RNN with the brain\n",
    "\n",
    "Our trained RNN transforms a temporal sequence of inputs into a temporal sequence of muscle activations. In effect, the RNN is a *stand-in* (model) for motor cortex. The activity of the hidden units of the RNN might *look* like motor cortex. We plot different peri-stimulus temporal histograms (PSTHs) of **real neurons** when an animal performs a specific arm movement (reach condition). Then, we plot different PSTHs of hidden units of the unregularized RNN for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4656278f-bbaa-4823-ad28-325722a6453c",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "hidden_states = hidden_states.squeeze().detach().cpu().numpy()\n",
    "\n",
    "plot_hidden_unit_activations(hidden_states=hidden_states,\n",
    "                             times=times,\n",
    "                             neurons_to_plot=10,\n",
    "                             title='PSTHs of Hidden Units in UnregularizedRNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384b08b1-c0f8-48c8-877f-b6c119d70148",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Let's do the same now with real neural data. We load smoothed spiking data from Susillo et al. (2015). These are visualizations from trials where monkeys performed the same kind of reaching movement that we trained the artificial neural network to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442c4a80-abdb-4ca2-9cb1-a9162f30fa69",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat('m1_reaching_data.mat')\n",
    "plot_psth(data, neurons_to_plot=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb5c10a-6c62-443a-b7be-a0e8e50efec7",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Qualitatively, that doesn't look like much of a match. **A trained RNN that performs the same task as the brain can have very different latent representations**. In later tutorials, we'll cover in detail quantitative methods for evaluating how well representations in artificial and biological neural networks match each other; in particular. For now, let's try to get a qualitative match between the two PSTHs by applying better regularization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe04b3d-26f8-4748-8fe7-8bc14186897e",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_RNN_vs_Brain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cb1867-859d-4de6-91a8-858b8fa4de1f",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 3: Inductive Bias\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', 'O4cM86DcVUw'), ('Bilibili', 'BV1Gb421v7PH')]\n",
    "tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3926aac-d1e6-42fc-8dd0-b275e1b68204",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_inductive_bias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c1598f-aeea-45f2-81ca-afcb0be0c04b",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Section 3: Training a regularized task-driven neural network\n",
    "\n",
    "The previous network found complicated solutions to the problem of generating muscle activity: the hidden activity of the network didn't match to what we see in real neurons. We'd like to obtain more **naturalistic solutions** that better match the brain. We'll attempt this by regularizing this network. Later, we'll test this regularized network for robustness and generalization to see if this also affects the network's ability to extrapolate beyond its training data.\n",
    "\n",
    "Susillo et al. propose to regularize the network in many different ways.\n",
    "\n",
    "**Weight regularization**\n",
    "\n",
    "Synapses are expensive to grow and maintain. The authors thus propose to use a standard L2 penalty on the sum of squares of the weights:\n",
    "\n",
    "$$R_0 = \\sum_{ij} B_{ij}^2 + W_{ij}^2$$\n",
    "\n",
    "Recall that $W$ are the weights that map the RNN's latent activity to the predicted EMG data, while $B$ are the weights from the feedforward drive of the system. The penalty limits the magnitude of the weights, potentially leading to more biologically plausible solutions.\n",
    "\n",
    "**Firing rate regularization**\n",
    "\n",
    "Neural activity in biological neural networks is expensive. Thus, we add a penalty for the magnitude of the hidden activity in the network.\n",
    "\n",
    "$$R_1 = \\frac{1}{NT} \\sum_{it} r_{it} ^ 2$$\n",
    "\n",
    "Here $N$ is the number of hidden neurons and $T$ is the total number of discrete time steps in the simulation, and $r{it}$ is the activity of the hidden neurons over time.\n",
    "\n",
    "**Multiple delays**\n",
    "\n",
    "Neural activity should be robust to the exact delays between the preparatory input and the Go Cue. We augment the dataset with multiple delays between the signal and the Go Cue so that more varied examples exist that aren't closely tied to the exact starting time of the Go Cue. This means we become more robust to such vairiations, which also boosts generalization.\n",
    "\n",
    "**Less chaotic initialization regime**\n",
    "\n",
    "We initialized the previous RNN with large weights, putting the network in a chaotic regime, with high sensitivity to changes in activity. We'll dial down the initialization range in this network to obtain dynamics at the edge of chaos. In practice, this involves changing the parameter that controls the magnitude of the initial recurrent weights $g$ from 4 to 1.5.\n",
    "\n",
    "With all these changes in mind, we're ready to implement the regularized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ccb5ad-f7f7-46e6-83d7-e6f85818e683",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "class RegularizedRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, g, h, tau_over_dt=5):\n",
    "        super(RegularizedRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.tau_over_dt = tau_over_dt  # Time constant\n",
    "        self.output_linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        # Weight initialization\n",
    "        self.J = nn.Parameter(torch.randn(hidden_size, hidden_size) * (g / torch.sqrt(torch.tensor(hidden_size, dtype=torch.float))))\n",
    "        self.B = nn.Parameter(torch.randn(hidden_size, input_size) * (h / torch.sqrt(torch.tensor(input_size, dtype=torch.float))))\n",
    "        self.bx = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "        # Nonlinearity\n",
    "        self.nonlinearity = rectified_tanh\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # Calculate the visible firing rate from the hidden state.\n",
    "        firing_rate_before = self.nonlinearity(hidden)\n",
    "\n",
    "        # Update hidden state\n",
    "        recurrent_drive = torch.matmul(self.J, firing_rate_before.transpose(0, 1))\n",
    "        input_drive = torch.matmul(self.B, input.transpose(0, 1))\n",
    "        total_drive = recurrent_drive + input_drive + self.bx.unsqueeze(1)\n",
    "        total_drive = total_drive.transpose(0, 1)\n",
    "\n",
    "        # Euler integration for continuous-time update\n",
    "        hidden = hidden + (1 / self.tau_over_dt) * (-hidden + total_drive)\n",
    "\n",
    "        # Calculate the new firing rate given the update.\n",
    "        firing_rate = self.nonlinearity(hidden)\n",
    "\n",
    "        # Project the firing rate linearly to form the output\n",
    "        output = self.output_linear(firing_rate)\n",
    "\n",
    "        # Regularization terms (used for R1 calculation)\n",
    "        firing_rate_reg = firing_rate.pow(2).sum()\n",
    "\n",
    "        return output, hidden, firing_rate_reg\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # Initialize hidden state with batch dimension\n",
    "        return torch.zeros(batch_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ac6883-40d7-4426-9949-e30f0e404e86",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We split the dataset into training and validation sets. Importantly, we keep the different delays corresponding to the same condition in the same set. Otherwise, we might experience **data leakage**, where we inadvertently allow information about test set data to become part of our training data, leading to an overly optimistic accuracy when we come to evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cde5eda-c684-4d3f-87a7-e60a19f8955d",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "train_flattened_inputs = normalised_inputs_with_delay[train_idx].view(-1, *normalised_inputs_with_delay.shape[2:])\n",
    "train_flattened_targets = outputs_with_delay[train_idx].view(-1, *outputs_with_delay.shape[2:])\n",
    "\n",
    "val_flattened_inputs = normalised_inputs_with_delay[val_idx].view(-1, *normalised_inputs_with_delay.shape[2:])\n",
    "val_flattened_targets = outputs_with_delay[val_idx].view(-1, *outputs_with_delay.shape[2:])\n",
    "\n",
    "# Create the dataset with the fixed delay\n",
    "train_dataset = TimeseriesDataset(train_flattened_inputs, train_flattened_targets)\n",
    "val_dataset = TimeseriesDataset(val_flattened_inputs, val_flattened_targets)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 20\n",
    "regularized_train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "regularized_val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb0d107-0ff6-44a6-9017-8246b232e82c",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Activity 3.1: Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a273ae-dc6c-4d09-bee0-85ab251dec86",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Let's evaluate the model by looking at its generated activity! Once again, we skip the training of the model and load a model that has been trained previously, for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc591d7-e210-4920-ac32-aee771ea1cc7",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Instantiate model\n",
    "input_size = 16 # Features + Go Cue\n",
    "hidden_size = 150\n",
    "output_size = 2  # Number of muscles\n",
    "g = 1.5  # g value\n",
    "h_val = 1.0  # h value\n",
    "\n",
    "regularized_model = RegularizedRNN(input_size, hidden_size, output_size, g, h_val)\n",
    "regularized_model.to(device)  # Move model to the appropriate device\n",
    "\n",
    "# Load the pretrained model\n",
    "model_path = 'regularized_model_final.pth'\n",
    "model_state_dict = torch.load(model_path, map_location=device)\n",
    "regularized_model.load_state_dict(model_state_dict)\n",
    "regularized_model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Example index\n",
    "idx = 0\n",
    "\n",
    "# Ensure data is on the correct device\n",
    "sample_input = normalised_inputs[train_idx[idx], ...].to(device)\n",
    "sample_target = outputs[train_idx[idx], ...].to(device)\n",
    "\n",
    "# Generate trajectory\n",
    "generated_target, hidden_states = generate_trajectory(regularized_model, sample_input.unsqueeze(0), device)\n",
    "\n",
    "# Plotting\n",
    "plot_inputs_over_time(times, sample_input.cpu())\n",
    "plot_muscles_over_time(times, sample_target.cpu(), 'Targets')\n",
    "plot_muscles_over_time(times, generated_target.squeeze().detach().cpu().numpy(), 'Generated')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5963c61d-96fe-4613-b6cb-466d9b38440f",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Looks promising! But what do the RNN's latent / hidden representations look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb65cba-8003-40e8-ae95-1401cfc6f5ca",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_Regularized_Model_Evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e85237-251e-4282-8442-5bad0793872d",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Activity 3.2: Comparing trained RNN with real data\n",
    "\n",
    "Let's see if this regularized network's activity is aligned with the brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d669ec7-9a47-450f-a4c9-080c1169833d",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "hidden_states=hidden_states.squeeze().detach().cpu().numpy() \n",
    "\n",
    "plot_hidden_unit_activations(hidden_states=hidden_states,\n",
    "                             times=times,\n",
    "                             neurons_to_plot=10,\n",
    "                             title='PSTHs of Hidden Units in RegularizedRNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bd5cbe-6441-44a7-95e2-3f7c24da0949",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "plot_psth(data, neurons_to_plot=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b990c0a7-2eea-4445-bf33-74d4a45fa46f",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_Regularized_RNN_vs_Brain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445e313b-8209-4553-bd47-5ba6a331af17",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Discussion point\n",
    "\n",
    "1. Which RNN (a. untrained, b. trained without regularization, c. trained with regularization) looks more like the real brain data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca1a56a-5269-4ad8-9263-065323ed0640",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_Discussion_Point\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99f992e-4379-40c6-af6d-8680595dfb01",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 4: A brain-like network\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', '45gbldrYfHo'), ('Bilibili', 'BV1er421c7Uu')]\n",
    "tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd7fb29-d7a8-424b-afc3-cbc9cabbd249",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_a_brain_like_network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e552086-0cbc-4f39-8e87-6bce1a05a43f",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Section 4: Robustness to change in RNNs and the brain\n",
    "\n",
    "In this section, we perturb our regularized and unregularized inputs and structural connectivity by adding random noise to the inputs to replicate a noisy recording device. This in essence means the new inputs to the model will contain true signal as well as random noise that is not connected to the true signal.\n",
    "\n",
    "Will regularization help the neural network be more resilient to these changes?\n",
    "\n",
    "Let's start by perturbing the inputs. For this purpose, we use the smaller train dataset without delay augmentations (See Section 3: Multiple Delays, above, for an explanation of delay augmentations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750ee71a-25d9-4042-a0de-cc6db1c7bdde",
   "metadata": {
    "execution": {},
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "test_dataset = TimeseriesDataset(normalised_inputs[train_idx], outputs[train_idx])\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ee0281-a790-4cce-b4f2-2bd0e8da93a6",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "def perturb_inputs(model, inputs, perturbation_strength):\n",
    "    device = inputs.device\n",
    "    # Perturb the inputs by adding random noise scaled by the perturbation strength and input strength\n",
    "    input_strength = torch.norm(inputs, p=2, dim=-1, keepdim=True)  # Calculate the L2 norm of inputs\n",
    "    noise = torch.rand(inputs.shape[0], 1, inputs.shape[2], device=device) * perturbation_strength * input_strength\n",
    "    perturbed_inputs = inputs + noise\n",
    "    return perturbed_inputs\n",
    "\n",
    "def compute_loss(model, inputs, targets, criterion, device):\n",
    "    batch_size = inputs.size(0)\n",
    "    h = model.init_hidden(batch_size).to(device)  # Initialize hidden state\n",
    "    losses = []\n",
    "    for t in range(inputs.shape[1]):  # Iterate over time steps\n",
    "        model_output = model(inputs[:, t, :], h)\n",
    "        output, h, *rest = model_output[:2]\n",
    "        loss = criterion(output, targets[:, t])  # Assume targets is a sequence of same length as inputs\n",
    "        losses.append(loss)\n",
    "    mean_loss = torch.mean(torch.stack(losses)).item()\n",
    "    return mean_loss\n",
    "\n",
    "def test_perturbed_inputs(model, perturbation_strengths, test_loader, criterion, device, max_error):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    perturbation_results = []\n",
    "\n",
    "    for strength in perturbation_strengths:\n",
    "        all_errors = []  # Store all errors for each perturbation strength to compute mean and s.d.\n",
    "        print(f\"Testing perturbation strength {strength}\")\n",
    "        for iteration in tqdm(range(30)):  # Repeat the procedure 30 times\n",
    "            batch_errors = []  # Store errors for each batch\n",
    "\n",
    "            for inputs, targets in test_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                # Compute error for original inputs\n",
    "                # original_loss = compute_loss(model, inputs, targets, criterion, device)\n",
    "                # Compute error for perturbed inputs\n",
    "\n",
    "                perturbed_inputs = perturb_inputs(model, inputs, strength)\n",
    "                perturbed_loss = compute_loss(model, perturbed_inputs, targets, criterion, device)\n",
    "\n",
    "                # Store the normalized error.\n",
    "                rel_error = perturbed_loss / max_error * 100\n",
    "                batch_errors.append(rel_error)\n",
    "\n",
    "            all_errors.extend(batch_errors)\n",
    "\n",
    "        mean_error = np.mean(all_errors)\n",
    "        std_error = np.std(all_errors)\n",
    "        perturbation_results.append((mean_error, std_error))\n",
    "        print(f\"Completed testing for perturbation strength {strength}.\")\n",
    "\n",
    "    return perturbation_results\n",
    "\n",
    "# Calculate the maximum error for a null model, the error when the output is constant.\n",
    "max_error = ((outputs - outputs.mean(axis=[0, 1], keepdims=True)) ** 2).mean()\n",
    "\n",
    "perturbation_strengths = [0.0125, 0.025, 0.05, 0.1, 0.2]\n",
    "results_unregularized = test_perturbed_inputs(unregularized_model, perturbation_strengths, test_loader, nn.MSELoss(), device, max_error)\n",
    "results_regularized = test_perturbed_inputs(regularized_model, perturbation_strengths, test_loader, nn.MSELoss(), device, max_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1268bf57-9f00-4acb-b181-f025c65b3b38",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#Plot perturbation results\n",
    "plot_perturbation_results(perturbation_strengths, results_regularized, results_unregularized, \"Perturbation of the inputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e354427f-f371-4fff-aecd-8c835e2a6c63",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Note here that the higher the bars, the more errors the model has (the worse it performs). On the X-axis, we can see the magnitude of the perturbation. For small perturbations, the regularized model (blue bars) performs better than the unregularized model (red bars) for most of the perturbation strengths. When the perturbation magnitude is large, then we start to see that the regularized model starts to perform worse.\n",
    "\n",
    "Now, we proceed to a different type of perturbation: this time on the model weights (not the inputs)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b31e7ef-e4dc-472a-98f8-251f82a6b2ca",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding exercise 4.1: Weights perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043936ab-106f-49fa-98e0-68833273c903",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "def calculate_mean_absolute_strength(model):\n",
    "    # Calculate the mean absolute connection strength of the recurrent weight matrix\n",
    "    return torch.mean(torch.abs(model.J)).item()\n",
    "\n",
    "def perturb_recurrent_weights(model, mean_strength, perturbation_percentage):\n",
    "    ###########################################################\n",
    "    # Fill in the missing lines to complete the exercise\n",
    "    raise NotImplementedError(\"Student exercise\")\n",
    "    ###########################################################\n",
    "    perturbation_strength = ... * ...\n",
    "    with torch.no_grad():\n",
    "        noise = torch.randn_like(model.J) * perturbation_strength\n",
    "        perturbed_weights = model.J + noise\n",
    "        return perturbed_weights\n",
    "\n",
    "def test_perturbed_structure(model, perturbation_percentages, test_loader, criterion, device, max_error):\n",
    "    ###########################################################\n",
    "    # Fill in the missing lines to complete the exercise\n",
    "    raise NotImplementedError(\"Student exercise\")\n",
    "    ###########################################################\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    mean_strength = calculate_mean_absolute_strength(model)\n",
    "    perturbation_results = []  # List to store (mean error, std dev) tuples\n",
    "\n",
    "    original_weights = model.J.data.clone()  # Save the original weights\n",
    "\n",
    "    for percentage in ...:\n",
    "        multiple_perturbations_error = []\n",
    "        print(f\"Testing perturbation percentage {percentage:.4f}\")\n",
    "\n",
    "        for perturbation in tqdm(range(30)):  # Perturb 30 times for each strength\n",
    "            batch_errors = []\n",
    "            perturbed_weights = perturb_recurrent_weights(model, mean_strength, percentage)\n",
    "            model.J.data = perturbed_weights.data\n",
    "\n",
    "            for inputs, targets in test_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                batch_size = inputs.size(0)\n",
    "                h = model.init_hidden(batch_size).to(device)\n",
    "\n",
    "                outputs = torch.zeros_like(targets).to(device)\n",
    "                for t in range(inputs.shape[1]):\n",
    "                    output, h, *rest = ...\n",
    "                    outputs[:, t, :] = output\n",
    "\n",
    "                loss = criterion(outputs, targets).item()\n",
    "                batch_errors.append(loss)\n",
    "\n",
    "            # Reset to original weights after each perturbation\n",
    "            model.J.data = original_weights.data\n",
    "            multiple_perturbations_error.append(np.mean(batch_errors))\n",
    "\n",
    "        mean_error = np.mean(multiple_perturbations_error)  # Average over the 50 perturbations\n",
    "        std_dev_error = np.std(multiple_perturbations_error)  # Standard deviation for error bars\n",
    "        perturbation_results.append((100 * mean_error / max_error, 100 * std_dev_error / max_error))\n",
    "\n",
    "        # Normalize the errors\n",
    "        print(f\"Completed testing for perturbation percentage {percentage:.4f}. Mean error: {mean_error:.4f}, Std. dev.: {std_dev_error:.4f}\\n\")\n",
    "\n",
    "    return perturbation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb42315-b28f-4d77-a550-e2644f26c207",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# to_remove solution\n",
    "\n",
    "def calculate_mean_absolute_strength(model):\n",
    "    # Calculate the mean absolute connection strength of the recurrent weight matrix\n",
    "    return torch.mean(torch.abs(model.J)).item()\n",
    "\n",
    "def perturb_recurrent_weights(model, mean_strength, perturbation_percentage):\n",
    "    perturbation_strength = mean_strength * perturbation_percentage\n",
    "    with torch.no_grad():\n",
    "        noise = torch.randn_like(model.J) * perturbation_strength\n",
    "        perturbed_weights = model.J + noise\n",
    "        return perturbed_weights\n",
    "\n",
    "def test_perturbed_structure(model, perturbation_percentages, test_loader, criterion, device, max_error):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    mean_strength = calculate_mean_absolute_strength(model)\n",
    "    perturbation_results = []  # List to store (mean error, std dev) tuples\n",
    "\n",
    "    original_weights = model.J.data.clone()  # Save the original weights\n",
    "\n",
    "    for percentage in perturbation_percentages:\n",
    "        multiple_perturbations_error = []\n",
    "        print(f\"Testing perturbation percentage {percentage:.4f}\")\n",
    "\n",
    "        for perturbation in tqdm(range(30)):  # Perturb 30 times for each strength\n",
    "            batch_errors = []\n",
    "            perturbed_weights = perturb_recurrent_weights(model, mean_strength, percentage)\n",
    "            model.J.data = perturbed_weights.data\n",
    "\n",
    "            for inputs, targets in test_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                batch_size = inputs.size(0)\n",
    "                h = model.init_hidden(batch_size).to(device)\n",
    "\n",
    "                outputs = torch.zeros_like(targets).to(device)\n",
    "                for t in range(inputs.shape[1]):\n",
    "                    output, h, *rest = model(inputs[:, t, :], h)\n",
    "                    outputs[:, t, :] = output\n",
    "\n",
    "                loss = criterion(outputs, targets).item()\n",
    "                batch_errors.append(loss)\n",
    "\n",
    "            # Reset to original weights after each perturbation\n",
    "            model.J.data = original_weights.data\n",
    "            multiple_perturbations_error.append(np.mean(batch_errors))\n",
    "\n",
    "        mean_error = np.mean(multiple_perturbations_error)  # Average over the 50 perturbations\n",
    "        std_dev_error = np.std(multiple_perturbations_error)  # Standard deviation for error bars\n",
    "        perturbation_results.append((100 * mean_error / max_error, 100 * std_dev_error / max_error))\n",
    "\n",
    "        # Normalize the errors\n",
    "        print(f\"Completed testing for perturbation percentage {percentage:.4f}. Mean error: {mean_error:.4f}, Std. dev.: {std_dev_error:.4f}\\n\")\n",
    "\n",
    "    return perturbation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88117520-dcf8-4c8e-9874-2834ee451a1c",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Calculate the maximum error for a null model, the error when the output is constant.\n",
    "max_error = ((outputs - outputs.mean(axis=[0, 1], keepdims=True)) ** 2).mean()\n",
    "\n",
    "# Define perturbation strengths as percentages\n",
    "perturbation_strengths = [0.01, .1, .2, .4, .8]\n",
    "\n",
    "# Function calls for regularized and unregularized models\n",
    "results_regularized_weights = test_perturbed_structure(regularized_model, perturbation_strengths, test_loader, nn.MSELoss(), device, max_error)\n",
    "results_unregularized_weights = test_perturbed_structure(unregularized_model, perturbation_strengths, test_loader, nn.MSELoss(), device, max_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f40c9a9-3429-4b69-a693-5016c9c3319c",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Plot perturbation results\n",
    "plot_perturbation_results(perturbation_strengths, results_regularized_weights, results_unregularized_weights, \"Perturbation of the weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9218f3e2-9029-4317-a9ed-03bd3ea80f54",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_Weights_Perturbation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3447c1f5-31b2-4bce-ad0c-f4ce2e05f70b",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Discussion point 1\n",
    "\n",
    "Why is the regularized RNN more resistant to noise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8867a817-c05c-4a61-97d4-7cd8adb3e3ab",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_Discussion_Point_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcc771e-7e6a-4c83-a481-943e14e401bc",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Discussion point 2\n",
    "\n",
    "Is the regularized RNN “how the brain works” in the motor cortex? If not, why is it useful to model this way? Does this experiment suggest that a system that can perform a task and generalize well is necessarily brain-like? If not, what else is required? Plasticity? Complex decision-making? Sensory integration? Agency? Autonomy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63306328-47a4-458e-9df1-b6341ede66c2",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_Discussion_Point_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d19e8b-6bd4-4f2b-8f8a-c699ac9e57ee",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 5: Final Thoughts\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', 'iIjGOqc8lLw'), ('Bilibili', 'BV1CS411P77f')]\n",
    "tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdcec9f-8918-4e51-a317-ab123e220f5c",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_final_thoughts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5a94df-de87-4e42-b65b-a292cfaad9b0",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# The Big Picture\n",
    "\n",
    "* Neuroscientists often want to uncover *how* the brain performs a task.\n",
    "* Artificial neural networks are a useful tool for investigating how a computation might be performed.\n",
    "* We often care about biological plausibility: the operations performed by the network should roughly match those that the brain can perform. For instance, while RNNs have been surpassed by transformers for natural language processing, they remain popular in neuroscience.\n",
    "* Neuroscientists often care about whether a model generalizes across circumstances that an organism might face.\n",
    "* We tested robustness to noise (e.g. neural noise) and robustness to weight changes (e.g. rollover in synapses) across different models and found regularized models offered a useful **inductive bias** which generalized better.\n",
    "* Inductive biases such as preferring simpler models (like in the Sussillo paper) often lead to models that more closely resemble real neural data.\n",
    "* The tools to improve generalization in task-driven neural networks are similar to the ones used in AI more generally: regularization, augmentations, but also potentially pretraining the model and transfer learning.\n",
    "* Networks that perform similar tasks to the brain **and** generalize well *sometimes* converge to similar solutions to the brain. We don't fully understand this phenomenon, and we'll introduce tools throughout the course to more quantitatively assess the correspondence."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "gpuType": "T4",
   "include_colab_link": true,
   "name": "W1D1_Tutorial2",
   "provenance": [],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
