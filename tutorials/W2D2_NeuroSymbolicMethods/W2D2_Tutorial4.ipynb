{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {},
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/neuromatch/NeuroAI_Course/blob/main/tutorials/W2D2_NeuroSymbolicMethods/student/W2D2_Tutorial4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> &nbsp; <a href=\"https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/neuromatch/NeuroAI_Course/main/tutorials/W2D2_NeuroSymbolicMethods/student/W2D2_Tutorial4.ipynb\" target=\"_parent\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open in Kaggle\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# (BONUS) Tutorial 4: VSA Analogies\n",
    "\n",
    "**Week 2, Day 2: Neuro-Symbolic Methods**\n",
    "\n",
    "**By Neuromatch Academy**\n",
    "\n",
    "__Content creators:__ P. Michael Furlong, Chris Eliasmith\n",
    "\n",
    "__Content reviewers:__ Hlib Solodzhuk, Patrick Mineault, Aakash Agrawal, Alish Dipani, Hossein Rezaei, Yousef Ghanbari, Mostafa Abdollahi, Alex Murphy\n",
    "\n",
    "__Production editors:__ Konstantine Tsafatinos, Ella Batty, Spiros Chavlis, Samuele Bolotta, Hlib Solodzhuk, Alex Murphy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "___\n",
    "\n",
    "\n",
    "# Tutorial Objectives\n",
    "\n",
    "This tutorial will present you with a couple of toy examples using the basic operations of vector symbolic algebras. We will further show how these can generalize to new knowledge. If you are familiar with the basics of semantic algebra on word embeddings, you already understand the basics of what we'll be demonstrating in this tutorial. If not, don't worry, this tutorial is designed to be highly self-contained. If you're interested in learning more about word embedding algebra, then we encourage you to use your search engine of choice and learn more after completing the code exercises given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Tutorial slides\n",
    "# @markdown These are the slides for the videos in all tutorials today\n",
    "\n",
    "from IPython.display import IFrame\n",
    "link_id = \"jybuw\"\n",
    "\n",
    "print(f\"If you want to download the slides: 'https://osf.io/download/{link_id}'\")\n",
    "\n",
    "IFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{link_id}/?direct%26mode=render\", width=854, height=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Setup (Colab Users: Please Read)\n",
    "\n",
    "Note that because this tutorial relies on some special Python packages, these packages have requirements for specific versions of common scientific libraries, such as `numpy`. If you're in Google Colab, then as of May 2025, this comes with a later version (2.0.2) pre-installed. We require an older version (we'll be installing `1.24.4`). This causes Colab to force a session restart and then re-running of the installation cells for the new version to take effect. When you run the cell below, you will be prompted to restart the session. This is *entirely expected* and you haven't done anything wrong. Simply click 'Restart' and then run the cells as normal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Install dependencies and import feedback gadget\n",
    "\n",
    "!pip install numpy==1.24.4 --quiet\n",
    "!pip install scikit-learn==1.6.1 --quiet\n",
    "!pip install scipy==1.15.3 --quiet\n",
    "!pip install git+https://github.com/neuromatch/sspspace@neuromatch --no-deps --quiet\n",
    "!pip install nengo==4.0.0 --quiet\n",
    "!pip install nengo_spa==2.0.0 --quiet\n",
    "!pip install --quiet matplotlib ipywidgets vibecheck\n",
    "!pip install --quiet numpy matplotlib ipywidgets scipy scikit-learn vibecheck\n",
    "\n",
    "from vibecheck import DatatopsContentReviewContainer\n",
    "def content_review(notebook_section: str):\n",
    "    return DatatopsContentReviewContainer(\n",
    "        \"\",  # No text prompt\n",
    "        notebook_section,\n",
    "        {\n",
    "            \"url\": \"https://pmyvdlilci.execute-api.us-east-1.amazonaws.com/klab\",\n",
    "            \"name\": \"neuromatch_neuroai\",\n",
    "            \"user_key\": \"wb2cxze8\",\n",
    "        },\n",
    "    ).render()\n",
    "\n",
    "\n",
    "feedback_prefix = \"W2D2_T4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Notice that exactly the `neuromatch` branch of `sspspace` should be installed! Otherwise, some of the functionality (like `optimize` parameter in the `DiscreteSPSpace` initialization) won't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Imports\n",
    "\n",
    "#working with data\n",
    "import numpy as np\n",
    "\n",
    "#plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "#interactive display\n",
    "# import ipywidgets as widgets\n",
    "\n",
    "#modeling\n",
    "import sspspace\n",
    "import nengo_spa as spa\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from nengo_spa.algebras.hrr_algebra import HrrProperties, HrrAlgebra\n",
    "from nengo_spa.vector_generation import VectorsWithProperties\n",
    "\n",
    "def make_vocabulary(vector_length):\n",
    "    vec_generator = VectorsWithProperties(vector_length, algebra=HrrAlgebra(), properties = [HrrProperties.UNITARY, HrrProperties.POSITIVE])\n",
    "    vocab = spa.Vocabulary(vector_length, pointer_gen=vec_generator)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Figure settings\n",
    "\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' # perfrom high definition rendering for images and plots\n",
    "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/nma.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Plotting functions\n",
    "\n",
    "def plot_similarity_matrix(sim_mat, labels, values = False):\n",
    "    \"\"\"\n",
    "    Plot the similarity matrix between vectors.\n",
    "\n",
    "    Inputs:\n",
    "    - sim_mat (numpy.ndarray): similarity matrix between vectors.\n",
    "    - labels (list of str): list of strings which represent concepts.\n",
    "    - values (bool): True if we would like to plot values of similarity too.\n",
    "    \"\"\"\n",
    "    with plt.xkcd():\n",
    "        plt.imshow(sim_mat, cmap='Greys')\n",
    "        plt.colorbar()\n",
    "        plt.xticks(np.arange(len(labels)), labels, rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "        plt.yticks(np.arange(len(labels)), labels)\n",
    "        if values:\n",
    "            for x in range(sim_mat.shape[1]):\n",
    "                for y in range(sim_mat.shape[0]):\n",
    "                    plt.text(x, y, f\"{sim_mat[y, x]:.2f}\", fontsize = 8, ha=\"center\", va=\"center\", color=\"green\")\n",
    "        plt.title('Similarity between vector-symbols')\n",
    "        plt.xlabel('Symbols')\n",
    "        plt.ylabel('Symbols')\n",
    "        plt.show()\n",
    "\n",
    "def plot_training_and_choice(losses, sims, ant_names, cons_names, action_names):\n",
    "    \"\"\"\n",
    "    Plot loss progression over training as well as predicted similarities for given rules / correct solutions.\n",
    "\n",
    "    Inputs:\n",
    "    - losses (list): list of loss values.\n",
    "    - sims (list): list of similartiy matrices.\n",
    "    - ant_names (list): list of antecedance names.\n",
    "    - cons_names (list): list of consequent names.\n",
    "    - action_names (list): full list of concepts.\n",
    "    \"\"\"\n",
    "    with plt.xkcd():\n",
    "        plt.subplot(1, len(ant_names) + 1, 1)\n",
    "        plt.plot(losses)\n",
    "        plt.xlabel('Training number')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training Error')\n",
    "        index = 1\n",
    "        for ant_name, cons_name, sim in zip(ant_names, cons_names, sims):\n",
    "            index += 1\n",
    "            plt.subplot(1, len(ant_names) + 1, index)\n",
    "            plt.bar(range(len(action_names)), sim.flatten())\n",
    "            plt.gca().set_xticks(range(len(action_names)))\n",
    "            plt.gca().set_xticklabels(action_names, rotation=90)\n",
    "            plt.title(f'{ant_name}, not*{cons_name}')\n",
    "\n",
    "def plot_choice(sims, ant_names, cons_names, action_names):\n",
    "    \"\"\"\n",
    "    Plot predicted similarities for given rules / correct solutions.\n",
    "    \"\"\"\n",
    "    with plt.xkcd():\n",
    "        index = 0\n",
    "        for ant_name, cons_name, sim in zip(ant_names, cons_names, sims):\n",
    "            index += 1\n",
    "            plt.subplot(1, len(ant_names) + 1, index)\n",
    "            plt.bar(range(len(action_names)), sim.flatten())\n",
    "            plt.gca().set_xticks(range(len(action_names)))\n",
    "            plt.gca().set_xticklabels(action_names, rotation=90)\n",
    "            plt.ylabel(\"Similarity\")\n",
    "            plt.title(f'{ant_name}, not*{cons_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Set random seed\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def set_seed(seed=None):\n",
    "  if seed is None:\n",
    "    seed = np.random.choice(2 ** 32)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "\n",
    "set_seed(seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Helper functions\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "symbol_names = ['monarch','heir','male','female']\n",
    "discrete_space = sspspace.DiscreteSPSpace(symbol_names, ssp_dim=1024, optimize=False)\n",
    "\n",
    "objs = {n:discrete_space.encode(n) for n in symbol_names}\n",
    "\n",
    "objs['king'] = objs['monarch'] * objs['male']\n",
    "objs['queen'] = objs['monarch'] * objs['female']\n",
    "objs['prince'] = objs['heir'] * objs['male']\n",
    "objs['princess'] = objs['heir'] * objs['female']\n",
    "\n",
    "bundle_objs = {n:discrete_space.encode(n) for n in symbol_names}\n",
    "\n",
    "bundle_objs['king'] = (bundle_objs['monarch'] + bundle_objs['male']).normalize()\n",
    "bundle_objs['queen'] = (bundle_objs['monarch'] + bundle_objs['female']).normalize()\n",
    "bundle_objs['prince'] = (bundle_objs['heir'] + bundle_objs['male']).normalize()\n",
    "bundle_objs['princess'] = (bundle_objs['heir'] + bundle_objs['female']).normalize()\n",
    "\n",
    "bundle_objs['princess_query'] = (bundle_objs['prince'] - bundle_objs['king']) + bundle_objs['queen']\n",
    "\n",
    "new_symbol_names = ['dollar', 'peso', 'ottawa', 'mexico-city', 'currency', 'capital']\n",
    "new_discrete_space = sspspace.DiscreteSPSpace(new_symbol_names, ssp_dim=1024, optimize=False)\n",
    "\n",
    "new_objs = {n:new_discrete_space.encode(n) for n in new_symbol_names}\n",
    "\n",
    "cleanup = sspspace.Cleanup(new_objs)\n",
    "\n",
    "new_objs['canada'] = ((new_objs['currency'] * new_objs['dollar']) + (new_objs['capital'] * new_objs['ottawa'])).normalize()\n",
    "new_objs['mexico'] = ((new_objs['currency'] * new_objs['peso']) + (new_objs['capital'] * new_objs['mexico-city'])).normalize()\n",
    "\n",
    "card_states = ['red','blue','odd','even','not','green','prime','implies','ant','relation','cons']\n",
    "encoder = sspspace.DiscreteSPSpace(card_states, ssp_dim=1024, optimize=False)\n",
    "vocab = {c:encoder.encode(c) for c in card_states}\n",
    "\n",
    "for a in ['red','blue','odd','even','green','prime']:\n",
    "    vocab[f'not*{a}'] = vocab['not'] * vocab[a]\n",
    "\n",
    "action_names = ['red','blue','odd','even','green','prime','not*red','not*blue','not*odd','not*even','not*green','not*prime']\n",
    "action_space = np.array([vocab[x] for x in action_names]).squeeze()\n",
    "\n",
    "rules = [\n",
    "    (vocab['ant'] * vocab['blue'] + vocab['relation'] * vocab['implies'] + vocab['cons'] * vocab['even']).normalize(),\n",
    "    (vocab['ant'] * vocab['odd'] + vocab['relation'] * vocab['implies'] + vocab['cons'] * vocab['green']).normalize(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "\n",
    "# Section 1: Analogies. Part 1\n",
    "\n",
    "In this section we will construct a simple analogy using Vector Symbolic Algebras. The question we are going to try and solve is \"King is to the queen as the prince is to X.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 1: Analogy 1\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', '2tR4fHvL1Jk'), ('Bilibili', 'BV1fS411P7Ez')]\n",
    "tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_analogy_part_one\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding Exercise 1: Royal Relationships\n",
    "\n",
    "We're going to start by considering our vocabulary. We will use the basic discrete concepts of monarch, heir, male, and female."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Let's create the objects we know about by combinatorially expanding the space: \n",
    "\n",
    "1. King is a male monarch\n",
    "2. Queen is a female monarch\n",
    "3. Prince is a male heir\n",
    "4. Princess is a female heir\n",
    "\n",
    "Complete the missing parts of the code to obtain correct representations of new concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "vector_length = 1024\n",
    "symbol_names = ['MONARCH', 'HEIR', 'MALE', 'FEMALE']\n",
    "vocab = make_vocabulary(vector_length)\n",
    "vocab.populate(';'.join(symbol_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete correct relations for creating new concepts.\")\n",
    "\n",
    "###################################################################\n",
    "vocab.add('KING', vocab['MONARCH'] * vocab['MALE'])\n",
    "vocab.add('QUEEN', vocab['MONARCH'] * ...)\n",
    "vocab.add('PRINCE', vocab['HEIR'] * vocab['MALE'])\n",
    "vocab.add('PRINCESS', ... * vocab['FEMALE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "vocab.add('KING', vocab['MONARCH'] * vocab['MALE'])\n",
    "vocab.add('QUEEN', vocab['MONARCH'] * vocab['FEMALE'])\n",
    "vocab.add('PRINCE', vocab['HEIR'] * vocab['MALE'])\n",
    "vocab.add('PRINCESS', vocab['HEIR'] * vocab['FEMALE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now, we can take an explicit approach. We know that the conversion from king to queen is to unbind male and bind female, so let's apply that to our prince object and see what we uncover.\n",
    "\n",
    "At first, in the cell below, let's recover `queen` from `king` by constructing a new `query` concept, which represents the unbinding of `male` and the binding of `female.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete correct relation for creating `query` object to compare with `queen`.\")\n",
    "###################################################################\n",
    "\n",
    "vocab.add('QUERY_QUEEN', (vocab[...] * ~vocab[...]) * vocab[...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "vocab.add('QUERY_QUEEN', (vocab['KING'] * ~vocab['MALE']) * vocab['FEMALE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's see if this new query object bears any similarity to anything in our vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_names = list(vocab.keys())\n",
    "sims = np.zeros((len(object_names), len(object_names)))\n",
    "\n",
    "for name_idx, name in enumerate(object_names):\n",
    "    for other_idx in range(name_idx, len(object_names)):\n",
    "        sims[name_idx, other_idx] = sims[other_idx, name_idx] = spa.dot(vocab[name], vocab[object_names[other_idx]])\n",
    "\n",
    "plot_similarity_matrix(sims, object_names, values = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "The above similarity plot shows that applying that operation successfully converts king to queen. Let's apply it to 'prince' and see what happens. Now, `query` should represent the `princess` concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "vocab.add('QUERY_PRINCESS', (vocab['PRINCE'] * ~vocab['MALE']) * vocab['FEMALE'])\n",
    "\n",
    "sims = np.zeros((len(object_names), len(object_names)))\n",
    "\n",
    "for name_idx, name in enumerate(object_names):\n",
    "    for other_idx in range(name_idx, len(object_names)):\n",
    "        sims[name_idx, other_idx] = sims[other_idx, name_idx] = spa.dot(vocab[name], vocab[object_names[other_idx]])\n",
    "\n",
    "plot_similarity_matrix(sims, object_names, values = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Here, we have successfully recovered the princess, completing the analogy.\n",
    "\n",
    "This approach, however, requires explicit knowledge of the construction of the objects.  Let's see if we can just work with the concepts of 'king,' 'queen,' and 'prince' directly.\n",
    "\n",
    "In the cell below, construct the `princess` concept using only `king,` `queen`, and `prince.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete correct relation for creating `query` object to compare with `princess`.\")\n",
    "###################################################################\n",
    "\n",
    "vocab.add('QUERY_PRINCESS_2', (vocab[...] * ~vocab[...]) * vocab[...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "# objs['query'] = (objs['prince'] * ~objs['king']) * objs['queen']\n",
    "vocab.add('QUERY_PRINCESS_2', (vocab['PRINCE'] * ~vocab['KING']) * vocab['QUEEN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_names = list(vocab.keys())\n",
    "sims = np.zeros((len(object_names), len(object_names)))\n",
    "\n",
    "for name_idx, name in enumerate(object_names):\n",
    "    for other_idx in range(name_idx, len(object_names)):\n",
    "        sims[name_idx, other_idx] = sims[other_idx, name_idx] = spa.dot(vocab[name], vocab[object_names[other_idx]])\n",
    "\n",
    "plot_similarity_matrix(sims, object_names, values = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Again, we see that we have recovered the princess by using our analogy.\n",
    "\n",
    "That said, the above depends on knowing that the representations are constructed using binding. Can we do something similar through the bundling operation? Let's try that out.\n",
    "\n",
    "Reassing concept definitions using bundling operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "vocab = vocab.create_subset(['MONARCH','HEIR','FEMALE','MALE'])\n",
    "vocab.add('KING', (vocab['MONARCH'] + vocab['MALE']).normalized())\n",
    "vocab.add('QUEEN', (vocab['MONARCH'] + vocab['FEMALE']).normalized())\n",
    "vocab.add('PRINCE', (vocab['HEIR'] + vocab['MALE']).normalized())\n",
    "vocab.add('PRINCESS', (vocab['HEIR'] + vocab['FEMALE']).normalized())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "But now that we are using an additive model, we need to take a different approach. Instead of unbinding the king and binding the queen, we subtract the king and add the queen to find the princess from the prince.\n",
    "\n",
    "Complete the code to reflect the updated mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete correct relation for creating `query` object to compare with `princess`.\")\n",
    "###################################################################\n",
    "\n",
    "vocab.add('QUERY_PRINCESS', ((vocab[...] - vocab[...]) + vocab[...]).normalized())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "vocab.add('QUERY_PRINCESS', ((vocab['PRINCE'] - vocab['KING']) + vocab['QUEEN']).normalized())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "object_names = list(vocab.keys())\n",
    "sims = np.zeros((len(object_names), len(object_names)))\n",
    "\n",
    "for name_idx, name in enumerate(object_names):\n",
    "    for other_idx in range(name_idx, len(object_names)):\n",
    "        sims[name_idx, other_idx] = sims[other_idx, name_idx] = spa.dot(vocab[name], vocab[object_names[other_idx]])\n",
    "\n",
    "plot_similarity_matrix(sims, object_names, values = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "This is a messier similarity plot due to the fact that the bundled representations interact with all their constituent parts in the vocabulary.  That said, we see that 'princess' is still most similar to the query vector. \n",
    "\n",
    "This approach is more like what we would expect from a `word2vec` embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_royal_relationships\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "\n",
    "# Section 2: Analogies (Part 2)\n",
    "\n",
    "Estimated timing to here from start of tutorial: 15 minutes\n",
    "\n",
    "In this section, we will construct a database of data structures that describe different countries. Materials are adopted from [Kanerva (2010)](https://cdn.aaai.org/ocs/2243/2243-9566-1-PB.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 2: Analogy 2\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', 'OB3hzhM7Ois'), ('Bilibili', 'BV1TZ421g7G5')]\n",
    "tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_analogy_part_two\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding Exercise 2: Dollar of Mexico\n",
    "\n",
    "This is going to be a little more involved, because to construct the data structure we are going to need vectors that don't just represent values that we are reasoning about, but also vectors that represent different roles data can play. This is sometimes called a slot-filler representation, or a key-value representation.\n",
    "\n",
    "At first, let us define concepts and cleanup object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "symbol_names = ['DOLLAR','PESO', 'OTTAWA','MEXICO_CITY','CURRENCY','CAPITAL']\n",
    "vocab = make_vocabulary(vector_length)\n",
    "vocab.populate(';'.join(symbol_names))\n",
    "\n",
    "cleanup = sspspace.Cleanup(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will define `Canada` and `Mexico` concepts by integrating the available information together. You will be provided with `Canada` object and your task is to complete for `Mexico` one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete `mexico` concept.\")\n",
    "###################################################################\n",
    "\n",
    "vocab.add('CANADA', (vocab['CURRENCY'] * vocab['DOLLAR'] + vocab['CAPITAL'] * vocab['OTTAWA']).normalized())\n",
    "vocab.add('MEXICO', (vocab['CURRENCY'] * ... + vocab['CAPITAL'] * ...).normalized())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "vocab.add('CANADA', (vocab['CURRENCY'] * vocab['DOLLAR'] + vocab['CAPITAL'] * vocab['OTTAWA']).normalized())\n",
    "vocab.add('MEXICO', (vocab['CURRENCY'] * vocab['PESO'] + vocab['CAPITAL'] * vocab['MEXICO_CITY']).normalized())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We would like to find out Mexico's currency. Complete the code for constructing a `query` which will help us do that. Note that we are using a cleanup operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete `query` concept which will be similar to currency in Mexico.\")\n",
    "###################################################################\n",
    "\n",
    "vocab.add('QUERY_MX_CURRENCY', vocab['MEXICO'] * ~(... * ~...))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "vocab.add('QUERY_MX_CURRENCY', vocab['MEXICO'] * ~(vocab['CANADA'] * ~vocab['DOLLAR']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_names = list(vocab.keys())\n",
    "sims = np.zeros((len(object_names), len(object_names)))\n",
    "\n",
    "for name_idx, name in enumerate(object_names):\n",
    "    for other_idx in range(name_idx, len(object_names)):\n",
    "        sims[name_idx, other_idx] = sims[other_idx, name_idx] = spa.dot(vocab[name], vocab[object_names[other_idx]])\n",
    "\n",
    "plot_similarity_matrix(sims, object_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "After cleanup, the query vector is the most similar with the 'peso' object in the vocabularly, correctly answering the question.  \n",
    "\n",
    "Note, however, that the similarity is not perfectly equal to 1.  This is due to the scale factors applied to the composite vectors 'canada' and 'mexico', to ensure they remain unit vectors, and due to cross talk. Crosstalk is a symptom of the fact that we are binding and unbinding bundles of vector symbols to produce the resultant query vector. The constituent vectors are not perfectly orthogonal (i.e., having a dot product of zero) and as such the terms in the bundle interact when we measure similarity between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_dollar_of_mexico\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# The Big Picture\n",
    "\n",
    "*Estimated timing of tutorial: 45 minutes*\n",
    "\n",
    "In this tutorial, we observed three scenarios where we used the basic operations to solve different analogies and engage in structured learning. Those of you familiar with word embeddings from Natural Language Processing (NLP) might already be familiar with the idea of interpretable semantics on vector representations. This bonus tutorial helps to show how this can be accomplished in a different way. The ability to recreate different phenomena in different paradigms often gives us a great way to compare and contrast model mechanisms and we hope that this bonus tutorial has given you a curiosity to dive a bit deeper and start experimenting further with what you can accomplish using these great open-source tools!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "W2D2_Tutorial2",
   "provenance": [],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
