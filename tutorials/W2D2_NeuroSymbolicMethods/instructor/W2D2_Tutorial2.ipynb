{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {},
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/neuromatch/NeuroAI_Course/blob/main/tutorials/W2D2_NeuroSymbolicMethods/student/W2D2_Tutorial2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> &nbsp; <a href=\"https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/neuromatch/NeuroAI_Course/main/tutorials/W2D2_NeuroSymbolicMethods/student/W2D2_Tutorial2.ipynb\" target=\"_parent\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open in Kaggle\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Tutorial 2: Learning with structure\n",
    "\n",
    "**Week 2, Day 2: Neuro-Symbolic Methods**\n",
    "\n",
    "**By Neuromatch Academy**\n",
    "\n",
    "__Content creators:__ P. Michael Furlong, Chris Eliasmith\n",
    "\n",
    "__Content reviewers:__ Hlib Solodzhuk, Patrick Mineault, Aakash Agrawal, Alish Dipani, Hossein Rezaei, Yousef Ghanbari, Mostafa Abdollahi\n",
    "\n",
    "__Production editors:__ Konstantine Tsafatinos, Ella Batty, Spiros Chavlis, Samuele Bolotta, Hlib Solodzhuk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "___\n",
    "\n",
    "\n",
    "# Tutorial Objectives\n",
    "\n",
    "*Estimated timing of tutorial: 50 minutes*\n",
    "\n",
    "This tutorial will present you with a couple of play-examples on the usage of basic operations of vector symbolic algebras while generalizing to the new knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Tutorial slides\n",
    "# @markdown These are the slides for the videos in all tutorials today\n",
    "\n",
    "from IPython.display import IFrame\n",
    "link_id = \"2szmk\"\n",
    "\n",
    "print(f\"If you want to download the slides: 'https://osf.io/download/{link_id}'\")\n",
    "\n",
    "IFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{link_id}/?direct%26mode=render\", width=854, height=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Install and import feedback gadget\n",
    "\n",
    "!pip install --quiet numpy matplotlib ipywidgets scipy scikit-learn vibecheck\n",
    "\n",
    "from vibecheck import DatatopsContentReviewContainer\n",
    "def content_review(notebook_section: str):\n",
    "    return DatatopsContentReviewContainer(\n",
    "        \"\",  # No text prompt\n",
    "        notebook_section,\n",
    "        {\n",
    "            \"url\": \"https://pmyvdlilci.execute-api.us-east-1.amazonaws.com/klab\",\n",
    "            \"name\": \"neuromatch_neuroai\",\n",
    "            \"user_key\": \"wb2cxze8\",\n",
    "        },\n",
    "    ).render()\n",
    "\n",
    "\n",
    "feedback_prefix = \"W2D2_T2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Notice that exactly the `neuromatch` branch of `sspspace` should be installed! Otherwise, some of the functionality (like `optimize` parameter in the `DiscreteSPSpace` initialization) won't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Install dependencies\n",
    "\n",
    "# Install sspspace\n",
    "!pip install git+https://github.com/ctn-waterloo/sspspace@neuromatch --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Imports\n",
    "\n",
    "#working with data\n",
    "import numpy as np\n",
    "\n",
    "#plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "#interactive display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "#modeling\n",
    "import sspspace\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Figure settings\n",
    "\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' # perfrom high definition rendering for images and plots\n",
    "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/nma.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Plotting functions\n",
    "\n",
    "def plot_similarity_matrix(sim_mat, labels, values = False):\n",
    "    \"\"\"\n",
    "    Plot the similarity matrix between vectors.\n",
    "\n",
    "    Inputs:\n",
    "    - sim_mat (numpy.ndarray): similarity matrix between vectors.\n",
    "    - labels (list of str): list of strings which represent concepts.\n",
    "    - values (bool): True if we would like to plot values of similarity too.\n",
    "    \"\"\"\n",
    "    with plt.xkcd():\n",
    "        plt.imshow(sim_mat, cmap='Greys')\n",
    "        plt.colorbar()\n",
    "        plt.xticks(np.arange(len(labels)), labels, rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "        plt.yticks(np.arange(len(labels)), labels)\n",
    "        if values:\n",
    "            for x in range(sim_mat.shape[1]):\n",
    "                for y in range(sim_mat.shape[0]):\n",
    "                    plt.text(x, y, f\"{sim_mat[y, x]:.2f}\", fontsize = 8, ha=\"center\", va=\"center\", color=\"green\")\n",
    "        plt.title('Similarity between vector-symbols')\n",
    "        plt.xlabel('Symbols')\n",
    "        plt.ylabel('Symbols')\n",
    "        plt.show()\n",
    "\n",
    "def plot_training_and_choice(losses, sims, ant_names, cons_names, action_names):\n",
    "    \"\"\"\n",
    "    Plot loss progression over training as well as predicted similarities for given rules / correct solutions.\n",
    "\n",
    "    Inputs:\n",
    "    - losses (list): list of loss values.\n",
    "    - sims (list): list of similartiy matrices.\n",
    "    - ant_names (list): list of antecedance names.\n",
    "    - cons_names (list): list of consequent names.\n",
    "    - action_names (list): full list of concepts.\n",
    "    \"\"\"\n",
    "    with plt.xkcd():\n",
    "        plt.subplot(1, len(ant_names) + 1, 1)\n",
    "        plt.plot(losses)\n",
    "        plt.xlabel('Training number')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training Error')\n",
    "        index = 1\n",
    "        for ant_name, cons_name, sim in zip(ant_names, cons_names, sims):\n",
    "            index += 1\n",
    "            plt.subplot(1, len(ant_names) + 1, index)\n",
    "            plt.bar(range(len(action_names)), sim.flatten())\n",
    "            plt.gca().set_xticks(range(len(action_names)))\n",
    "            plt.gca().set_xticklabels(action_names, rotation=90)\n",
    "            plt.title(f'{ant_name}, not*{cons_name}')\n",
    "\n",
    "def plot_choice(sims, ant_names, cons_names, action_names):\n",
    "    \"\"\"\n",
    "    Plot predicted similarities for given rules / correct solutions.\n",
    "    \"\"\"\n",
    "    with plt.xkcd():\n",
    "        index = 0\n",
    "        for ant_name, cons_name, sim in zip(ant_names, cons_names, sims):\n",
    "            index += 1\n",
    "            plt.subplot(1, len(ant_names) + 1, index)\n",
    "            plt.bar(range(len(action_names)), sim.flatten())\n",
    "            plt.gca().set_xticks(range(len(action_names)))\n",
    "            plt.gca().set_xticklabels(action_names, rotation=90)\n",
    "            plt.ylabel(\"Similarity\")\n",
    "            plt.title(f'{ant_name}, not*{cons_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Helper functions\n",
    "\n",
    "action_names = ['red','blue','odd','even','green','prime','not*red','not*blue','not*odd','not*even','not*green','not*prime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Set random seed\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def set_seed(seed=None):\n",
    "  if seed is None:\n",
    "    seed = np.random.choice(2 ** 32)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "\n",
    "set_seed(seed = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "\n",
    "# Section 1: Analogies. Part 1\n",
    "\n",
    "In this section we will construct a simple analogy using Vector Symbolic Algebras. The question we are going to try and solve is \"King is to the queen as the prince is to X.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 1: Analogy 1\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', '2tR4fHvL1Jk'), ('Bilibili', 'BV1fS411P7Ez')]\n",
    "tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_analogy_part_one\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding Exercise 1: Royal Relationships\n",
    "\n",
    "We're going to start by considering our vocabulary. We will use the basic discrete concepts of monarch, heir, male, and female."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Let's create the objects we know about by combinatorially expanding the space: \n",
    "\n",
    "1. King is a male monarch\n",
    "2. Queen is a female monarch\n",
    "3. Prince is a male heir\n",
    "4. Princess is a female heir\n",
    "\n",
    "Complete the missing parts of the code to obtain correct representations of new concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "```python\n",
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete correct relations for creating new concepts.\")\n",
    "###################################################################\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "symbol_names = ['monarch','heir','male','female']\n",
    "discrete_space = sspspace.DiscreteSPSpace(symbol_names, ssp_dim=1024, optimize=False)\n",
    "\n",
    "objs = {n:discrete_space.encode(n) for n in symbol_names}\n",
    "\n",
    "objs['king'] = objs['monarch'] * objs['male']\n",
    "objs['queen'] = objs['monarch'] * ...\n",
    "objs['prince'] = objs['heir'] * objs['male']\n",
    "objs['princess'] = ... * objs['female']\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "symbol_names = ['monarch','heir','male','female']\n",
    "discrete_space = sspspace.DiscreteSPSpace(symbol_names, ssp_dim=1024, optimize=False)\n",
    "\n",
    "objs = {n:discrete_space.encode(n) for n in symbol_names}\n",
    "\n",
    "objs['king'] = objs['monarch'] * objs['male']\n",
    "objs['queen'] = objs['monarch'] * objs['female']\n",
    "objs['prince'] = objs['heir'] * objs['male']\n",
    "objs['princess'] = objs['heir'] * objs['female']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now, we can take an explicit approach. We know that the conversion from king to queen is to unbind male and bind female, so let's apply that to our prince object and see what we uncover. \n",
    "\n",
    "At first, in the cell below, let's recover `queen` from `king` by constructing a new `query` concept, which represents the unbinding of `male` and the binding of `female.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "```python\n",
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete correct relation for creating `query` object to compare with `queen`.\")\n",
    "###################################################################\n",
    "\n",
    "objs['query'] = (objs[...] * ~objs[...]) * objs[...]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "objs['query'] = (objs['king'] * ~objs['male']) * objs['female']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Let's see if this new query object bears any similarity to anything in our vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "object_names = list(objs.keys())\n",
    "sims = np.zeros((len(object_names), len(object_names)))\n",
    "\n",
    "for name_idx, name in enumerate(object_names):\n",
    "    for other_idx in range(name_idx, len(object_names)):\n",
    "        sims[name_idx, other_idx] = sims[other_idx, name_idx] = (objs[name] | objs[object_names[other_idx]]).item()\n",
    "\n",
    "plot_similarity_matrix(sims, object_names, values = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "The above similarity plot shows that applying that operation successfully converts king to queen. Let's apply it to 'prince' and see what happens. Now, `query` should represent the `princess` concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "objs['query'] = (objs['prince'] * ~objs['male']) * objs['female']\n",
    "\n",
    "sims = np.zeros((len(object_names), len(object_names)))\n",
    "\n",
    "for name_idx, name in enumerate(object_names):\n",
    "    for other_idx in range(name_idx, len(object_names)):\n",
    "        sims[name_idx, other_idx] = sims[other_idx, name_idx] = (objs[name] | objs[object_names[other_idx]]).item()\n",
    "\n",
    "plot_similarity_matrix(sims, object_names, values = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Here, we have successfully recovered the princess, completing the analogy.\n",
    "\n",
    "This approach, however, requires explicit knowledge of the construction of the objects.  Let's see if we can just work with the concepts of 'king,' 'queen,' and 'prince' directly.\n",
    "\n",
    "In the cell below, construct the `princess` concept using only `king,` `queen`, and `prince.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "```python\n",
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete correct relation for creating `query` object to compare with `princess`.\")\n",
    "###################################################################\n",
    "\n",
    "objs['query'] = (objs[...] * ~objs[...]) * objs[...]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "objs['query'] = (objs['prince'] * ~objs['king']) * objs['queen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "sims = np.zeros((len(object_names), len(object_names)))\n",
    "\n",
    "for name_idx, name in enumerate(object_names):\n",
    "    for other_idx in range(name_idx, len(object_names)):\n",
    "        sims[name_idx, other_idx] = sims[other_idx, name_idx] = (objs[name] | objs[object_names[other_idx]]).item()\n",
    "\n",
    "plot_similarity_matrix(sims, object_names, values = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Again, we see that we have recovered the princess by using our analogy.\n",
    "\n",
    "That said, the above depends on knowing that the representations are constructed using binding. Can we do something similar through the bundling operation? Let's try that out.\n",
    "\n",
    "Reassing concept definitions using bundling operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "objs['king'] = (objs['monarch'] + objs['male']).normalize()\n",
    "objs['queen'] = (objs['monarch'] + objs['female']).normalize()\n",
    "objs['prince'] = (objs['heir'] + objs['male']).normalize()\n",
    "objs['princess'] = (objs['heir'] + objs['female']).normalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "But now that we are using an additive model, we need to take a different approach. Instead of unbinding the king and binding the queen, we subtract the king and add the queen to find the princess from the prince.\n",
    "\n",
    "Complete the code to reflect the updated mechanism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "```python\n",
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete correct relation for creating `query` object to compare with `princess`.\")\n",
    "###################################################################\n",
    "\n",
    "objs['query'] = (objs[...] - objs[...]) + objs[...]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "objs['query'] = (objs['prince'] - objs['king']) + objs['queen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "sims = np.zeros((len(object_names), len(object_names)))\n",
    "\n",
    "for name_idx, name in enumerate(object_names):\n",
    "    for other_idx in range(name_idx, len(object_names)):\n",
    "        sims[name_idx, other_idx] = sims[other_idx, name_idx] = (objs[name] | objs[object_names[other_idx]]).item()\n",
    "\n",
    "plot_similarity_matrix(sims, object_names, values = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "This is a messier similarity plot due to the fact that the bundled representations interact with all their constituent parts in the vocabulary.  That said, we see that 'princess' is still most similar to the query vector. \n",
    "\n",
    "This approach is more like what we would expect from a `word2vec` embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_royal_relationships\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "\n",
    "# Section 2: Analogies. Part 2\n",
    "\n",
    "Estimated timing to here from start of tutorial: 15 minutes\n",
    "\n",
    "In this section, we will construct a database of data structures that describe different countries. Materials are adopted from [Kanerva (2010)](https://cdn.aaai.org/ocs/2243/2243-9566-1-PB.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 2: Analogy 2\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', 'OB3hzhM7Ois'), ('Bilibili', 'BV1TZ421g7G5')]\n",
    "tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_analogy_part_two\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding Exercise 2: Dollar of Mexico\n",
    "\n",
    "This is going to be a little more involved because to construct the data structure, we are going to need vectors that not only represent values that we are reasoning about, but also vectors that represent different roles data can play. This is sometimes called a slot-filler representation or a key-value representation.\n",
    "\n",
    "At first, let us define concepts and cleanup object. Then, we will define `canada` and `mexico` concepts by integrating the available information together. You will be provided with a `canada` object and your task is to complete for `mexico` one. Note that:\n",
    "\n",
    "* We bind `currency` to the relevant currency for that country (`dollar` for Canada, `peso` for Mexico)\n",
    "* We bind `capital` to the relevant capital for that country (`Ottawa` for Canada, `Mexico City` for Mexico)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "```python\n",
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete `mexico` concept.\")\n",
    "###################################################################\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "symbol_names = ['dollar', 'peso', 'ottawa', 'mexico-city', 'currency', 'capital']\n",
    "discrete_space = sspspace.DiscreteSPSpace(symbol_names, ssp_dim=1024, optimize=False)\n",
    "\n",
    "objs = {n:discrete_space.encode(n) for n in symbol_names}\n",
    "\n",
    "cleanup = sspspace.Cleanup(objs)\n",
    "\n",
    "objs['canada'] = ((objs['currency'] * objs['dollar']) + (objs['capital'] * objs['ottawa'])).normalize()\n",
    "objs['mexico'] = ((objs['currency'] * ...) + (objs['capital'] * ...)).normalize()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "symbol_names = ['dollar', 'peso', 'ottawa', 'mexico-city', 'currency', 'capital']\n",
    "discrete_space = sspspace.DiscreteSPSpace(symbol_names, ssp_dim=1024, optimize=False)\n",
    "\n",
    "objs = {n:discrete_space.encode(n) for n in symbol_names}\n",
    "\n",
    "cleanup = sspspace.Cleanup(objs)\n",
    "\n",
    "objs['canada'] = ((objs['currency'] * objs['dollar']) + (objs['capital'] * objs['ottawa'])).normalize()\n",
    "objs['mexico'] = ((objs['currency'] * objs['peso']) + (objs['capital'] * objs['mexico-city'])).normalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We would like to find out Mexico's currency. Complete the code for constructing a `query` which will help us do that. Note that we are using a cleanup operation (feel free to remove it and compare the results)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "```python\n",
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete `query` concept which will be similar to currency in Mexico.\")\n",
    "###################################################################\n",
    "\n",
    "objs['query'] = cleanup(~objs[...] * objs[...] * objs['mexico'])\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "objs['query'] = cleanup(~objs['canada'] * objs['dollar'] * objs['mexico'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "object_names = list(objs.keys())\n",
    "sims = np.zeros((len(object_names), len(object_names)))\n",
    "\n",
    "for name_idx, name in enumerate(object_names):\n",
    "    for other_idx in range(name_idx, len(object_names)):\n",
    "        sims[name_idx, other_idx] = sims[other_idx, name_idx] = (objs[name] | objs[object_names[other_idx]]).item()\n",
    "\n",
    "plot_similarity_matrix(sims, object_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "After cleanup, the query vector is the most similar to the `peso` object in the vocabulary, correctly answering the question.  \n",
    "\n",
    "Note, however, that the similarity is not perfectly equal to 1. This is due to the scale factors applied to the composite vectors `canada` and `mexico`, to ensure they remain unit vectors, and due to cross talk. Crosstalk is a symptom of the fact that we are binding and unbinding bundles of vector symbols to produce the resultant query vector. The constituent vectors are not perfectly orthogonal (i.e., having a dot product of zero), and as such, the terms in the bundle interact when we measure similarity between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_dolar_of_mexico\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "\n",
    "# Section 3: Wason Card Task\n",
    "\n",
    "Estimated timing to here from start of tutorial: 25 minutes\n",
    "\n",
    "One of the powerful benefits of using these structured representations is being able to generalize to other circumstances. To demonstrate this, we are going to show you this in a simple task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 3: Wason Card Task Intro\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', 'BAju3MNHCq8'), ('Bilibili', 'BV1Qf421X7MB')]\n",
    "tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_wason_card_task_intro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding Exercise 3: Wason Card Task\n",
    "\n",
    "We are going to test the generalization property on the Wason Card Task, where a person is told a rule of the form \"if the card is even, then the back is blue\", they are then presented with a number of cards with either an odd number, an even number, a red back, or a blue back. The participant is asked which cards they have to flip to determine that the rule is true.\n",
    "\n",
    "In this case, the participant needs to flip only the even card(s), and any card where the back is not blue, as the rule does not state whether or not odd numbers can have blue backs, and a red-backed card with an even number would violate the rule. We can get this from Boolean logic:\n",
    "\n",
    "$$\n",
    "\\mathrm{even} \\implies \\mathrm{blue}\n",
    "$$\n",
    "\n",
    "which is equal to \n",
    "\n",
    "$$ \n",
    "\\neg \\mathrm{even} \\vee \\mathrm{blue}\n",
    "$$\n",
    "\n",
    "where $\\neg$ means a logical not and $\\vee$ means logical or. If we want to find cards that violate the rule, then we negate the rule, providing:\n",
    "\n",
    "$$ \n",
    "\\neg (\\neg \\mathrm{even} \\vee \\mathrm{blue}) = \\mathrm{even} \\wedge \\neg \\mathrm{blue}.\n",
    "$$\n",
    "\n",
    "Where $\\wedge$ is the logical and. Hence, the cards that can violate the rule are either even or not blue.  \n",
    "\n",
    "At first, we will define all the needed concepts. For all noun concepts, we would also like to have `not concept` presented in the space; please complete missing code parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "```python\n",
    "set_seed(42)\n",
    "\n",
    "card_states = ['red','blue','odd','even','not','green','prime','implies','ant','relation','cons']\n",
    "encoder = sspspace.DiscreteSPSpace(card_states, ssp_dim=1024, optimize=False)\n",
    "vocab = {c:encoder.encode(c) for c in card_states}\n",
    "\n",
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete creating `not x` concepts.\")\n",
    "###################################################################\n",
    "\n",
    "for a in ['red','blue','odd','even','green','prime']:\n",
    "    vocab[f'not*{a}'] = vocab[...] * vocab[a]\n",
    "\n",
    "action_names = ['red','blue','odd','even','green','prime','not*red','not*blue','not*odd','not*even','not*green','not*prime']\n",
    "action_space = np.array([vocab[x] for x in action_names]).squeeze()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "card_states = ['red','blue','odd','even','not','green','prime','implies','ant','relation','cons']\n",
    "encoder = sspspace.DiscreteSPSpace(card_states, ssp_dim=1024, optimize=False)\n",
    "vocab = {c:encoder.encode(c) for c in card_states}\n",
    "\n",
    "for a in ['red','blue','odd','even','green','prime']:\n",
    "    vocab[f'not*{a}'] = vocab['not'] * vocab[a]\n",
    "\n",
    "action_names = ['red','blue','odd','even','green','prime','not*red','not*blue','not*odd','not*even','not*green','not*prime']\n",
    "action_space = np.array([vocab[x] for x in action_names]).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now, we are going to set up a simple perceptron-style learning rule using the HRR (Holographic Reduced Representations) algebra. We are going to learn a target transformation, $T$, such that given a learning rule, $A^{*} = T\\circledast R$. Here:\n",
    "\n",
    "* $R$ is the rule to be learned\n",
    "* $A^{*}$ is the antecedent value bundled with $\\texttt{not}$ bound with the consequent value. This is because we are trying to learn the cards that can *violate* the rule.\n",
    "\n",
    "Rules themselves are going to be composed like the data structures representing different countries in the previous section. `ant`, `relation`, and `cons` are extra concepts that define the structure and which will bind to the specific instances (think of them as anchor concepts which got bound to the specific instances). \n",
    "\n",
    "If we have a rule, $X \\implies Y$, then we would create the VSA representation:\n",
    "\n",
    "$$ R = \\texttt{ant} \\circledast X + \\texttt{relation} \\circledast \\texttt{implies} + \\texttt{cons} \\circledast Y $$\n",
    "\n",
    "and the ideal output is:\n",
    "\n",
    "$$\n",
    "A^{*} = X + \\texttt{not}\\circledast Y\n",
    "$$\n",
    "\n",
    "In the cell below, let us define two rules:\n",
    "\n",
    "$$\\text{blue} \\implies \\text{even}$$\n",
    "$$\\text{odd} \\implies \\text{green}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "```python\n",
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete creating rules as defined above.\")\n",
    "###################################################################\n",
    "\n",
    "rules = [\n",
    "    (vocab['ant'] * vocab['blue'] + vocab['relation'] * vocab['implies'] + vocab['cons'] * vocab[...]).normalize(),\n",
    "    (vocab[...] * vocab[...] + vocab[...] * vocab[...] + vocab[...] * vocab[...]).normalize(),\n",
    "]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "rules = [\n",
    "    (vocab['ant'] * vocab['blue'] + vocab['relation'] * vocab['implies'] + vocab['cons'] * vocab['even']).normalize(),\n",
    "    (vocab['ant'] * vocab['odd'] + vocab['relation'] * vocab['implies'] + vocab['cons'] * vocab['green']).normalize(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now, we are ready to derive the transformation! For that, we will iterate through the rules and solutions for a specified number of iterations and update it as the following:\n",
    "\n",
    "$$ T \\leftarrow T - \\text{lr} (T - A^{} \\circledast \\sim R)$$\n",
    "\n",
    "where $\\text{lr}$ is learning rate constant value. Ultimately, we want $A^{*} = T\\circledast R$, so we unbind $R$ to recover the desired transform and use the learning rule to update our current estimated transform.\n",
    "\n",
    "We will also compute loss progression over time and log the loss function between perfect similarity (ones only for antecedence value and not consequent one) and the one we obtain between prediction for current transformation and full action space. Complete the missing parts of the code in the next cell to complete training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "```python\n",
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete training loop.\")\n",
    "###################################################################\n",
    "\n",
    "num_iters = 500\n",
    "losses = []\n",
    "sims = []\n",
    "lr = 1e-1\n",
    "ant_names = [\"blue\", \"odd\"]\n",
    "cons_names = [\"even\", \"green\"]\n",
    "\n",
    "transform = np.zeros((1,encoder.ssp_dim))\n",
    "for i in range(num_iters):\n",
    "    loss = 0\n",
    "    for rule, ant_name, cons_name in zip(rules, ant_names, cons_names):\n",
    "\n",
    "        #perfect similarity\n",
    "        y_true = np.eye(len(action_names))[action_names.index(ant_name),:] + np.eye(len(action_names))[4+action_names.index(cons_name),:]\n",
    "\n",
    "        #prediction with current transform (a_hat = transform * rule)\n",
    "        a_hat = sspspace.SSP(transform) * ...\n",
    "\n",
    "        #similarity with current transform\n",
    "        sim_mat = action_space @ a_hat.T\n",
    "\n",
    "        #cleanup\n",
    "        y_hat = softmax(sim_mat)\n",
    "\n",
    "        #true solution (a* = ant_name + not * cons_name)\n",
    "        a_true = (vocab[ant_name] + vocab['not']*vocab[...]).normalize()\n",
    "\n",
    "        #calculate loss\n",
    "        loss += log_loss(y_true, y_hat)\n",
    "\n",
    "        #update transform (T <- T - lr * (T - A* * (~rule)))\n",
    "        transform -= (lr) * (... - np.array(... * ~...))\n",
    "        transform = transform / np.linalg.norm(transform)\n",
    "\n",
    "        #save predicted similarities if it is last iteration\n",
    "        if i == num_iters - 1:\n",
    "            sims.append(sim_mat)\n",
    "\n",
    "    #save loss\n",
    "    losses.append(np.copy(loss))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "num_iters = 500\n",
    "losses = []\n",
    "sims = []\n",
    "lr = 1e-1\n",
    "ant_names = [\"blue\", \"odd\"]\n",
    "cons_names = [\"even\", \"green\"]\n",
    "\n",
    "transform = np.zeros((1,encoder.ssp_dim))\n",
    "for i in range(num_iters):\n",
    "    loss = 0\n",
    "    for rule, ant_name, cons_name in zip(rules, ant_names, cons_names):\n",
    "\n",
    "        #perfect similarity\n",
    "        y_true = np.eye(len(action_names))[action_names.index(ant_name),:] + np.eye(len(action_names))[4+action_names.index(cons_name),:]\n",
    "\n",
    "        #prediction with current transform (a_hat = transform * rule)\n",
    "        a_hat = sspspace.SSP(transform) * rule\n",
    "\n",
    "        #similarity with current transform\n",
    "        sim_mat = action_space @ a_hat.T\n",
    "\n",
    "        #cleanup\n",
    "        y_hat = softmax(sim_mat)\n",
    "\n",
    "        #true solution (a* = ant_name + not * cons_name)\n",
    "        a_true = (vocab[ant_name] + vocab['not']*vocab[cons_name]).normalize()\n",
    "\n",
    "        #calculate loss\n",
    "        loss += log_loss(y_true, y_hat)\n",
    "\n",
    "        #update transform (T <- T - lr * (T - A* * (~rule)))\n",
    "        transform -= (lr) * (transform - np.array(a_true * ~rule))\n",
    "        transform = transform / np.linalg.norm(transform)\n",
    "\n",
    "        #save predicted similarities if it is last iteration\n",
    "        if i == num_iters - 1:\n",
    "            sims.append(sim_mat)\n",
    "\n",
    "    #save loss\n",
    "    losses.append(np.copy(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plot_training_and_choice(losses, sims, ant_names, cons_names, action_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Let's see what happens when we test it on a new rule it hasn't seen before. This time, we will use the rule that $\\text{red} \\implies \\text{prime}$. Your task is to complete the new rule in the cell below and observe the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "```python\n",
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete new rule and predict for it.\")\n",
    "###################################################################\n",
    "\n",
    "new_rule = (vocab['ant'] * vocab[...] + vocab['relation'] * ... + vocab['cons'] * vocab[...]).normalize()\n",
    "\n",
    "#apply transform on new rule to test the generalization of the transform\n",
    "a_hat = sspspace.SSP(transform) * ...\n",
    "\n",
    "new_sims = action_space @ a_hat.T\n",
    "y_hat = softmax(new_sims)\n",
    "\n",
    "plot_choice([new_sims], [\"red\"], [\"prime\"], action_names)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "new_rule = (vocab['ant'] * vocab['red'] + vocab['relation'] * vocab['implies'] + vocab['cons'] * vocab['prime']).normalize()\n",
    "\n",
    "#apply transform on new rule to test the generalization of the transform\n",
    "a_hat = sspspace.SSP(transform) * new_rule\n",
    "\n",
    "new_sims = action_space @ a_hat.T\n",
    "y_hat = softmax(new_sims)\n",
    "\n",
    "plot_choice([new_sims], [\"red\"], [\"prime\"], action_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Let's compare how a standard MLP that isn't aware of the structure in the representation performs. Here, features are going to be the rules and output - solutions. Complete the code below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "```python\n",
    "###################################################################\n",
    "## Fill out the following then remove\n",
    "raise NotImplementedError(\"Student exercise: complete MLP training.\")\n",
    "###################################################################\n",
    "\n",
    "#features - rules\n",
    "X_train = np.array(...).squeeze()\n",
    "\n",
    "#output - a* for each rule\n",
    "y_train = np.array([\n",
    "    (vocab[ant_names[0]] + vocab['not']*vocab[cons_names[0]]).normalize(),\n",
    "    (vocab[ant_names[1]] + vocab['not']*vocab[cons_names[1]]).normalize(),\n",
    "]).squeeze()\n",
    "\n",
    "regr = MLPRegressor(random_state=1, hidden_layer_sizes=(1024,1024), max_iter=1000).fit(..., ...)\n",
    "\n",
    "a_mlp = regr.predict(new_rule)\n",
    "\n",
    "mlp_sims = action_space @ a_mlp.T\n",
    "\n",
    "plot_choice([mlp_sims], [\"red\"], [\"prime\"], action_names)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#to_remove solution\n",
    "\n",
    "#features - rules\n",
    "X_train = np.array(rules).squeeze()\n",
    "\n",
    "#output - a* for each rule\n",
    "y_train = np.array([\n",
    "    (vocab[ant_names[0]] + vocab['not']*vocab[cons_names[0]]).normalize(),\n",
    "    (vocab[ant_names[1]] + vocab['not']*vocab[cons_names[1]]).normalize(),\n",
    "]).squeeze()\n",
    "\n",
    "regr = MLPRegressor(random_state=1, hidden_layer_sizes=(1024,1024), max_iter=1000).fit(X_train, y_train)\n",
    "\n",
    "a_mlp = regr.predict(new_rule)\n",
    "\n",
    "mlp_sims = action_space @ a_mlp.T\n",
    "\n",
    "plot_choice([mlp_sims], [\"red\"], [\"prime\"], action_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "As you can see, this model, even though it is a more expressive neural network, simply learns to predict the values it had seen before when presented with a novel stimulus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_wason_card_task\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 4: Wason Card Task Outro\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', '_77GHH8gfvk'), ('Bilibili', 'BV1rM4m1U7M3')]\n",
    "tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_wason_card_task_outro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Summary\n",
    "\n",
    "*Estimated timing of tutorial: 45 minutes*\n",
    "\n",
    "In this tutorial, we observed three scenarios where we used the basic operations to solve different analogies and engage in structured learning. The next final tutorial will show us how to use structure to impose inductive biases and how to use continuous representations to represent mixtures of discrete and continuous objects."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "W2D2_Tutorial2",
   "provenance": [],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
