{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82ed61a3-87d2-4e76-83f6-4b786c101af2",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# W2D5Tutorial1\n",
    "\n",
    "**Week 2, Day 5: Mysteries**\n",
    "\n",
    "**By Neuromatch Academy**\n",
    "\n",
    "__Content creators:__ Names & Surnames\n",
    "\n",
    "__Content reviewers:__ Names & Surnames\n",
    "\n",
    "__Production editors:__ Names & Surnames\n",
    "\n",
    "<br>\n",
    "\n",
    "Acknowledgments: [ACKNOWLEDGMENT_INFORMATION]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6366c740-80c7-4545-b688-d547ef79613e",
   "metadata": {
    "execution": {}
   },
   "source": [
    "___\n",
    "\n",
    "\n",
    "# Tutorial Objectives\n",
    "\n",
    "*Estimated timing of tutorial: [insert estimated duration of whole tutorial in minutes]*\n",
    "\n",
    "In this tutorial, you will observe how performance degrades as testing data distribution strays from training distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4fa9f7-d9cc-4594-be41-b31f02af1bd4",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Tutorial slides\n",
    "\n",
    "# @markdown These are the slides for the videos in all tutorials today\n",
    "\n",
    "\n",
    "## Uncomment the code below to test your function\n",
    "\n",
    "#from IPython.display import IFrame\n",
    "#link_id = \"<YOUR_LINK_ID_HERE>\"\n",
    "\n",
    "print(\"If you want to download the slides: 'Link to the slides'\")\n",
    "      # Example: https://osf.io/download/{link_id}/\n",
    "\n",
    "#IFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{link_id}/?direct%26mode=render\", width=854, height=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60d1a7f-452c-436d-90a8-409571405e62",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4762c382-3622-4178-8e19-da783bac0a57",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Install dependencies\n",
    "# @markdown\n",
    "\n",
    "!pip install numpy matplotlib Pillow torch torchvision transformers ipywidgets gradio trdg scikit-learn networkx pickleshare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299b676d-d8de-41ad-80c6-3516e25f0fba",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Import dependencies\n",
    "# @markdown Enhanced organization and clarity in import statements for better readability\n",
    "\n",
    "# Standard libraries for essential operations, random number generation, logging, and file management\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import requests\n",
    "\n",
    "# Data handling libraries\n",
    "import pickleshare\n",
    "\n",
    "# Scientific computing and statistical libraries for advanced mathematical operations and array handling\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from scipy.special import logsumexp\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "# Deep learning libraries for constructing and training neural networks\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Image processing and visualization libraries\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Libraries for interactive elements in notebooks and web applications\n",
    "from IPython.display import IFrame\n",
    "import gradio as gr\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "# Graph analysis library for the creation, manipulation, and study of the structure of complex networks\n",
    "import networkx as nx\n",
    "\n",
    "# Progress monitoring\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Standard Libraries\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0960e64d-fe33-4276-8da0-e450e2649bcc",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Figure settings\n",
    "# @markdown\n",
    "\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' # perfrom high definition rendering for images and plots\n",
    "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/nma.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f79032-091e-4f19-88b6-7fb797a1cc31",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Set device (GPU or CPU). Execute `set_device()`\n",
    "# especially if torch modules used.\n",
    "# @markdown\n",
    "\n",
    "# inform the user if the notebook uses GPU or CPU.\n",
    "\n",
    "def set_device():\n",
    "    \"\"\"\n",
    "    Determines and sets the computational device for PyTorch operations based on the availability of a CUDA-capable GPU.\n",
    "\n",
    "    Outputs:\n",
    "    - device (str): The device that PyTorch will use for computations ('cuda' or 'cpu'). This string can be directly used\n",
    "    in PyTorch operations to specify the device.\n",
    "    \"\"\"\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    if device != \"cuda\":\n",
    "        print(\"GPU is not enabled in this notebook. \\n\"\n",
    "              \"If you want to enable it, in the menu under `Runtime` -> \\n\"\n",
    "              \"`Hardware accelerator.` and select `GPU` from the dropdown menu\")\n",
    "    else:\n",
    "        print(\"GPU is enabled in this notebook. \\n\"\n",
    "              \"If you want to disable it, in the menu under `Runtime` -> \\n\"\n",
    "              \"`Hardware accelerator.` and select `None` from the dropdown menu\")\n",
    "\n",
    "    return device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4734a181-77f8-4e19-8674-10904df84761",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Section 1: Recurrent Independent Mechanisms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33b2098-9d42-4060-a470-fad0d748faac",
   "metadata": {
    "execution": {}
   },
   "source": [
    "The crucial idea behind this section is that machine learning aims to capture the modular structure of the physical world, where complexity emerges from simpler, independently evolving subsystems. This concept aligns with causal inference, suggesting that understanding and modeling the world involves identifying and integrating these autonomous mechanisms. These mechanisms, which interact sparsely, maintain their functionality even amidst changes in others, highlighting their robustness. Recurrent Independent Mechanisms (RIMs) embody this principle by operating mostly independently, occasionally interacting through an attention-based mechanism for efficient and dynamic information processing. This approach [https://arxiv.org/pdf/1909.10893.pdf] suggests a preference for models that can capture the independence and sparse interactions of mechanisms, potentially leading to more adaptable and generalizable AI systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae3e1d3-7be8-460b-ad89-17c96274cb2c",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Data retrieval\n",
    "# @markdown\n",
    "\n",
    "# URL of the repository to clone\n",
    "!git clone https://github.com/SamueleBolotta/RIMs-Sequential-MNIST\n",
    "%cd RIMs-Sequential-MNIST\n",
    "\n",
    "# Imports\n",
    "from data import MnistData\n",
    "from networks import MnistModel, LSTM\n",
    "\n",
    "# Function to download files\n",
    "def download_file(url, destination):\n",
    "    print(f\"Starting to download {url} to {destination}\")\n",
    "    response = requests.get(url, allow_redirects=True)\n",
    "    open(destination, 'wb').write(response.content)\n",
    "    print(f\"Successfully downloaded {url} to {destination}\")\n",
    "\n",
    "# Path of the models\n",
    "model_path = {\n",
    "    'LSTM': 'lstm_model_dir/lstm_best_model.pt',\n",
    "    'RIM': 'rim_model_dir/best_model.pt'\n",
    "}\n",
    "\n",
    "# URLs of the models\n",
    "model_urls = {\n",
    "    'LSTM': 'https://osf.io/4gajq/download',\n",
    "    'RIM': 'https://osf.io/3squn/download'\n",
    "}\n",
    "\n",
    "# Check if model files exist, if not, download them\n",
    "for model_key, model_url in model_urls.items():\n",
    "    if not os.path.exists(model_path[model_key]):\n",
    "        download_file(model_url, model_path[model_key])\n",
    "        print(f\"{model_key} model downloaded.\")\n",
    "    else:\n",
    "        print(f\"{model_key} model already exists. No download needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e85190a-f57e-41c8-8d4a-3ddc658ae045",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# RIMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bb7131-c719-47de-98bf-9cfdb59f1abc",
   "metadata": {
    "execution": {}
   },
   "source": [
    "The model has been trained on the Sequential MNIST datset with individual image size 14x14. To assess its generalization capabilities, it got tested on 16x16 (Validation Set 3), 19x19 (Validation Set 2) and 24x24 images (Validation Set 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad179715-7c6f-455b-aea4-7b7860430c6b",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Config\n",
    "config = {\n",
    "    'cuda': True,\n",
    "    'epochs': 200,\n",
    "    'batch_size': 64,\n",
    "    'hidden_size': 100,\n",
    "    'input_size': 1,\n",
    "    'model': 'RIM', # Or 'RIM' for the MnistModel\n",
    "    'train': False, # Set to False to load the saved model\n",
    "    'num_units': 6,\n",
    "    'rnn_cell': 'LSTM',\n",
    "    'key_size_input': 64,\n",
    "    'value_size_input': 400,\n",
    "    'query_size_input': 64,\n",
    "    'num_input_heads': 1,\n",
    "    'num_comm_heads': 4,\n",
    "    'input_dropout': 0.1,\n",
    "    'comm_dropout': 0.1,\n",
    "    'key_size_comm': 32,\n",
    "    'value_size_comm': 100,\n",
    "    'query_size_comm': 32,\n",
    "    'k': 4,\n",
    "    'size': 14,\n",
    "    'loadsaved': 1, # Ensure this is 1 to load saved model\n",
    "    'log_dir': 'rim_model_dir'\n",
    "}\n",
    "\n",
    "# Choose the model\n",
    "model = MnistModel(config)  # Instantiating MnistModel (RIM) with config\n",
    "model_directory = model_path['RIM']\n",
    "\n",
    "# Set device\n",
    "device = set_device()\n",
    "model.to(device)\n",
    "\n",
    "# Set the map_location based on whether CUDA is available\n",
    "map_location = 'cuda' if torch.cuda.is_available() and config['cuda'] else 'cpu'\n",
    "\n",
    "# Use torch.load with the map_location parameter\n",
    "saved = torch.load(model_directory, map_location=map_location)\n",
    "model.load_state_dict(saved['net'])\n",
    "\n",
    "# Data\n",
    "data = MnistData(config['batch_size'], (config['size'], config['size']), config['k'])\n",
    "\n",
    "# Evaluation function\n",
    "def test_model(model, loader, func):\n",
    "    accuracy = 0\n",
    "    loss = 0\n",
    "    model.eval()\n",
    "\n",
    "    print(f\"Total validation samples: {loader.val_len()}\")  # Print total number of validation samples\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(loader.val_len())):\n",
    "            test_x, test_y = func(i)\n",
    "            test_x = model.to_device(test_x)\n",
    "            test_y = model.to_device(test_y).long()\n",
    "            print(f\"Sample {i}: test_x device: {test_x.device}, test_y device: {test_y.device}\")\n",
    "\n",
    "            probs  = model(test_x)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "            correct = preds == test_y\n",
    "            accuracy += correct.sum().item()\n",
    "\n",
    "    accuracy /= 100  # Use the total number of items in the validation set for accuracy calculation\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# Evaluate on all three validation sets\n",
    "validation_functions = [data.val_get1, data.val_get2, data.val_get3]\n",
    "validation_accuracies_rim = []\n",
    "\n",
    "print(f\"Model: {config['model']}, Device: {device}\")\n",
    "print(f\"Configuration: {config}\")\n",
    "\n",
    "for func in validation_functions:\n",
    "    accuracy = test_model(model, data, func)\n",
    "    validation_accuracies_rim.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6303ab3d-10e3-4f17-98cd-d1cc8bec2244",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7acc2d-4aa5-4e4c-82ae-43ec4a3c2bd8",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Let's now repeat the same process with LSTMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ceb84b-e550-48ed-a612-a5e5155ebf7b",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Config\n",
    "config = {\n",
    "    'cuda': True,\n",
    "    'epochs': 200,\n",
    "    'batch_size': 64,\n",
    "    'hidden_size': 100,\n",
    "    'input_size': 1,\n",
    "    'model': 'LSTM',\n",
    "    'train': False, # Set to False to load the saved model\n",
    "    'num_units': 6,\n",
    "    'rnn_cell': 'LSTM',\n",
    "    'key_size_input': 64,\n",
    "    'value_size_input': 400,\n",
    "    'query_size_input': 64,\n",
    "    'num_input_heads': 1,\n",
    "    'num_comm_heads': 4,\n",
    "    'input_dropout': 0.1,\n",
    "    'comm_dropout': 0.1,\n",
    "    'key_size_comm': 32,\n",
    "    'value_size_comm': 100,\n",
    "    'query_size_comm': 32,\n",
    "    'k': 4,\n",
    "    'size': 14,\n",
    "    'loadsaved': 1, # Ensure this is 1 to load saved model\n",
    "    'log_dir': 'rim_model_dir'\n",
    "}\n",
    "\n",
    "model = LSTM(config)  # Instantiating LSTM with config\n",
    "model_directory = model_path['LSTM']\n",
    "\n",
    "# Set device\n",
    "device = set_device()\n",
    "model.to(device)\n",
    "\n",
    "# Set the map_location based on whether CUDA is available\n",
    "map_location = 'cuda' if torch.cuda.is_available() and config['cuda'] else 'cpu'\n",
    "\n",
    "# Use torch.load with the map_location parameter\n",
    "saved = torch.load(model_directory, map_location=map_location)\n",
    "model.load_state_dict(saved['net'])\n",
    "\n",
    "# Data\n",
    "data = MnistData(config['batch_size'], (config['size'], config['size']), config['k'])\n",
    "\n",
    "# Evaluation function\n",
    "def test_model(model, loader, func):\n",
    "    accuracy = 0\n",
    "    loss = 0\n",
    "    model.eval()\n",
    "\n",
    "    print(f\"Total validation samples: {loader.val_len()}\")  # Print total number of validation samples\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(loader.val_len())):\n",
    "            test_x, test_y = func(i)\n",
    "            test_x = model.to_device(test_x)\n",
    "            test_y = model.to_device(test_y).long()\n",
    "            probs  = model(test_x)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "            correct = preds == test_y\n",
    "            accuracy += correct.sum().item()\n",
    "\n",
    "    accuracy /= 100  # Use the total number of items in the validation set for accuracy calculation\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# Evaluate on all three validation sets\n",
    "validation_functions = [data.val_get1, data.val_get2, data.val_get3]\n",
    "validation_accuracies_lstm = []\n",
    "\n",
    "print(f\"Model: {config['model']}, Device: {device}\")\n",
    "print(f\"Configuration: {config}\")\n",
    "\n",
    "for func in validation_functions:\n",
    "    accuracy = test_model(model, data, func)\n",
    "    validation_accuracies_lstm.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4b188f-b335-4ffb-b723-4782aa18af7d",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Print accuracies for all validation sets (RIMs)\n",
    "for i, accuracy in enumerate(validation_accuracies_rim, 1):\n",
    "    print(f'Validation Set {i} Accuracy (RIMs): {accuracy:.2f}%')\n",
    "\n",
    "# Print accuracies for all validation sets (LSTM)\n",
    "for i, accuracy in enumerate(validation_accuracies_lstm, 1):\n",
    "    print(f'Validation Set {i} Accuracy (LSTM): {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367f514c-7da3-4f7b-bea3-adcada11ed47",
   "metadata": {
    "execution": {}
   },
   "source": [
    "As you can see, the accuracy on 16x16 images is not extremely different. However, RIMs generalize way more robustly to 19x19 and 24x24 images. To achieve this, the authors built recurrent networks that are modular in nature, with each module being independent of the other modules and only interacting sparsely through attention. In this way, each module can learn different aspects of the environment and is only responsible for ensuring similar performance on the same aspect of a different environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45788f3e-bcba-4a40-8836-833d1d06803d",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Section 2: Global Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0ea49e-f052-42c0-8b1a-c37135584646",
   "metadata": {
    "execution": {}
   },
   "source": [
    "As we have seen, deep learning has shifted towards structured models with specialized modules that enhance scalability and generalization. But we can go one step further. Inspired by the 1980s AI focus on modular architectures and the Global Workspace Theory from cognitive neuroscience, the approach [https://arxiv.org/pdf/2103.01197.pdf] we are going to analyse in this section employs a shared global workspace for module coordination. It promotes flexibility and systematic generalization by allowing dynamic interactions among specialized modules. This model emphasizes the importance of having a number of sparsely communicating specialist modules interact via a shared working memory, aiming to achieve coherent and efficient behavior across the system. \n",
    "\n",
    "RIMs leverage a self-attention mechanism to enable information sharing among specialist modules, traditionally through pairwise interactions where each module attends to every other. This new approach, however, introduces a shared workspace with limited capacity to streamline this process. At each computational step, specialist modules compete for the opportunity to write to this shared workspace. Subsequently, the information stored in the workspace is broadcasted to all specialists simultaneously, enhancing coordination and information flow among the modules without the need for direct pairwise communication."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d22f777-19ce-4858-a1dd-93d98bbf9035",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding Exercise: Creating a Shared Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf09def-0d69-4c45-b418-0d956789de07",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Specialists compete to write their information into the shared workspace. This process is guided by a key-query-value attention mechanism, where the competition is realized through attention scores determining which specialists' information is most critical to be updated in the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2380f39e-ec9f-4981-b0c0-2531f1730db7",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)  # Ensure reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d73b534-831e-4e4f-b268-02077f8599bc",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "class SharedWorkspace(nn.Module):\n",
    "\n",
    "    def __init__(self, num_specialists, hidden_dim, num_memory_slots, memory_slot_dim):\n",
    "        #################################################\n",
    "        ## TODO for students: fill in the missing variables ##\n",
    "        # Fill out function and remove\n",
    "        raise NotImplementedError(\"Student exercise: fill in the missing variables\")\n",
    "        #################################################\n",
    "        super().__init__()\n",
    "        self.num_specialists = num_specialists\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_memory_slots = num_memory_slots\n",
    "        self.memory_slot_dim = memory_slot_dim\n",
    "        self.workspace_memory = nn.Parameter(torch.randn(num_memory_slots, memory_slot_dim))\n",
    "\n",
    "        # Attention mechanism components for writing to the workspace\n",
    "        self.key = ...\n",
    "        self.query = ...\n",
    "        self.value = nn.Linear(hidden_dim, memory_slot_dim)\n",
    "\n",
    "    def write_to_workspace(self, specialists_states):\n",
    "        #################################################\n",
    "        ## TODO for students: fill in the missing variables ##\n",
    "        # Fill out function and remove\n",
    "        raise NotImplementedError(\"Student exercise: fill in the missing variables\")\n",
    "        #################################################\n",
    "        # Flatten specialists' states if they're not already\n",
    "        specialists_states = specialists_states.view(-1, self.hidden_dim)\n",
    "\n",
    "        # Compute key, query, and value\n",
    "        keys = self.key(specialists_states)\n",
    "        query = self.query(self.workspace_memory)\n",
    "        values = self.value(specialists_states)\n",
    "\n",
    "        # Compute attention scores and apply softmax\n",
    "        attention_scores = torch.matmul(query, keys.transpose(-2, -1)) / (self.memory_slot_dim ** 0.5)\n",
    "        attention_probs = ...\n",
    "\n",
    "        # Update workspace memory with weighted sum of values\n",
    "        updated_memory = torch.matmul(attention_probs, values)\n",
    "        self.workspace_memory = nn.Parameter(updated_memory)\n",
    "\n",
    "        return self.workspace_memory\n",
    "\n",
    "    def forward(self, specialists_states):\n",
    "        #################################################\n",
    "        ## TODO for students: fill in the missing variables ##\n",
    "        # Fill out function and remove\n",
    "        raise NotImplementedError(\"Student exercise: fill in the missing variables\")\n",
    "        #################################################\n",
    "        updated_memory = ...\n",
    "        return updated_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4d1740-cc8b-4246-b566-e725e52e54b1",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# to remove solution\n",
    "\n",
    "class SharedWorkspace(nn.Module):\n",
    "\n",
    "    def __init__(self, num_specialists, hidden_dim, num_memory_slots, memory_slot_dim):\n",
    "        super().__init__()\n",
    "        self.num_specialists = num_specialists\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_memory_slots = num_memory_slots\n",
    "        self.memory_slot_dim = memory_slot_dim\n",
    "        self.workspace_memory = nn.Parameter(torch.randn(num_memory_slots, memory_slot_dim))\n",
    "\n",
    "        # Attention mechanism components for writing to the workspace\n",
    "        self.key = nn.Linear(hidden_dim, memory_slot_dim)\n",
    "        self.query = nn.Linear(memory_slot_dim, memory_slot_dim)\n",
    "        self.value = nn.Linear(hidden_dim, memory_slot_dim)\n",
    "\n",
    "    def write_to_workspace(self, specialists_states):\n",
    "        # Flatten specialists' states if they're not already\n",
    "        specialists_states = specialists_states.view(-1, self.hidden_dim)\n",
    "\n",
    "        # Compute key, query, and value\n",
    "        keys = self.key(specialists_states)\n",
    "        query = self.query(self.workspace_memory)\n",
    "        values = self.value(specialists_states)\n",
    "\n",
    "        # Compute attention scores and apply softmax\n",
    "        attention_scores = torch.matmul(query, keys.transpose(-2, -1)) / (self.memory_slot_dim ** 0.5)\n",
    "        attention_probs = F.softmax(attention_scores, dim=-1)\n",
    "\n",
    "        # Update workspace memory with weighted sum of values\n",
    "        updated_memory = torch.matmul(attention_probs, values)\n",
    "        self.workspace_memory = nn.Parameter(updated_memory)\n",
    "\n",
    "        return self.workspace_memory\n",
    "\n",
    "    def forward(self, specialists_states):\n",
    "        updated_memory = self.write_to_workspace(specialists_states)\n",
    "        return updated_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c901689-abca-4a3a-8d14-9cb2644f5184",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Example parameters\n",
    "num_specialists = 5\n",
    "hidden_dim = 10\n",
    "num_memory_slots = 4\n",
    "memory_slot_dim = 6\n",
    "\n",
    "# Generate deterministic specialists' states\n",
    "specialists_states = torch.randn(num_specialists, hidden_dim)\n",
    "\n",
    "workspace = SharedWorkspace(num_specialists, hidden_dim, num_memory_slots, memory_slot_dim)\n",
    "expected_output = workspace.forward(specialists_states)\n",
    "print(\"Expected Output:\", expected_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ed9ace-b3de-4fdc-8996-664dd8e4b3a1",
   "metadata": {
    "execution": {}
   },
   "source": [
    "After updating the shared workspace with the most critical signals, this information is then broadcast back to all specialists. Each specialist updates its state using this broadcast information, which can involve an attention mechanism for consolidation and an update function (like an LSTM or GRU step) based on the new combined state. Let's add this method!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03836253-ec99-490b-9921-db1395e5c3de",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "def broadcast_from_workspace(self, specialists_states):\n",
    "    # Broadcast updated memory to specialists\n",
    "    broadcast_query = self.query(specialists_states).view(self.num_specialists, -1, self.memory_slot_dim)\n",
    "    broadcast_keys = self.key(self.workspace_memory).unsqueeze(0).repeat(self.num_specialists, 1, 1)\n",
    "\n",
    "    # Compute attention scores for broadcasting\n",
    "    broadcast_attention_scores = torch.matmul(broadcast_query, broadcast_keys.transpose(-2, -1)) / (self.memory_slot_dim ** 0.5)\n",
    "    broadcast_attention_probs = F.softmax(broadcast_attention_scores, dim=-1)\n",
    "\n",
    "    # Update specialists' states with attention-weighted memory information\n",
    "    broadcast_values = self.value(self.workspace_memory).unsqueeze(0).repeat(self.num_specialists, 1, 1)\n",
    "    updated_states = torch.matmul(broadcast_attention_probs, broadcast_values)\n",
    "\n",
    "    return updated_states.view_as(specialists_states)\n",
    "\n",
    "# Assign the method to the class\n",
    "SharedWorkspace.broadcast_from_workspace = broadcast_from_workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc221d3-530e-4835-b542-905ce3e281bf",
   "metadata": {
    "execution": {}
   },
   "source": [
    "This approach modularizes the shared workspace functionality, ensuring the specialists' states are first aggregated in a competitive manner into the workspace, followed by an efficient distribution of this consolidated information. This mechanism allows for dynamic filtering based on the current context and enhances the model's ability to generalize from past experiences by focusing on the most relevant signals at each computational step. To integrate this into a full system, you would need to instantiate this SharedWorkspace within your RIM architecture, ensuring that the initial representations of specialists are processed (Step 1), passed to the SharedWorkspace for competition and update (Step 2), and then the updated information is broadcast back to the specialists (Step3)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f71074b-70b5-4446-bf86-00e9f781ecd7",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Section 3: a toy model for illustrating GNW "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa2a7bc-5498-48d4-a1ee-599314124450",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now, we outline a `SimpleGNWModel` class for simulating node activation within a network. It uses an Erdős-Rényi graph to model connections and includes methods to activate nodes, reset the network, and visualize the results. This setup provides an interactive introduction to network dynamics, making it easy to observe how activations spread across a network.\n",
    "\n",
    "In the network visualization, the colors distinguish between active and inactive nodes. Active nodes are colored green, indicating they have been activated either directly or through their connection to another activated node. Inactive nodes are colored red, showing they have yet to be activated in the simulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3070b46f-51c0-4416-80ee-728a32f75cd3",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "class SimpleGNWModel:\n",
    "    def __init__(self, num_nodes=5):\n",
    "        self.num_nodes = num_nodes\n",
    "        self.network = nx.erdos_renyi_graph(n=num_nodes, p=0.5)\n",
    "        self.activations = {node: False for node in self.network.nodes}\n",
    "\n",
    "    def activate_node(self):\n",
    "        selected_node = random.choice(list(self.network.nodes))\n",
    "        self.activations[selected_node] = True\n",
    "\n",
    "        # Simulate global broadcast\n",
    "        for neighbor in self.network.neighbors(selected_node):\n",
    "            self.activations[neighbor] = True\n",
    "\n",
    "    def reset_activations(self):\n",
    "        self.activations = {node: False for node in self.network.nodes}\n",
    "\n",
    "    def draw_network(self):\n",
    "        color_map = ['green' if self.activations[node] else 'red' for node in self.network.nodes]\n",
    "        nx.draw(self.network, node_color=color_map, with_labels=True, node_size=700)\n",
    "        plt.show()\n",
    "\n",
    "# Create a GNW model instance\n",
    "gnw_model = SimpleGNWModel()\n",
    "\n",
    "# Button to activate a node\n",
    "activate_button = widgets.Button(description='Activate Node')\n",
    "\n",
    "# Button to reset activations\n",
    "reset_button = widgets.Button(description='Reset')\n",
    "\n",
    "# Output area for the network graph\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def on_activate_clicked(b):\n",
    "    with output_area:\n",
    "        output_area.clear_output(wait=True)\n",
    "        gnw_model.activate_node()\n",
    "        gnw_model.draw_network()\n",
    "\n",
    "def on_reset_clicked(b):\n",
    "    with output_area:\n",
    "        output_area.clear_output(wait=True)\n",
    "        gnw_model.reset_activations()\n",
    "        gnw_model.draw_network()\n",
    "\n",
    "activate_button.on_click(on_activate_clicked)\n",
    "reset_button.on_click(on_reset_clicked)\n",
    "\n",
    "display(widgets.VBox([activate_button, reset_button, output_area]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c701cbc-d70b-44e3-8838-7b917ff3ef1a",
   "metadata": {
    "execution": {}
   },
   "source": [
    "When you click on the \"Activate Node\" button, the code randomly selects one node in the network and activates it, changing its status to active (if it was inactive). This action also triggers a \"global broadcast\" effect, meaning that all of the selected node's immediate neighbors are activated as well. The network visualization then updates to reflect these changes: the activated nodes are colored green, while any nodes that remain inactive are colored red. This process visually demonstrates how activation can spread through a network, highlighting the connections between nodes and the potential influence of a single node's activation on its neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2770325e-4d09-4666-a8cd-b69a7932ea4a",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Ignition "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87a9de2-701e-46f1-830c-a515fed7558a",
   "metadata": {
    "execution": {}
   },
   "source": [
    "The idea of ignition in cognitive science refers to the moment a stimulus becomes strong enough to trigger a widespread activation across the network, simulating the threshold of conscious awareness.\n",
    "\n",
    "The following class is equipped with a damping factor that controls how activation spreads through the network, mirroring the dampening effects seen in biological networks where not all signals lead to widespread activation. The network itself is constructed with nodes and directed edges to represent the flow of information, crucial for understanding how different parts of a cognitive system can ignite and sustain activation that leads to consciousness.\n",
    "\n",
    "By simulating the propagation of a stimulus through the network for given durations, the model visualizes the ignition process. Activation levels are calculated at each step, showing how initial stimuli can either dissipate or amplify to achieve ignition across the network. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150504f0-67d9-43df-88db-97d265fd4d92",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "class GlobalWorkspaceNetwork:\n",
    "    \"\"\"\n",
    "    A class to model and visualize a simplified global workspace network.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, damping_factor=0.1):\n",
    "        \"\"\"\n",
    "        Initialize the network with a specified damping factor.\n",
    "\n",
    "        :param damping_factor: A float representing the damping factor applied to activation propagation.\n",
    "        \"\"\"\n",
    "        if not 0 <= damping_factor <= 1:\n",
    "            raise ValueError(\"Damping factor must be between 0 and 1.\")\n",
    "\n",
    "        self.network = nx.DiGraph()\n",
    "        self.damping_factor = damping_factor\n",
    "        self.setup_network()\n",
    "\n",
    "    def setup_network(self, nodes=None, edges=None):\n",
    "        \"\"\"\n",
    "        Set up the network structure.\n",
    "\n",
    "        :param nodes: A list of nodes for the network. If None, a default set is used.\n",
    "        :param edges: A list of tuples representing edges between nodes. If None, a default set is used.\n",
    "        \"\"\"\n",
    "        default_nodes = [\"sensory_input\", \"processing_module\", \"global_workspace\", \"visual_cortex\"]\n",
    "        default_edges = [\n",
    "            (\"sensory_input\", \"processing_module\"),\n",
    "            (\"processing_module\", \"global_workspace\"),\n",
    "            (\"global_workspace\", \"visual_cortex\"),\n",
    "            (\"visual_cortex\", \"processing_module\")\n",
    "        ]\n",
    "        self.network.add_nodes_from(nodes if nodes is not None else default_nodes)\n",
    "        self.network.add_edges_from(edges if edges is not None else default_edges)\n",
    "\n",
    "    def propagate_stimulus(self, duration):\n",
    "        \"\"\"\n",
    "        Simulate the propagation of stimulus through the network for a given duration.\n",
    "\n",
    "        :param duration: The number of steps to simulate.\n",
    "        :return: A dictionary of activation levels for each node.\n",
    "        \"\"\"\n",
    "        activation_levels = {node: 0 for node in self.network.nodes}\n",
    "        activation_levels[\"sensory_input\"] = 1\n",
    "\n",
    "        for step in range(duration):\n",
    "            new_activation_levels = activation_levels.copy()\n",
    "            for node in self.network.nodes:\n",
    "                total_input = sum(activation_levels[pre] for pre in self.network.predecessors(node))\n",
    "                new_activation_levels[node] += total_input * (1 - self.damping_factor)\n",
    "            activation_levels = new_activation_levels\n",
    "\n",
    "        return activation_levels\n",
    "\n",
    "    def visualize_network(self, activation_levels):\n",
    "        \"\"\"\n",
    "        Visualize the network with node colors representing activation levels.\n",
    "\n",
    "        :param activation_levels: A dictionary of activation levels for each node.\n",
    "        \"\"\"\n",
    "        pos = nx.spring_layout(self.network, seed=42)  # For consistent layout\n",
    "        nx.draw(self.network, pos, with_labels=True, node_size=700)\n",
    "        nx.draw_networkx_nodes(self.network, pos, nodelist=activation_levels.keys(),\n",
    "        node_color=[activation_levels[n] for n in activation_levels],\n",
    "        cmap=plt.cm.viridis)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def interactive_propagation(self):\n",
    "        \"\"\"\n",
    "        Create an interactive widget to explore the effects of stimulus duration on the network.\n",
    "        \"\"\"\n",
    "        @interact(duration=IntSlider(min=1, max=10, step=1, value=1))\n",
    "        def update(duration):\n",
    "            activation_levels = self.propagate_stimulus(duration)\n",
    "            self.visualize_network(activation_levels)\n",
    "\n",
    "# Create an instance of the GlobalWorkspaceNetwork\n",
    "gwn = GlobalWorkspaceNetwork(damping_factor=0.06)  # Feel free to adjust the damping factor\n",
    "\n",
    "# Use the interactive widget to explore how different durations of stimulus affect the network\n",
    "gwn.interactive_propagation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfa4601-c636-4999-9b2d-70f1d85057ab",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Section 4: Second Order Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d70aae-6376-48c4-876f-41fcbd4c05dd",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Section 5: HOSS model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85588efd-993d-4125-9859-12c28d600834",
   "metadata": {
    "execution": {}
   },
   "source": [
    "The following function is designed for inference within a simplified Bayesian framework, specifically tailored for assessing perceptual states based on observed data. It computes the posterior probabilities of these states and the Kullback-Leibler (KL) divergence between the posterior and prior distributions. This function operates under a model that assumes a flat (or single-layer) Bayesian network, focusing directly on the relationship between perceptual states and observed data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aa71fb-ce0a-4f12-a7a6-3df4996eb358",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "def HOSS_evaluate_flat(X, mu, Sigma, Wprior):\n",
    "    \"\"\"\n",
    "    Perform inference on a 2D Bayes net for asymmetric inference on presence vs. absence.\n",
    "\n",
    "    Parameters:\n",
    "    X - Observed data\n",
    "    mu - Means for each perceptual state\n",
    "    Sigma - Covariance matrix\n",
    "    Wprior - Prior probabilities of perceptual states\n",
    "\n",
    "    #Returns:\n",
    "    post_W - Posterior probabilities of perceptual states\n",
    "    KL_W - Kullback-Leibler divergence from posterior to prior\n",
    "    \"\"\"\n",
    "    # Prior on perceptual states W\n",
    "    p_W = Wprior\n",
    "\n",
    "    # Compute likelihood of observed X for each possible W (P(X|W))\n",
    "    log_lik_X_W = np.array([np.log(multivariate_normal.pdf(X, mean=mu[m], cov=Sigma)) for m in range(mu.shape[0])])\n",
    "\n",
    "    # Renormalize to get P(X|W)\n",
    "    log_p_X_W = log_lik_X_W - logsumexp(log_lik_X_W)\n",
    "\n",
    "    # Posterior over W (P(W|X=x))\n",
    "    log_post_W = log_p_X_W + np.log(p_W)\n",
    "    log_post_W = log_post_W - logsumexp(log_post_W)  # Normalize\n",
    "    post_W = np.exp(log_post_W)\n",
    "\n",
    "    # KL divergences\n",
    "    KL_W = np.sum(post_W * (np.log(post_W) - np.log(p_W)))\n",
    "\n",
    "    return post_W, KL_W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cfba4a-b48a-48c5-a554-f03e7096af2e",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Make our stimulus space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ffb999-c213-4400-8f1b-dac5b42ff5e1",
   "metadata": {
    "execution": {}
   },
   "source": [
    "The model we are using is grounded in classical \"signal detection theory\", or SDT for short. SDT is in turn a special case of a Bayesian generative model, in which an arbitrary \"evidence\" value is drawn from an unknown distribution, and the task of the observer is to infer which distribution this evidence came from.\n",
    "\n",
    "Let's imagine we have two categories, A and B - for instance, left- and right-tilted visual stimuli. \n",
    "The sensory \"evidence\" can be written as 2D vector, where the first element is evidence for A, and the second element evidence for B:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eeba6f-6608-41e1-bfa3-2861bbeb6738",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Creating the array X with strong evidence for A and weak evidence for B\n",
    "X = np.array([1.5, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd32b9f0-cd87-43fa-8169-8fdb78fd606d",
   "metadata": {
    "execution": {}
   },
   "source": [
    "The origin (0,0) represents low activation of both features, consistent with no stimulus (or noise) being presented. Comparing how the model handles inference on stimulus presence vs. absence - detecting, vs. not detecting a stimulus - allows us to capture the classical conscious vs. unconscious contrast in consciousness science.\n",
    "\n",
    "Let's start by creating our space, and placing three Gaussian distributions on the space that represent the likelihood of observing a pair of features given each of three stimulus classes: leftward tilt (w1), rightward tilt (w2) and noise/nothing (w0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c40e73d-d90c-4630-9089-4cb64d22f811",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Define the grid\n",
    "xgrid = np.arange(-4, 6.02, 0.02)\n",
    "X1, X2 = np.meshgrid(xgrid, xgrid)\n",
    "\n",
    "# Mean and covariance of the distributions\n",
    "mu = np.array([[0.5, 0.5], [3.5, 0.5], [0.5, 3.5]])\n",
    "Sigma = np.array([[1, 0], [0, 1]])\n",
    "\n",
    "# Plotting\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Colors and labels according to the specification\n",
    "colors = ['green', 'blue', 'red']\n",
    "labels = ['w0', 'w1', 'w2']\n",
    "\n",
    "for i, (color, label) in enumerate(zip(colors, labels)):\n",
    "    p = multivariate_normal.pdf(np.dstack((X1, X2)), mean=mu[i], cov=Sigma)\n",
    "    ax.plot_surface(X1, X2, p.reshape(X1.shape), color=color, alpha=0.5, label=label)\n",
    "\n",
    "# Create custom legends\n",
    "legend_elements = [Patch(facecolor=color, edgecolor='k', label=label) for color, label in zip(colors, labels)]\n",
    "ax.legend(handles=legend_elements, loc='upper right')\n",
    "\n",
    "# Reverse the X1 axis\n",
    "ax.set_xlim([6, -4])\n",
    "ax.set_ylim([-4, 6])\n",
    "ax.set_xlabel('X1')\n",
    "ax.set_ylabel('X2')\n",
    "ax.set_title('2D SDT')\n",
    "ax.view_init(45, -45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27f1787-11f0-4c57-8685-dc49e0819540",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Define the input parameters\n",
    "mu = np.array([[3.5, 0.5], [0.5, 3.5], [0.5, 0.5]])\n",
    "Sigma = np.array([[1, 0], [0, 1]])\n",
    "Wprior = np.array([1/3, 1/3, 1/3])  # flat priors\n",
    "\n",
    "# High evidence for X1, low evidence for X2\n",
    "X = np.array([3, 0])\n",
    "post_w, KL_W = HOSS_evaluate_flat(X, mu, Sigma, Wprior)\n",
    "print('Posterior probabilities for X = [3, 0]:', post_w)\n",
    "print('KL Divergence for X = [3, 0]:', KL_W)\n",
    "\n",
    "# High evidence for X2, low evidence for X1\n",
    "X = np.array([0, 3])\n",
    "post_w, KL_W = HOSS_evaluate_flat(X, mu, Sigma, Wprior)\n",
    "print('Posterior probabilities for X = [0, 3]:', post_w)\n",
    "print('KL Divergence for X = [0, 3]:', KL_W)\n",
    "\n",
    "# No evidence for either\n",
    "X = np.array([0, 0])\n",
    "post_w, KL_W = HOSS_evaluate_flat(X, mu, Sigma, Wprior)\n",
    "print('Posterior probabilities for X = [0, 0]:', post_w)\n",
    "print('KL Divergence for X = [0, 0]:', KL_W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5573eaad-da8f-4379-b226-497b7333374d",
   "metadata": {
    "execution": {}
   },
   "source": [
    "This is as we would expect - the most likely state is recovered in each case. The slightly higher KL divergence in the third scenario indicates a greater degree of \"surprise\" or information gain, as the prior was uniformly distributed across all states, but the posterior is now highly concentrated on the third state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978c08c7-ea2b-43bb-b1b4-560ba46089a6",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Add in higher-order node for global detection\n",
    "So far we have considered a \"flat\" architecture in which each state (w1, w2 or absence) is independent.\n",
    "The key addition in HOSS is to allow the model to flexibly answer queries about awareness of any stimulus contents (w1 or w2... or wN).\n",
    "We achieve this by introducing a higher-order node - the \"A\" level - that \"monitors\" for activations in the W-level below.\n",
    "\n",
    "The inputs remain the same - pairs of X's. But now the outputs give us queries on both the W (content) and A (awareness) levels - where post_A denotes the posterior probaiblity of any content (vs. noise).\n",
    "We now also need to set priors at both the A- and W-levels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8c6660-231a-4b1c-8c6d-224007e2fad5",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Coding exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a12f7e4-1eba-47b2-b49e-1ae0593ced22",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "```python\n",
    "def HOSS_evaluate(X, mu, Sigma, Aprior, Wprior):\n",
    "    \"\"\"\n",
    "    Inference on 2D Bayes net for asymmetric inference on presence vs. absence.\n",
    "    \"\"\"\n",
    "\n",
    "    #################################################\n",
    "    ## TODO for students: fill in the missing variables ##\n",
    "    # Fill out function and remove\n",
    "    raise NotImplementedError(\"Student exercise: fill in the missing variables\")\n",
    "    #################################################\n",
    "\n",
    "    # Initialise variables and conditional prob tables\n",
    "    p_A = np.array([1 - Aprior, Aprior])  # prior on awareness state A\n",
    "    p_W_a1 = np.append(Wprior, 0)  # likelihood of world states W given aware, last entry is absence\n",
    "    p_W_a0 = np.append(np.zeros(len(Wprior)), 1)  # likelihood of world states W given unaware, last entry is absence\n",
    "    p_W = (p_W_a1 + p_W_a0) / 2  # prior on W marginalising over A (for KL)\n",
    "\n",
    "    # Compute likelihood of observed X for each possible W (P(X|mu_w, Sigma))\n",
    "    lik_X_W = np.array([multivariate_normal.pdf(...) for mu_i in mu])\n",
    "    p_X_W = lik_X_W / lik_X_W.sum()  # normalise to get P(X|W)\n",
    "\n",
    "    # Combine with likelihood of each world state w given awareness state A\n",
    "    lik_W_A = np.vstack((p_X_W * p_W_a0 * p_A[0], p_X_W * p_W_a1 * p_A[1]))\n",
    "    post_A = ...  # sum over W\n",
    "    post_A = post_A / post_A.sum()  # normalise\n",
    "\n",
    "    # Posterior over W (P(W|X=x) marginalising over A)\n",
    "    post_W = ...  # sum over A\n",
    "    post_W = post_W / post_W.sum()  # normalise\n",
    "\n",
    "    # KL divergences\n",
    "    KL_W = (post_W * np.log(post_W / p_W)).sum()\n",
    "    KL_A = (post_A * np.log(post_A / p_A)).sum()\n",
    "\n",
    "    return post_W, post_A, KL_W, KL_A\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb04c59-a0e2-4595-ac2c-5659242eb42f",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# to_remove solution\n",
    "\n",
    "def HOSS_evaluate(X, mu, Sigma, Aprior, Wprior):\n",
    "    \"\"\"\n",
    "    Inference on 2D Bayes net for asymmetric inference on presence vs. absence.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialise variables and conditional prob tables\n",
    "    p_A = np.array([1 - Aprior, Aprior])  # prior on awareness state A\n",
    "    p_W_a1 = np.append(Wprior, 0)  # likelihood of world states W given aware, last entry is absence\n",
    "    p_W_a0 = np.append(np.zeros(len(Wprior)), 1)  # likelihood of world states W given unaware, last entry is absence\n",
    "    p_W = (p_W_a1 + p_W_a0) / 2  # prior on W marginalising over A (for KL)\n",
    "\n",
    "    # Compute likelihood of observed X for each possible W (P(X|mu_w, Sigma))\n",
    "    lik_X_W = np.array([multivariate_normal.pdf(X, mean=mu_i, cov=Sigma) for mu_i in mu])\n",
    "    p_X_W = lik_X_W / lik_X_W.sum()  # normalise to get P(X|W)\n",
    "\n",
    "    # Combine with likelihood of each world state w given awareness state A\n",
    "    lik_W_A = np.vstack((p_X_W * p_W_a0 * p_A[0], p_X_W * p_W_a1 * p_A[1]))\n",
    "    post_A = lik_W_A.sum(axis=1)  # sum over W\n",
    "    post_A = post_A / post_A.sum()  # normalise\n",
    "\n",
    "    # Posterior over W (P(W|X=x) marginalising over A)\n",
    "    post_W = lik_W_A.sum(axis=0)  # sum over A\n",
    "    post_W = post_W / post_W.sum()  # normalise\n",
    "\n",
    "    # KL divergences\n",
    "    KL_W = (post_W * np.log(post_W / p_W)).sum()\n",
    "    KL_A = (post_A * np.log(post_A / p_A)).sum()\n",
    "\n",
    "    return post_W, post_A, KL_W, KL_A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c45dfdc-3442-40ea-b116-7daae2d73384",
   "metadata": {
    "execution": {}
   },
   "source": [
    "This is now factorised in the code, so we first set the prior on presence (vs. absence), and then set the priors on w1 vs. w2, and the model takes care of the rest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8a881f-3103-4fbc-b958-8f29db2bee57",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Define the input parameters for this specific example\n",
    "X = np.array([0, 3])  # Input observed features\n",
    "Wprior = np.array([0.5, 0.5])  # Prior probabilities of stimuli\n",
    "Aprior = 0.5  # Prior probability of being aware\n",
    "\n",
    "# Call the HOSS_evaluate function with the specified parameters\n",
    "post_W, post_A, KL_W, KL_A = HOSS_evaluate(X, mu, Sigma, Aprior, Wprior)\n",
    "\n",
    "# Print the posterior probabilities\n",
    "print(f\"Posterior probabilities at W level: {post_W}\")\n",
    "print(f\"Posterior probability at A level: {post_A}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03eb858-2e3e-442e-8f74-746268824a30",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Define the input parameters for this specific example\n",
    "X = np.array([0, 3])  # Input observed features\n",
    "Wprior = np.array([0.5, 0.5])  # Prior probabilities of stimuli\n",
    "Aprior = 0.5  # Prior probability of being aware\n",
    "\n",
    "# Call the HOSS_evaluate function with the specified parameters\n",
    "post_W, post_A, KL_W, KL_A = HOSS_evaluate(X, mu, Sigma, Aprior, Wprior)\n",
    "\n",
    "# Print the posterior probabilities\n",
    "print(f\"Posterior probabilities at W level: {post_W}\")\n",
    "print(f\"Posterior probability at A level: {post_A}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a694f1e-3f32-48fc-bce8-0b544d43ca62",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Plot surfaces for content / awareness inferences\n",
    "To explore the properties of the model, we can simulate inference at different levels of the hierarchy over the full 2D space of possible input X's. The left panel below shows that the probability of awareness (of any stimulus contents) rises in a graded manner from the lower left corner of the graph (low activation of any feature) to the upper right (high activation of both features). In contrast, the right panel shows that confidence in making a discrimination response (e.g. rightward vs. leftward) increases away from the major diagonal, as the model becomes sure that the sample was generated by either a leftward or rightward tilted stimulus. \n",
    "\n",
    "Together, the two surfaces make predictions about the relationships we might see between discrimination confidence and awareness in a simple psychophysics experiment. One notable prediction is that discrimination could still be possible - and lead to some degree of confidence - even when the higher-order node is \"reporting\" unawareness of the stimulus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7add05-825c-477e-8051-dd24ecbccc66",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Define the grid\n",
    "xgrid = np.arange(0, 2.01, 0.01)\n",
    "\n",
    "# Define the means for the Gaussian distributions\n",
    "mu = np.array([[0.5, 1.5], [1.5, 0.5], [0.5, 0.5]])\n",
    "\n",
    "# Define the covariance matrix\n",
    "Sigma = np.array([[1, 0], [0, 1]])\n",
    "\n",
    "# Prior probabilities\n",
    "Wprior = np.array([0.5, 0.5])\n",
    "Aprior = 0.5\n",
    "\n",
    "# Initialize arrays to hold confidence and posterior probability\n",
    "confW = np.zeros((len(xgrid), len(xgrid)))\n",
    "posteriorAware = np.zeros((len(xgrid), len(xgrid)))\n",
    "KL_w = np.zeros((len(xgrid), len(xgrid)))\n",
    "KL_A = np.zeros((len(xgrid), len(xgrid)))\n",
    "\n",
    "# Compute confidence and posterior probability for each point in the grid\n",
    "for i, xi in enumerate(xgrid):\n",
    "    for j, xj in enumerate(xgrid):\n",
    "        X = [xi, xj]\n",
    "        post_w, post_A, KL_w[i, j], KL_A[i, j] = HOSS_evaluate(X, mu, Sigma, Aprior, Wprior)\n",
    "\n",
    "        confW[i, j] = max(post_w)\n",
    "        posteriorAware[i, j] = post_A[1]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Posterior probability \"seen\"\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.contourf(xgrid, xgrid, posteriorAware.T)\n",
    "plt.colorbar()\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.title('Posterior probability \"seen\"')\n",
    "plt.axis('square')\n",
    "\n",
    "# Confidence in identity\n",
    "plt.subplot(1, 2, 2)\n",
    "contour_set = plt.contourf(xgrid, xgrid, confW.T)\n",
    "plt.colorbar()\n",
    "plt.contour(xgrid, xgrid, posteriorAware.T, levels=[0.5], linewidths=4, colors=['white'])  # Line contour for threshold\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.title('Confidence in identity')\n",
    "plt.axis('square')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fb2c34-fd8e-4525-bf21-aa582657c565",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Simulate KL divergence surfaces\n",
    "\n",
    "We can also simulate K-L divergences (a measure of Bayesian surprise) at each layer in the network, which under predictive coding models of brain has been proposed to scale with neural activation (eg Friston, 2005; Summerfield & de Lange, 2014)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bf267c-3acb-4ca4-ab47-4bc99ad7bc70",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Calculate the mean K-L divergence for absent and present awareness states\n",
    "KL_A_absent = np.mean(KL_A[posteriorAware < 0.5])\n",
    "KL_A_present = np.mean(KL_A[posteriorAware >= 0.5])\n",
    "KL_w_absent = np.mean(KL_w[posteriorAware < 0.5])\n",
    "KL_w_present = np.mean(KL_w[posteriorAware >= 0.5])\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "# K-L divergence, perceptual states\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.contourf(xgrid, xgrid, KL_w.T, cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.title('K-L divergence, perceptual states')\n",
    "plt.axis('square')\n",
    "\n",
    "# K-L divergence, awareness state\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.contourf(xgrid, xgrid, KL_A.T, cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.title('K-L divergence, awareness state')\n",
    "plt.axis('square')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463989fa-0824-4c8c-9bdd-dbb7e4857e46",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Discussion point\n",
    "\n",
    "Can you recognise the difference between the K-L divergence for the W-level and the one for the A-level?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8230cc74-de5f-4a18-b5ee-fb5f2e4e14c3",
   "metadata": {
    "execution": {}
   },
   "source": [
    "#### Answer below "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91f5470-e848-4508-a426-f097e43b774a",
   "metadata": {
    "execution": {}
   },
   "source": [
    "At the level of perceptual states W, there is substantial asymmetry in the K-L divergence expected when the model says ‘seen’ vs. ‘unseen’ (lefthand panel). This is due to the large belief updates invoked in the perceptual layer W by samples that deviate from the lower lefthand corner - from absence. In contrast, when we compute K-L divergence for the A-level (righthand panel), the level of prediction error is symmetric across seen and unseen decisions, leading to \"hot\" zones both at the upper righthand (present) and lower lefthand (absent) corners of the 2D space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1c87c0-7067-4e7f-a60f-1ce8caf3ea3c",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We can also sort the K-L divergences as a function of whether the model \"reported\" presence or absence. As can be seen in the bar plots below, there is more asymmetry in the prediction error at the W compared to the A levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f9586b-29cc-42cc-bae5-37eb06f611c7",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Create figure with specified size\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# KL divergence for W states\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(['unseen', 'seen'], [KL_w_absent, KL_w_present], color='k')\n",
    "plt.ylabel('K-L divergence, W states')\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "\n",
    "# KL divergence for A states\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(['unseen', 'seen'], [KL_A_absent, KL_A_present], color='k')\n",
    "plt.ylabel('K-L divergence, A states')\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dee04be-c5f5-487e-aaec-79653cf25768",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Simulate ignition (asymmetry vs. symmetry)\n",
    "\n",
    "A notable feature about the HOSS architecture is that it is asymmetric - there are naturally more possible (perceptual) states nested under \"presence\" than under \"absence\".\n",
    "As we saw in the previous section, this asymmetry in the state space suggests there will be greater summed prediction error in the entire network on presence decisions (as summarized by K-L divergence at each node of W). This may be a computational correlate of the global ignition responses often found to track awareness reports, and which is often interpreted as supporting global workspace models (e.g. Del Cul et al. 2007; Dehaene and Changeux 2011).\n",
    "We can simulate this by asking how the divergence in seen vs. unseen prediction error at the two levels seen in the previous plots changes as a function of stimulus strength - modeled here as sensory precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09f812a-f202-4f3d-ac66-247b322002e7",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "mu = np.array([[3.5, 0.5], [0.5, 3.5], [0.5, 0.5]])\n",
    "Nsubjects = 30\n",
    "Ntrials = 600\n",
    "cond = np.concatenate((np.ones(Ntrials//3), np.ones(Ntrials//3)*2, np.ones(Ntrials//3)*3))\n",
    "Wprior = [0.5, 0.5]\n",
    "Aprior = 0.5\n",
    "\n",
    "# Sensory precision values\n",
    "gamma = np.linspace(0.1, 10, 6)\n",
    "\n",
    "# Initialize lists for results\n",
    "all_KL_w_yes = []\n",
    "sem_KL_w_yes = []\n",
    "all_KL_w_no = []\n",
    "sem_KL_w_no = []\n",
    "all_KL_A_yes = []\n",
    "sem_KL_A_yes = []\n",
    "all_KL_A_no = []\n",
    "sem_KL_A_no = []\n",
    "all_prob_y = []\n",
    "\n",
    "#################################################\n",
    "## TODO for students: fill in the missing variables ##\n",
    "# Fill out function and remove\n",
    "raise NotImplementedError(\"Student exercise: fill in the missing variables\")\n",
    "#################################################\n",
    "\n",
    "for y in ...:\n",
    "    Sigma = np.diag([1./np.sqrt(y)]*2)\n",
    "    mean_KL_w = np.zeros((Nsubjects, 4))\n",
    "    mean_KL_A = np.zeros((Nsubjects, 4))\n",
    "    prob_y = np.zeros(Nsubjects)\n",
    "\n",
    "    for s in range(Nsubjects):\n",
    "        KL_w = np.zeros(len(cond))\n",
    "        KL_A = np.zeros(len(cond))\n",
    "        posteriorAware = np.zeros(len(cond))\n",
    "\n",
    "        # Generate sensory samples\n",
    "        X = np.array([multivariate_normal.rvs(mean=mu[int(c)-1, :], cov=Sigma) for c in cond])\n",
    "\n",
    "        # Model inversion for each trial\n",
    "        for i, x in enumerate(X):\n",
    "            post_w, post_A, KL_w[i], KL_A[i] = HOSS_evaluate(x, mu, Sigma, Aprior, Wprior)\n",
    "            posteriorAware[i] = post_A[1]  # Assuming post_A is a tuple with awareness probability at index 1\n",
    "\n",
    "        binaryAware = posteriorAware > 0.5\n",
    "        for i in range(4):\n",
    "            conditions = [(cond == 3), (cond != 3), (cond != 3), (cond == 3)]\n",
    "            aware_conditions = [(binaryAware == 0), (binaryAware == 0), (binaryAware == 1), (binaryAware == 1)]\n",
    "            mean_KL_w[s, i] = np.mean(KL_w[np.logical_and(aware_conditions[i], conditions[i])])\n",
    "            mean_KL_A[s, i] = np.mean(KL_A[np.logical_and(aware_conditions[i], conditions[i])])\n",
    "\n",
    "        prob_y[s] = np.mean(binaryAware[cond != 3])\n",
    "\n",
    "    # Aggregate results across subjects\n",
    "    all_KL_w_yes.append(np.mean(mean_KL_w[:, 2:4].flatten()))\n",
    "    sem_KL_w_yes.append(np.std(mean_KL_w[:, 2:4].flatten()) / np.sqrt(Nsubjects))\n",
    "    all_KL_w_no.append(np.mean(mean_KL_w[:, :2].flatten()))\n",
    "    sem_KL_w_no.append(np.std(mean_KL_w[:, :2].flatten()) / np.sqrt(Nsubjects))\n",
    "    all_KL_A_yes.append(np.mean(mean_KL_A[:, 2:4].flatten()))\n",
    "    sem_KL_A_yes.append(np.std(mean_KL_A[:, 2:4].flatten()) / np.sqrt(Nsubjects))\n",
    "    all_KL_A_no.append(np.mean(mean_KL_A[:, :2].flatten()))\n",
    "    sem_KL_A_no.append(np.std(mean_KL_A[:, :2].flatten()) / np.sqrt(Nsubjects))\n",
    "    all_prob_y.append(np.mean(prob_y))\n",
    "\n",
    "# Create figure\n",
    "plt.figure(figsize=(16, 4.67))\n",
    "\n",
    "# First subplot: Probability of reporting \"seen\" for w_1 or w_2\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(gamma, all_prob_y, linewidth=2)\n",
    "plt.xlabel('SOA (precision)')\n",
    "plt.ylabel('Prob. report \"seen\" for w_1 or w_2')\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.box(False)\n",
    "\n",
    "# Second subplot: K-L divergence, perceptual states\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.errorbar(gamma, all_KL_w_yes, yerr=sem_KL_w_yes, linewidth=2, label='Seen')\n",
    "plt.errorbar(gamma, all_KL_w_no, yerr=sem_KL_w_no, linewidth=2, label='Unseen')\n",
    "plt.legend(frameon=False)\n",
    "plt.xlabel('SOA (precision)')\n",
    "plt.ylabel('K-L divergence, perceptual states')\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.box(False)\n",
    "\n",
    "# Third subplot: K-L divergence, awareness state\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.errorbar(gamma, all_KL_A_yes, yerr=sem_KL_A_yes, linewidth=2, label='Seen')\n",
    "plt.errorbar(gamma, all_KL_A_no, yerr=sem_KL_A_no, linewidth=2, label='Unseen')\n",
    "plt.legend(frameon=False)\n",
    "plt.xlabel('SOA (precision)')\n",
    "plt.ylabel('K-L divergence, awareness state')\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.box(False)\n",
    "\n",
    "# Adjust layout and display the figure\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af24eab7-5e81-4f04-bdb8-f192058d06b3",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# to remove solution\n",
    "\n",
    "# Experiment parameters\n",
    "mu = np.array([[3.5, 0.5], [0.5, 3.5], [0.5, 0.5]])\n",
    "Nsubjects = 30\n",
    "Ntrials = 600\n",
    "cond = np.concatenate((np.ones(Ntrials//3), np.ones(Ntrials//3)*2, np.ones(Ntrials//3)*3))\n",
    "Wprior = [0.5, 0.5]\n",
    "Aprior = 0.5\n",
    "\n",
    "# Sensory precision values\n",
    "gamma = np.linspace(0.1, 10, 6)\n",
    "\n",
    "# Initialize lists for results\n",
    "all_KL_w_yes = []\n",
    "sem_KL_w_yes = []\n",
    "all_KL_w_no = []\n",
    "sem_KL_w_no = []\n",
    "all_KL_A_yes = []\n",
    "sem_KL_A_yes = []\n",
    "all_KL_A_no = []\n",
    "sem_KL_A_no = []\n",
    "all_prob_y = []\n",
    "\n",
    "for y in gamma:\n",
    "    Sigma = np.diag([1./np.sqrt(y)]*2)\n",
    "    mean_KL_w = np.zeros((Nsubjects, 4))\n",
    "    mean_KL_A = np.zeros((Nsubjects, 4))\n",
    "    prob_y = np.zeros(Nsubjects)\n",
    "\n",
    "    for s in range(Nsubjects):\n",
    "        KL_w = np.zeros(len(cond))\n",
    "        KL_A = np.zeros(len(cond))\n",
    "        posteriorAware = np.zeros(len(cond))\n",
    "\n",
    "        # Generate sensory samples\n",
    "        X = np.array([multivariate_normal.rvs(mean=mu[int(c)-1, :], cov=Sigma) for c in cond])\n",
    "\n",
    "        # Model inversion for each trial\n",
    "        for i, x in enumerate(X):\n",
    "            post_w, post_A, KL_w[i], KL_A[i] = HOSS_evaluate(x, mu, Sigma, Aprior, Wprior)\n",
    "            posteriorAware[i] = post_A[1]  # Assuming post_A is a tuple with awareness probability at index 1\n",
    "\n",
    "        binaryAware = posteriorAware > 0.5\n",
    "        for i in range(4):\n",
    "            conditions = [(cond == 3), (cond != 3), (cond != 3), (cond == 3)]\n",
    "            aware_conditions = [(binaryAware == 0), (binaryAware == 0), (binaryAware == 1), (binaryAware == 1)]\n",
    "            mean_KL_w[s, i] = np.mean(KL_w[np.logical_and(aware_conditions[i], conditions[i])])\n",
    "            mean_KL_A[s, i] = np.mean(KL_A[np.logical_and(aware_conditions[i], conditions[i])])\n",
    "\n",
    "        prob_y[s] = np.mean(binaryAware[cond != 3])\n",
    "\n",
    "    # Aggregate results across subjects\n",
    "    all_KL_w_yes.append(np.mean(mean_KL_w[:, 2:4].flatten()))\n",
    "    sem_KL_w_yes.append(np.std(mean_KL_w[:, 2:4].flatten()) / np.sqrt(Nsubjects))\n",
    "    all_KL_w_no.append(np.mean(mean_KL_w[:, :2].flatten()))\n",
    "    sem_KL_w_no.append(np.std(mean_KL_w[:, :2].flatten()) / np.sqrt(Nsubjects))\n",
    "    all_KL_A_yes.append(np.mean(mean_KL_A[:, 2:4].flatten()))\n",
    "    sem_KL_A_yes.append(np.std(mean_KL_A[:, 2:4].flatten()) / np.sqrt(Nsubjects))\n",
    "    all_KL_A_no.append(np.mean(mean_KL_A[:, :2].flatten()))\n",
    "    sem_KL_A_no.append(np.std(mean_KL_A[:, :2].flatten()) / np.sqrt(Nsubjects))\n",
    "    all_prob_y.append(np.mean(prob_y))\n",
    "\n",
    "# Create figure\n",
    "plt.figure(figsize=(16, 4.67))\n",
    "\n",
    "# First subplot: Probability of reporting \"seen\" for w_1 or w_2\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(gamma, all_prob_y, linewidth=2)\n",
    "plt.xlabel('SOA (precision)')\n",
    "plt.ylabel('Prob. report \"seen\" for w_1 or w_2')\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.box(False)\n",
    "\n",
    "# Second subplot: K-L divergence, perceptual states\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.errorbar(gamma, all_KL_w_yes, yerr=sem_KL_w_yes, linewidth=2, label='Seen')\n",
    "plt.errorbar(gamma, all_KL_w_no, yerr=sem_KL_w_no, linewidth=2, label='Unseen')\n",
    "plt.legend(frameon=False)\n",
    "plt.xlabel('SOA (precision)')\n",
    "plt.ylabel('K-L divergence, perceptual states')\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.box(False)\n",
    "\n",
    "# Third subplot: K-L divergence, awareness state\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.errorbar(gamma, all_KL_A_yes, yerr=sem_KL_A_yes, linewidth=2, label='Seen')\n",
    "plt.errorbar(gamma, all_KL_A_no, yerr=sem_KL_A_no, linewidth=2, label='Unseen')\n",
    "plt.legend(frameon=False)\n",
    "plt.xlabel('SOA (precision)')\n",
    "plt.ylabel('K-L divergence, awareness state')\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.box(False)\n",
    "\n",
    "# Adjust layout and display the figure\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61df22a0-185b-496f-a2b0-7f2339f1b93c",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Discussion point\n",
    "\n",
    "Can you think of experiments that could distinguish between the HOSS and GWS accounts of ignition?\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "W2D5_Tutorial1",
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
