{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e3d2b26-a059-4683-8bfd-2499a50eb346",
   "metadata": {
    "execution": {}
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/neuromatch/NeuroAI_Course/blob/main/tutorials/W1D3_ComparingArtificialAndBiologicalNetworks/student/W1D3_Tutorial5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> &nbsp; <a href=\"https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/neuromatch/NeuroAI_Course/main/tutorials/W1D3_ComparingArtificialAndBiologicalNetworks/student/W1D3_Tutorial5.ipynb\" target=\"_parent\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open in Kaggle\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d5410f-0745-4a99-a40f-cd591c3b4d45",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Bonus (Tutorial 5): Dynamical Similarity Analysis (DSA)\n",
    "\n",
    "**Week 1, Day 3: Comparing Artificial And Biological Networks**\n",
    "\n",
    "**By Neuromatch Academy**\n",
    "\n",
    "__Content creators:__ Mitchell Ostrow\n",
    "\n",
    "__Content reviewers:__ Xaq Pitkow, Hlib Solodzhuk\n",
    "\n",
    "__Production editors:__ Konstantine Tsafatinos, Ella Batty, Spiros Chavlis, Samuele Bolotta, Hlib Solodzhuk, Patrick Mineault\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3777bf-2134-47c9-9768-aec75a57a6c7",
   "metadata": {
    "execution": {}
   },
   "source": [
    "This short notebook expands the toolset of network comparison by taking a look at another important dimension for analysis - time. In particular, it would be beneficial to understand how the systems evolve over time and whether their dynamics are similar. The presented materials are the most similar to the ones introduced in [Tutorial 2](https://neuroai.neuromatch.io/tutorials/W1D3_ComparingArtificialAndBiologicalNetworks/student/W1D3_Tutorial2.html) for this day, and one of the projects on [Comparing Networks](https://neuroai.neuromatch.io/projects/project-notebooks/ComparingNetworks.html) is exactly about DSA.\n",
    "\n",
    "We begin by looking at the representational geometry of recurrent neural networks, providing an extension to the analyses we saw in Tutorial 2. We then look closer at the details of DSA and how the analysis of model dynamics can be approached from another direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08f673e-3657-47aa-aeb0-08c55904bd6d",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Install and import feedback gadget\n",
    "\n",
    "!pip install vibecheck --quiet\n",
    "\n",
    "from vibecheck import DatatopsContentReviewContainer\n",
    "def content_review(notebook_section: str):\n",
    "    return DatatopsContentReviewContainer(\n",
    "        \"\",  # No text prompt\n",
    "        notebook_section,\n",
    "        {\n",
    "            \"url\": \"https://pmyvdlilci.execute-api.us-east-1.amazonaws.com/klab\",\n",
    "            \"name\": \"neuromatch_neuroai\",\n",
    "            \"user_key\": \"wb2cxze8\",\n",
    "        },\n",
    "    ).render()\n",
    "\n",
    "\n",
    "feedback_prefix = \"W1D3_Bonus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28a92e7-e76c-48de-b574-15a1272717cf",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Bonus material slides\n",
    "\n",
    "from IPython.display import IFrame\n",
    "from ipywidgets import widgets\n",
    "out = widgets.Output()\n",
    "\n",
    "link_id = \"8fx23\"\n",
    "\n",
    "with out:\n",
    "    print(f\"If you want to download the slides: https://osf.io/download/{link_id}/\")\n",
    "    display(IFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/{link_id}/?direct%26mode=render%26action=download%26mode=render\", width=730, height=410))\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71164d2d",
   "metadata": {},
   "source": [
    "---\n",
    "# Representational Geometry of Recurrent Models\n",
    "\n",
    "Transformations of representations can occur across space and time, e.g., layers of a neural network and steps of recurrent computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e8c561",
   "metadata": {},
   "source": [
    "Just as the layers in a feedforward DNN can change the representational geometry to perform a task, steps in a recurrent network can reuse the same layer to reach the same computational depth.\n",
    "\n",
    "In this section, we look at a very simple recurrent network with only 2650 trainable parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53063596",
   "metadata": {},
   "source": [
    "Here is a diagram of this network:\n",
    "\n",
    "![Recurrent convolutional neural network](https://github.com/neuromatch/NeuroAI_Course/blob/main/tutorials/W1D3_ComparingArtificialAndBiologicalNetworks/static/rcnn_tutorial.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074f2533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Helper functions\n",
    "\n",
    "# TODO: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c45b6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Grab a recurrent model\n",
    "\n",
    "args = build_args()\n",
    "train_loader, test_loader = fetch_dataloaders(args)\n",
    "path = \"recurrent_model.pth\"\n",
    "model_recurrent = torch.load(path, map_location=args.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a108f2",
   "metadata": {},
   "source": [
    "<br>We can first look at the computational steps in this network. As we see below, the `conv2` operation is repeated for 5 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e9e134",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nodes, _ = get_graph_node_names(model_recurrent)\n",
    "print('The computational steps in the network are: \\n', train_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a7b1b3",
   "metadata": {},
   "source": [
    "Plotting the RDMs after each application of the `conv2` operation shows the same progressive emergence of the blockwise structure around the diagonal, mediating the correct classification in this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65047a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = sample_images(test_loader, n=20)\n",
    "return_layers = ['conv2', 'conv2_1', 'conv2_2', 'conv2_3', 'conv2_4']\n",
    "model_features = extract_features(model_recurrent, imgs.to(device), return_layers)\n",
    "\n",
    "rdms, rdms_dict = calc_rdms(model_features)\n",
    "plot_rdms(rdms_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a55054",
   "metadata": {},
   "source": [
    "We can also look at how the different dimensionality reduction techniques capture the dynamics of changing geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf787f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_layers = ['conv2', 'conv2_1', 'conv2_2', 'conv2_3', 'conv2_4']\n",
    "\n",
    "imgs, labels = sample_images(test_loader, n=50) #grab 500 samples from the test set\n",
    "model_features = extract_features(model_recurrent, imgs.to(device), return_layers)\n",
    "\n",
    "plot_dim_reduction(model_features, labels, transformer_funcs =['PCA', 'MDS', 't-SNE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f8af84",
   "metadata": {},
   "source": [
    "## Representational geometry paths for recurrent models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a5cb76",
   "metadata": {},
   "source": [
    "We can look at the model's recurrent computational steps as a path in the representational geometry space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eab11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = sample_images(test_loader, n=50) #grab 500 samples from the test set\n",
    "model_features_recurrent = extract_features(model_recurrent, imgs.to(device), return_layers='all')\n",
    "\n",
    "#rdms, rdms_dict = calc_rdms(model_features)\n",
    "features = {'recurrent model': model_features_recurrent}\n",
    "model_colors = {'recurrent model': 'y'}\n",
    "\n",
    "rep_path(features, model_colors, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7c7151",
   "metadata": {},
   "source": [
    "We can also look at the paths taken by the feedforward and the recurrent models and compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4569de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = sample_images(test_loader, n=50) #grab 500 samples from the test set\n",
    "model_features = extract_features(model, imgs.to(device), return_layers='all')\n",
    "model_features_recurrent = extract_features(model_recurrent, imgs.to(device), return_layers='all')\n",
    "\n",
    "features = {'feedforward model': model_features, 'recurrent model': model_features_recurrent}\n",
    "model_colors = {'feedforward model': 'b', 'recurrent model': 'y'}\n",
    "\n",
    "rep_path(features, model_colors, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc4968b",
   "metadata": {},
   "source": [
    "What we can see here is that different models can take very different paths in the space of representational geometries to map images to labels. This is because there exist many different functional mappings to do a classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4e1173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_recurrent_models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f7067a",
   "metadata": {},
   "source": [
    "We are now going to introduce an exciting new method to compare dynamical systems, Dynamic Similarity Analysis! Please watch the video below and follow through the example code in the following subsection to reproduce some of the figures you will see in the explanatory video. Enjoy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d6178f-ddf5-41ae-b676-15e452dc8b78",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 1: Dynamical Similarity Analysis\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', 'FHikIsQFQvM'), ('Bilibili', 'BV1qm421g7hV')]\n",
    "tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ce83bc-7e86-44d3-a40a-4ad46fd5a6df",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_DSA_video\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "W1D3_Tutorial5",
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
