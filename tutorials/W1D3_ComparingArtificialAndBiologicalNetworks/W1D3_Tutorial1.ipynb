{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nxk2AYDdBdjj"
   },
   "source": [
    "# Tutorial 1: Generalization and representational geometry\n",
    "\n",
    "**Week 1, Day 3: Comparing artificial and biological neural networks**\n",
    "\n",
    "**By Neuromatch Academy**\n",
    "\n",
    "__Content creators:__ JohnMark Taylor & Zhuofan Josh Ying\n",
    "\n",
    "__Content reviewers:__ Names & Surnames\n",
    "\n",
    "__Production editors:__ Names & Surnames\n",
    "\n",
    "<br>\n",
    "\n",
    "Acknowledgments: [ACKNOWLEDGMENT_INFORMATION]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7uRs5JMJZE0I"
   },
   "source": [
    "# Tutorial 1: Generalization and representational geometry\n",
    "\n",
    "Estimated timing of tutorial: 30 minutes\n",
    "\n",
    "Welcome to Tutorial 1 on Generalization and Representational Geometry. This tutorial aims to bridge the gap between theoretical concepts and practical applications in machine learning, focusing on the relationship between generalization and condition similarities based on linear models. By the end of this tutorial, you will:\n",
    "\n",
    "- Understand the connection between generalization and condition similarities in the linear case, including a nod towards the kernel trick discussed in lectures.\n",
    "- Understand how the analytic solution for linear regression can be seen as a weighted sum of training values, weighted by the test stimuli’s similarity to the training data.\n",
    "\n",
    "Exercises:\n",
    "1.   Question on comparing RDMs\n",
    "2.   Question on the relationship between RDMs and model performances\n",
    "3.   Interactive exercise on how similarity structure affects predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ofP481cIBdjk"
   },
   "outputs": [],
   "source": [
    "# @title Tutorial slides\n",
    "# @markdown These are the slides for the videos in all tutorials today\n",
    "\n",
    "# from IPython.display import IFrame\n",
    "#link_id = \"<YOUR_LINK_ID_HERE>\"\n",
    "# print(f\"If you want to download the slides: https://osf.io/download/{link_id}/\")\n",
    "#IFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{link_id}/?direct%26mode=render\", width=854, height=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HhaeqoOgBdjk"
   },
   "source": [
    "---\n",
    "# Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kDm331nuBdjk",
    "outputId": "85f94f7b-d1ec-42de-b8b8-d73d09582cf7"
   },
   "outputs": [],
   "source": [
    "# @title Install dependencies\n",
    "#! pip install ipympl ipywidgets mpl_interactions[\"jupyter\"] rsatoolbox torchlens\n",
    "#! pip install graphviz\n",
    "\n",
    "# To install jupyter-matplotlib (ipympl) via pip\n",
    "!pip install ipympl ipywidgets matplotlib numpy scikit-learn torch torchvision rsatoolbox scipy\n",
    "\n",
    "\n",
    "# To install jupyter-matplotlib via conda (comment out if you are not using conda)\n",
    "# !conda install -c conda-forge ipympl\n",
    "\n",
    "# To install the JupyterLab extension for ipywidgets\n",
    "!jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    "\n",
    "# To install the JupyterLab extension for jupyter-matplotlib\n",
    "!jupyter labextension install jupyter-matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3pzsryerGNS-"
   },
   "outputs": [],
   "source": [
    "# @title Import dependencies\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import AnnotationBbox, OffsetImage\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "import torchlens as tl\n",
    "import warnings\n",
    "\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from collections import OrderedDict\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "import numpy as np\n",
    "\n",
    "import torchlens as tl\n",
    "\n",
    "import rsatoolbox\n",
    "from rsatoolbox.data import Dataset\n",
    "from rsatoolbox.rdm.calc import calc_rdm\n",
    "from scipy import stats\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2jxiJqT8Bdjl"
   },
   "outputs": [],
   "source": [
    "# @title Figure settings\n",
    "# @markdown\n",
    "\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' # perfrom high definition rendering for images and plots\n",
    "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/nma.mplstyle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h4Hr4CBuBdjl"
   },
   "source": [
    "## Section 1: MNIST DNN Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @markdown\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "\n",
    "video_ids = [('Youtube', 'AjzqdrOrfgg'), ('Bilibili', '')]\n",
    "tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3pQ-S_vOZC1q"
   },
   "source": [
    "\n",
    "In this activity, you will use linear regression on representations of two neural networks trained on MNIST, one with adversarial training and one without. The objective is to observe:\n",
    "\n",
    "- How predictions for clean images of numbers are similar for a deep layer and closely align with the category structure.\n",
    "- The similarity matrix reflects a category structure and how matrices from the two networks compare.\n",
    "- The significant differences in predictions and similarity matrices when applying adversarial examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gky7NG7aZyEK"
   },
   "source": [
    "### Understanding the MNIST DNNs\n",
    "\n",
    "We start by defining and training two models on the MNIST dataset: a standard model and an adversarially robust model. The training process includes a step where adversarial examples are generated and used to train the robust model, providing an insight into how adversarial training influences model behavior.\n",
    "\n",
    "**Defining the MNIST Model**\n",
    "\n",
    "First, we define a neural network model that will be trained on the MNIST dataset. The MNIST dataset consists of 28x28 pixel images of handwritten digits (0 through 9). Our model, based on the LeNet architecture, includes two convolutional layers followed by dropout layers to reduce overfitting, and finally, fully connected layers to perform classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5zwDKp_yIPzY"
   },
   "outputs": [],
   "source": [
    "# modified and reorganized from https://github.com/pytorch/examples/blob/main/mnist/main.py\n",
    "\n",
    "#lenet model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "def train_one_epoch(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            if args.dry_run:\n",
    "                break\n",
    "\n",
    "def test(model, device, test_loader, return_features=False):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "def build_args():\n",
    "    # Training settings\n",
    "    parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "    parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                        help='input batch size for training (default: 64)')\n",
    "    parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                        help='input batch size for testing (default: 1000)')\n",
    "    parser.add_argument('--epochs', type=int, default=2, metavar='N',\n",
    "                        help='number of epochs to train (default: 14)')\n",
    "    parser.add_argument('--lr', type=float, default=1.0, metavar='LR',\n",
    "                        help='learning rate (default: 1.0)')\n",
    "    parser.add_argument('--gamma', type=float, default=0.7, metavar='M',\n",
    "                        help='Learning rate step gamma (default: 0.7)')\n",
    "    parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                        help='disables CUDA training')\n",
    "    parser.add_argument('--no-mps', action='store_true', default=False,\n",
    "                        help='disables macOS GPU training')\n",
    "    parser.add_argument('--dry-run', action='store_true', default=False,\n",
    "                        help='quickly check a single pass')\n",
    "    parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                        help='random seed (default: 1)')\n",
    "    parser.add_argument('--log-interval', type=int, default=50, metavar='N',\n",
    "                        help='how many batches to wait before logging training status')\n",
    "    parser.add_argument('--save-model', action='store_true', default=False,\n",
    "                        help='For Saving the current Model')\n",
    "    args = parser.parse_args('')\n",
    "\n",
    "    use_cuda = torch.cuda.is_available() #not args.no_cuda and\n",
    "    use_mps = not args.no_mps and torch.backends.mps.is_available()\n",
    "\n",
    "    if use_cuda:\n",
    "        device = torch.device(\"cuda\")\n",
    "    elif use_mps:\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    args.use_cuda = use_cuda\n",
    "    args.device = device\n",
    "    return args\n",
    "\n",
    "def fetch_dataloaders(args):\n",
    "\n",
    "    train_kwargs = {'batch_size': args.batch_size}\n",
    "    test_kwargs = {'batch_size': args.test_batch_size}\n",
    "    if args.use_cuda:\n",
    "        cuda_kwargs = {'num_workers': 1,\n",
    "                       'pin_memory': True,\n",
    "                       'shuffle': True}\n",
    "        train_kwargs.update(cuda_kwargs)\n",
    "        test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "    dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transform)\n",
    "    dataset2 = datasets.MNIST('../data', train=False,\n",
    "                       transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "def train_model(args, model, optimizer):\n",
    "    scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train_one_epoch(args, model, args.device, train_loader, optimizer, epoch)\n",
    "        test(model, args.device, test_loader)\n",
    "        scheduler.step()\n",
    "\n",
    "    if args.save_model:\n",
    "        torch.save(model.state_dict(), \"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KHrpUtWCbfBx"
   },
   "source": [
    "**Training the Standard Model**\n",
    "\n",
    "Once our model is defined, we proceed to train it on the MNIST dataset. Training involves feeding batches of images and their corresponding labels to the model, adjusting the model's weights based on the loss computed from its predictions and the actual labels. This process is iterated over multiple epochs to improve the model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WYMMRp97IXqV",
    "outputId": "837522c8-b799-40bd-a588-b4df8bc0dcc6"
   },
   "outputs": [],
   "source": [
    "# build and train the model\n",
    "\n",
    "args = build_args()\n",
    "torch.manual_seed(args.seed)\n",
    "train_loader, test_loader = fetch_dataloaders(args)\n",
    "\n",
    "# build_model\n",
    "model = Net().to(args.device)\n",
    "\n",
    "print(model)\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n",
    "\n",
    "# train model\n",
    "train_model(args, model, optimizer) #train the model for 2 epochs ~ %99 accuracy ~ 30 sec colab gpu\n",
    "\n",
    "# alternative, grab a pretrained model from some place\n",
    "# pretrained_model = \"{link}/lenet_mnist_model.pth\"\n",
    "# model.load_state_dict(torch.load(pretrained_model, map_location=args.device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FofBUBlZbmAt"
   },
   "source": [
    "**Generating Adversarial Examples**\n",
    "\n",
    "Adversarial examples are inputs to machine learning models that an attacker has intentionally designed to cause the model to make a mistake. They are often **indistinguishable** from real data by humans but result in incorrect predictions by the model. Generating these examples and using them in training can improve a model's robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "id": "T6Mtykh8JjJU",
    "outputId": "f3571d1e-9a82-4b6d-b0b4-f9efce266ee0"
   },
   "outputs": [],
   "source": [
    "# grab 5 test images from each category and visualize them\n",
    "\n",
    "def sample_images(data_loader, n=5, plot=False):\n",
    "\n",
    "    imgs, labels = next(iter(data_loader))\n",
    "\n",
    "    imgs_o = []\n",
    "    targets = []\n",
    "    for value in range(10):\n",
    "        imgs_o.append(imgs[np.where(labels == value)][0:n])\n",
    "        targets.append([value]*5)\n",
    "\n",
    "    imgs = torch.cat(imgs_o, dim=0)\n",
    "    targets = torch.tensor(targets).flatten()\n",
    "\n",
    "    if plot:\n",
    "        plt.imshow(torch.moveaxis(make_grid(imgs, nrow=5, padding=0, normalize=False, pad_value=0), 0,-1))\n",
    "        plt.axis('off')\n",
    "\n",
    "    return imgs, targets\n",
    "\n",
    "imgs, targets = sample_images(test_loader, n=5, plot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IKYmgD10Iai5"
   },
   "outputs": [],
   "source": [
    "# modified from https://pytorch.org/tutorials/beginner/fgsm_tutorial.html\n",
    "\n",
    "# generating adversarial images using FGSM attack\n",
    "\n",
    "# FGSM attack code\n",
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    # Collect the element-wise sign of the data gradient\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    # Create the perturbed image by adjusting each pixel of the input image\n",
    "    perturbed_image = image + epsilon*sign_data_grad\n",
    "    # Adding clipping to maintain [0,1] range\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    # Return the perturbed image\n",
    "    return perturbed_image\n",
    "\n",
    "# restores the tensors to their original scale\n",
    "def denorm(batch, mean=[0.1307], std=[0.3081]):\n",
    "    \"\"\"\n",
    "    Convert a batch of tensors to their original scale.\n",
    "\n",
    "    Args:\n",
    "        batch (torch.Tensor): Batch of normalized tensors.\n",
    "        mean (torch.Tensor or list): Mean used for normalization.\n",
    "        std (torch.Tensor or list): Standard deviation used for normalization.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: batch of tensors without normalization applied to them.\n",
    "    \"\"\"\n",
    "    if isinstance(mean, list):\n",
    "        mean = torch.tensor(mean).to(batch.device)\n",
    "    if isinstance(std, list):\n",
    "        std = torch.tensor(std).to(batch.device)\n",
    "\n",
    "    return batch * std.view(1, -1, 1, 1) + mean.view(1, -1, 1, 1)\n",
    "\n",
    "def generate_adversarial(model, imgs, targets, epsilon):\n",
    "\n",
    "    # Accuracy counter\n",
    "    correct = 0\n",
    "    adv_imgs = []\n",
    "\n",
    "    # Loop over all examples in test set\n",
    "    for img, target in zip(imgs, targets):\n",
    "\n",
    "        img = img.unsqueeze(0)\n",
    "        target = target.unsqueeze(0)\n",
    "        # Set requires_grad attribute of tensor. Important for Attack\n",
    "        img.requires_grad = True\n",
    "\n",
    "        # Forward pass the data through the model\n",
    "        output = model(img)\n",
    "        init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = F.nll_loss(output, target)\n",
    "\n",
    "        # Zero all existing gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Calculate gradients of model in backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Collect ``datagrad``\n",
    "        data_grad = img.grad.data\n",
    "\n",
    "        # Restore the data to its original scale\n",
    "        data_denorm = denorm(img)\n",
    "\n",
    "        # Call FGSM Attack\n",
    "        perturbed_data = fgsm_attack(data_denorm, epsilon, data_grad)\n",
    "\n",
    "        # Reapply normalization\n",
    "        perturbed_data_normalized = transforms.Normalize((0.1307,), (0.3081,))(perturbed_data)\n",
    "\n",
    "        adv_imgs.append(perturbed_data_normalized.detach())\n",
    "\n",
    "    return torch.cat(adv_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 628
    },
    "id": "7QZPWOruQAjb",
    "outputId": "8a92223e-b2dd-4e6f-ff2b-8ed5df129db0"
   },
   "outputs": [],
   "source": [
    "# Generate adversarial images for the standard model\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "eps = 0.2\n",
    "imgs =imgs.to(args.device)\n",
    "targets = targets.to(args.device)\n",
    "\n",
    "adv_imgs = generate_adversarial(model, imgs, targets, eps)\n",
    "adv_imgs.shape\n",
    "\n",
    "plt.imshow(torch.moveaxis(make_grid(adv_imgs.cpu(), nrow=5, padding=0, normalize=False, pad_value=0), 0,-1))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m6uWQRwscjXJ"
   },
   "source": [
    "**Training the Adversarially Robust Model**\n",
    "\n",
    "With adversarial examples at hand, we now train a model designed to be robust against such examples. The idea is to include adversarial examples in the training process, enabling the model to learn from and defend against them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3bBen41vJp38"
   },
   "outputs": [],
   "source": [
    "# Train the model to be robust to adversarial attack\n",
    "\n",
    "def train_one_epoch_adversarial(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # train the model on adversarial images\n",
    "        epsilon = 0.2\n",
    "        data = generate_adversarial(model, data, target, epsilon)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            if args.dry_run:\n",
    "                break\n",
    "\n",
    "def train_model_adversarial(args, model, optimizer):\n",
    "    scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train_one_epoch_adversarial(args, model, args.device, train_loader, optimizer, epoch)\n",
    "        test(model, args.device, test_loader)\n",
    "        scheduler.step()\n",
    "\n",
    "    if args.save_model:\n",
    "        torch.save(model.state_dict(), \"robust_mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2LMd4sB7Jup_",
    "outputId": "fe1a157d-0fd4-45a1-8ace-6267dfa4cfc1"
   },
   "outputs": [],
   "source": [
    "# train adversirally robust model\n",
    "import time\n",
    "start_time = time.time()\n",
    "model_robust = Net().to(args.device)\n",
    "print(model)\n",
    "optimizer = optim.Adadelta(model_robust.parameters(), lr=args.lr)\n",
    "\n",
    "train_model_adversarial(args, model_robust, optimizer) #train the model for 2 epochs ~ %98 accuracy ~ 2 minutes on cpu\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the total time taken and print it\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Training completed in {elapsed_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 628
    },
    "id": "o2Ig9gAjQGfZ",
    "outputId": "2aa77be5-3bca-4eca-ea10-9a84a7750afd"
   },
   "outputs": [],
   "source": [
    "# Generate adversarial images for the adversarially trained model\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "eps = 0.2\n",
    "imgs =imgs.to(args.device)\n",
    "targets = targets.to(args.device)\n",
    "\n",
    "adv_imgs_advmodel = generate_adversarial(model_robust, imgs, targets, eps)\n",
    "adv_imgs_advmodel.shape\n",
    "\n",
    "plt.imshow(torch.moveaxis(make_grid(adv_imgs_advmodel.cpu(), nrow=5, padding=0, normalize=False, pad_value=0), 0,-1))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYj4aU2WcNtX"
   },
   "source": [
    "**Evaluating Model Robustness**\n",
    "\n",
    "After training, it's essential to evaluate how well the models perform, particularly in the presence of adversarial examples. We do this by testing the models on both standard and adversarial images and comparing their accuracies.\n",
    "\n",
    "Note that these adversarially generated images are indistinguishable from the real ones, but they decrease standard model performances dramatically (as shown below). Adversarially trained model is robust to this kind of attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rEfYm9F6Jwps",
    "outputId": "7ed38708-3639-4c40-e158-bb43db2172c0"
   },
   "outputs": [],
   "source": [
    "def test_adversarial(model, imgs, targets, plot=False):\n",
    "\n",
    "    # Accuracy counter\n",
    "    correct = 0\n",
    "    adv_examples = []\n",
    "\n",
    "    output = model(imgs)\n",
    "\n",
    "    pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "    correct += pred.eq(targets.view_as(pred)).sum().item()\n",
    "\n",
    "    final_acc = correct/float(len(imgs))\n",
    "    print(f\"adversarial test accuracy = {correct} / {len(imgs)} = {final_acc}\")\n",
    "\n",
    "    if plot:\n",
    "        cnt = 0\n",
    "        epsilons = [0.2]\n",
    "        plt.figure(figsize=(8,10))\n",
    "        for i in range(10):\n",
    "            for j in range(5):\n",
    "\n",
    "                plt.subplot(10,5,cnt+1)\n",
    "                plt.xticks([], [])\n",
    "                plt.yticks([], [])\n",
    "                # if j == 0:\n",
    "                #     plt.ylabel(f\"Eps: {epsilons[i]}\", fontsize=14)\n",
    "                orig,adv,ex = targets[cnt].cpu().numpy(), pred[cnt].cpu().numpy(), imgs[cnt].moveaxis(0,-1).cpu()\n",
    "                if orig == adv:\n",
    "                    plt.title(f\"{orig} -> {adv}\")\n",
    "                else:\n",
    "                    plt.title(f\"{orig} -> {adv}\", fontweight=\"bold\")\n",
    "\n",
    "                plt.imshow(ex, cmap=\"gray\")\n",
    "                cnt += 1\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print(\"For standard model trained without adversarial examples:\")\n",
    "test_adversarial(model, adv_imgs, targets, plot=False)\n",
    "# test_adversarial(model_robust, adv_imgs, targets, plot=False)\n",
    "print(\"For adversrially trained model:\")\n",
    "test_adversarial(model_robust, adv_imgs_advmodel, targets, plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILEBOiMZdZci"
   },
   "source": [
    "## Extracting Model Features and Analyzing Representations\n",
    "\n",
    "With the models trained and adversarial images generated, we proceed to extract features from different layers of our networks using [torchlens](https://github.com/johnmarktaylor91/torchlens), a package for extracting neural network activations and visualizing their computational graph.  This step is crucial for understanding how data representations differ across layers and models, especially under adversarial conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "76CerEeIKm-4",
    "outputId": "e67360e9-c562-48f8-9b00-769bb017dd98"
   },
   "outputs": [],
   "source": [
    "# extract model features with torchlens\n",
    "\n",
    "def extract_features(model, imgs, return_layers, plot ='none'):\n",
    "\n",
    "    model_history = tl.log_forward_pass(model, imgs, layers_to_save='all', vis_opt=plot)\n",
    "    model_features = {}\n",
    "    for layer in return_layers:\n",
    "        model_features[layer] = model_history[layer].tensor_contents.flatten(1)\n",
    "\n",
    "    return model_features\n",
    "\n",
    "\n",
    "return_layers = ['input_1', 'conv1', 'conv2', 'fc1', 'fc2']\n",
    "features_model_imgs = extract_features(model, imgs, return_layers, plot = 'rolled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VW-d14KMNLVm"
   },
   "outputs": [],
   "source": [
    "features_model_advimgs = extract_features(model, adv_imgs, return_layers)\n",
    "features_advmodel_imgs = extract_features(model_robust, imgs, return_layers)\n",
    "features_advmodel_advimgs = extract_features(model_robust, adv_imgs_advmodel, return_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rneYCinNa3Kg"
   },
   "source": [
    "### Creating and Comparing Representation Similarity Matrices\n",
    "Using the RSA toolbox, you will create representation similarity matrices (RSMs) for each model and condition (standard and adversarial). These matrices provide a visual representation of how stimuli are represented within the network, offering insights into the models' generalization capabilities and the effects of adversarial training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zV1PkRXYdJfe"
   },
   "outputs": [],
   "source": [
    "# create the representationl similarity matrices using RSA toolbox\n",
    "\n",
    "def calc_rdms(model_features, method='correlation'):\n",
    "    ds_list = []\n",
    "    for l in range(len(model_features)):\n",
    "\n",
    "        layer = list(model_features.keys())[l]\n",
    "        feats = model_features[layer]\n",
    "\n",
    "        if type(feats) is list:\n",
    "            feats = feats[-1]\n",
    "\n",
    "        if args.use_cuda:\n",
    "            feats = feats.cpu()\n",
    "\n",
    "        if len(feats.shape)>2:\n",
    "            feats = feats.flatten(1)\n",
    "\n",
    "        feats = feats.detach().numpy()\n",
    "        # feats = stats.zscore(feats)\n",
    "\n",
    "        ds = Dataset(feats, descriptors=dict(layer=layer))\n",
    "        ds_list.append(ds)\n",
    "\n",
    "    rdms = calc_rdm(ds_list, method=method)\n",
    "\n",
    "    rdms_dict = {list(model_features.keys())[i]: rdms.get_matrices()[i] for i in range(len(model_features))}\n",
    "\n",
    "    return rdms, rdms_dict\n",
    "\n",
    "def plot_maps(model_features):\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 4))\n",
    "    # and we add one plot per reference point\n",
    "    gs = fig.add_gridspec(1, len(model_features))\n",
    "    fig.subplots_adjust(wspace=0.2, hspace=0.2)\n",
    "\n",
    "    for l in range(len(model_features)):\n",
    "\n",
    "        layer = list(model_features.keys())[l]\n",
    "        map_ = np.squeeze(model_features[layer])\n",
    "\n",
    "        if len(map_.shape) < 2:\n",
    "            map_ = map_.reshape( (int(np.sqrt(map_.shape[0])), int(np.sqrt(map_.shape[0]))) )\n",
    "\n",
    "        map_ = map_ / np.max(map_)\n",
    "\n",
    "        ax = plt.subplot(gs[0,l])\n",
    "        ax_ = ax.imshow(map_, cmap='magma_r')\n",
    "        ax.set_title(f'{layer}')\n",
    "\n",
    "    fig.subplots_adjust(right=0.9)\n",
    "    cbar_ax = fig.add_axes([1, 0.15, 0.01, 0.7])\n",
    "    fig.colorbar(ax_, cax=cbar_ax)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "J5VNs46FNdyI",
    "outputId": "ad3f2410-7af7-4103-ac1a-c64c756992c2"
   },
   "outputs": [],
   "source": [
    "# for standard model + standard images\n",
    "rdms, rdms_dict = calc_rdms(features_model_imgs)\n",
    "plot_maps(rdms_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "fgW_s8qENhZj",
    "outputId": "243417bc-11b9-457b-e580-2eebfe44e74b"
   },
   "outputs": [],
   "source": [
    "# for adversarially trained model + standard images\n",
    "rdms, rdms_dict = calc_rdms(features_advmodel_imgs)\n",
    "plot_maps(rdms_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ykzzk1Ej_yrb"
   },
   "source": [
    "**Question**: For clean images, how do the RDMs change across the model layers, and why?\n",
    "\n",
    "\n",
    "**Answer**: For clean images representing the same digit, their representations in the deeper layers of the network are remarkably similar and align well with the inherent category structure, manifesting as a distinct block effect. In contrast, this block effect is less pronounced in the earlier layers of the network. The initial layers focus more on capturing general and granular visual features. This progression from generic to more refined feature extraction across layers underscores the hierarchical nature of learning in deep neural networks, where complex representations are built upon the simpler ones extracted at earlier stages.\n",
    "\n",
    "RDMs of the standard model and the adversarially trained model are very similar for clean images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "2lpXfhjgN4Ps",
    "outputId": "e8516850-5d40-4cef-fa02-f957902b4ff9"
   },
   "outputs": [],
   "source": [
    "# for standard model + adversarial images\n",
    "rdms, rdms_dict = calc_rdms(features_model_advimgs)\n",
    "plot_maps(rdms_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "Afc4ejiTN9FN",
    "outputId": "fed5131c-df5a-4017-cc5d-e42f0fcb1076"
   },
   "outputs": [],
   "source": [
    "# for adversarially trained model + adversarial images\n",
    "rdms, rdms_dict = calc_rdms(features_advmodel_advimgs)\n",
    "plot_maps(rdms_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JmKCVJqFdNs1"
   },
   "source": [
    "**Question**: For adversarial images, how do the RDMs change when comparing representations from the standard model to the adversarially trained model?\n",
    "\n",
    "\n",
    "**Answer**: Note for adversarial images, the representation similarity of the standard model within each category (the block effect) is notably disrupted in the deeper layers.\n",
    "\n",
    "Conversely, for the adversarially trained model, despite the introduction of adversarial examples, the representation similarity matrix for preserves its block-like structure across categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-WsHbSuBkb3"
   },
   "source": [
    "**Question**: How does the RDMs relate to the performances of the standard and the adversarially trained models on clean and adversarial images?\n",
    "\n",
    "\n",
    "**Answer**: RDMs provide a visual and quantitative way to analyze how a neural network processes and represents different stimuli. By comparing the similarity of responses within the network across various inputs, the RSM can reveal significant insights into the network's internal representations and, consequently, its ability to generalize.\n",
    "\n",
    "Both the standard and the adversarially trained models show clear, distinct blocks in the RSM when inputs from the same category are represented similarly (high intra-class similarity) and inputs from different categories are distinct (low inter-class similarity). This differentiation is crucial for the model to achieve high accuracies on unseen test data from the same distribution.\n",
    "\n",
    "However, for adversarial images, the block effect of the standard model is notably disrupted. This disruption correlates with a diminished test accuracy when the model is evaluated on adversarial images, highlighting the vulnerability of the standard model to adversarial perturbations.\n",
    "For adversarially trained model, the structural preservation of its RDMs indicates that the model's internal representations of the stimuli remain robust against adversarial manipulation, allowing it to maintain high accuracy on adversarial images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ew76YH_UWi2P"
   },
   "source": [
    "# Section 2: Interactive Exploration with Widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aRdqJukVQHQf"
   },
   "source": [
    "The manner in which a readout function generalizes to new inputs depends closely on the similarity of the new inputs to training stimuli-—in other words, the more similar a test stimulus is to a training stimulus, the more similar the output of the readout will be. But what do we mean by \"similar\"? The relevant way to measure \"similarity\" in each case will depend on the readout function in question. In the case of linear regression, the relevant similarity metric is the kernel (dot product) similarity of the inputs. To see this, you can inspect the matrix form of the least squares solution for regression below:\n",
    "\n",
    "$$y_{pred} = X_{pred} \\left( X_{train}^T X_{train} \\right)^{-1} X_{train}^T y_{train}$$\n",
    "\n",
    "Note that the predicted outputs for the test stimuli are a weighted combination of the outputs for training stimuli, where the weights depend on the inner products of the training and test stimuli. Thus, the more similar a training stimulus is to a given test stimulus, the more strongly the output for that training stimulus will contribute to the output for that test stimulus. To give another example, in the case of a radial basis function readout, the relevant notion of similarity would be the distance between the inputs.\n",
    "\n",
    "In this interactive exercise, you will explore how the similarity between training and test stimuli predicts how the network generalizes. The task is to use linear regression on activations from our MNIST network from above in order to predict the \"legibility\" of images of different digit images. You play the role of the human rater, and will rate the legibility of the training images from 1-10 using the provided sliders (on the left). Based on these provided ratings, a ridge regression is trained to predict those ratings using the activations from a given layer of the neural network, and the resulting regression model is then applied to new images, yielding predicted legibility ratings for these images (red numbers at the bottom). The color-coded matrix shows the dot product similarity between activations for the training and test images.\n",
    "\n",
    "1) Using the matrix, find a training and test image that are highly similar, and play around with the rating of the training image. How much does the predicted legibility rating for the test image change?\n",
    "\n",
    "2) Now find a highly dissimilar pair, and play with the rating. How much does the predicted legibility of the test image change?\n",
    "\n",
    "3) Using the dropdown menu, you can choose a different layer of the neural network to predict the legibiligy of the images, reflecting different stages of processing in the network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9R-ygMAaBdjn",
    "outputId": "38af7ffc-32a5-4941-8b1c-5a407c23b10a"
   },
   "outputs": [],
   "source": [
    "#from google.colab import output\n",
    "#output.enable_custom_widget_manager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 989,
     "referenced_widgets": [
      "87e14015ac7f4e0380500f81a7bb5b25",
      "8a4272a9c1b749028adff1fb098a447f",
      "114d68b97dc245a5a5dd346eaaa5614a",
      "f6178852891a4a01828f023c60da2c55",
      "b10a79ec0c7249f596ae34896d6bcc51",
      "be4cffe5f34244edb64d03cbf0a36b70",
      "987f2d8fedc745578cd354f3de941752",
      "d1ce01e80a3d4511bc7dd0bdedece3f1",
      "c2dbab3dabd5436ab14db65399b95fc8",
      "065274d1c51747e29c4e149975f4d946",
      "44937249476243e4ad401ccd7b40814b",
      "ac1c39d6e7ce4f18b32a2e4a591e9c0d",
      "86b08ea160514defbc059f815adeec53",
      "225a3a182aa94869a713119eca6696c7",
      "cb0c793bad144905bd9ae9378cbe7f55",
      "0e72e094a071416090c339586f4e5a4a",
      "0a4e21333d524e42a1e50589f75a0317",
      "a7d9002c9ebf49d5a4004e37ba730789",
      "608cdffaefaa437087fd9de5c59ec3b4",
      "7af64dfb6fbc462282f26f9b00c2a93a",
      "4a6bca4632ca4220bdb4ab8cf10c8cc2",
      "c64b2401ac1940a79cbcdbe1b4523014",
      "7a95657592544c3f9196cd779bb67fb5",
      "d94767b8626342c99e060f9ed6aca5ba",
      "afe2ee92fe3a42d197f71a59d3d5ac27",
      "5a9c82737bae437d9133805ddec8616a",
      "0950638daa3846eca85a90cdd05e48b9",
      "ea8816332c464bd7b9d9dd38c2d2f677",
      "2c0e92b8cea94ac7949815a0fef19f2c",
      "f5a38cabbf0b422fa7c7595efab483b9",
      "70e228b00b1d46e4aa945470bdfaf8a5",
      "1a5e30d968cf43d5b3e06089bd768743",
      "33864b8f6a244b258a0a868bc69621ee",
      "63f0a4bf85874b279f2f202203f648c9",
      "d38db2885e214fa8a22aa2c21bdf2024",
      "4511df597bee4954937076306a7b8784",
      "7a3bd08ad75d4ebe9f8fca0c676cbdf8",
      "96cc25c3a49e4e25b0d6ded2b99ec04a",
      "2471acbae9c5425d83c49ba409699118",
      "250bc438f3c646f39c6bd284f1857b9c",
      "fa9e19d637a348ca9834686ea29e169f",
      "ba262fa175df4bc39c3932f39a5a914c",
      "fe2a8dcb1d394791bdcde4a2aeac7ae0"
     ]
    },
    "id": "JrVlX8kcL1wH",
    "outputId": "1d86cd69-3f43-4f0e-f358-91550e634dc3"
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "plt.rcParams['xtick.bottom'] = plt.rcParams['xtick.labelbottom'] = False\n",
    "plt.rcParams['xtick.top'] = plt.rcParams['xtick.labeltop'] = True\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "train_dataset = datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transform)\n",
    "test_dataset = datasets.MNIST('../data', train=False, download=True,\n",
    "                       transform=transform)\n",
    "\n",
    "num_train_samples = 10\n",
    "num_test_samples = 5\n",
    "\n",
    "train_data = torch.stack([train_dataset[i][0] for i in range(num_train_samples)])\n",
    "test_data = torch.stack([test_dataset[i][0] for i in range(num_test_samples)])\n",
    "\n",
    "train_patterns = tl.log_forward_pass(model, train_data)\n",
    "test_patterns = tl.log_forward_pass(model, test_data)\n",
    "\n",
    "out = widgets.Output()\n",
    "with plt.ioff():\n",
    "  with out:\n",
    "    fig, ax = plt.subplots(constrained_layout=True, figsize=(6, 9))\n",
    "fig.first = True\n",
    "\n",
    "def update_and_visualize(layer, rating1, rating2, rating3, rating4, rating5,\n",
    "                         rating6, rating7, rating8, rating9, rating10):\n",
    "    X_train = train_patterns[layer].tensor_contents.flatten(start_dim=1).detach().cpu().numpy()\n",
    "    X_test = test_patterns[layer].tensor_contents.flatten(start_dim=1).detach().cpu().numpy()\n",
    "    Y_train = [rating1, rating2, rating3, rating4, rating5,\n",
    "               rating6, rating7, rating8, rating9, rating10]\n",
    "    Y_train = np.array(Y_train)\n",
    "\n",
    "    # Ridge Regression\n",
    "    with warnings.catch_warnings():\n",
    "      warnings.filterwarnings('ignore')\n",
    "      model = Ridge(alpha=.99)\n",
    "      model.fit(X_train, Y_train)\n",
    "      Y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Dot product matrix visualization\n",
    "    dot_product_matrix = np.dot(X_train, X_test.T)\n",
    "    padded_matrix = np.zeros((dot_product_matrix.shape[0]+1,\n",
    "                              dot_product_matrix.shape[1]+1))\n",
    "    padded_matrix[0:-1, 1:] = dot_product_matrix\n",
    "    dot_product_matrix = padded_matrix\n",
    "\n",
    "    im = ax.imshow(dot_product_matrix, cmap='viridis')\n",
    "    if len(fig.axes) == 1:\n",
    "      plt.colorbar(im, label='Dot Product Similarity', shrink=.8)\n",
    "    im.set_clim([dot_product_matrix.min(), dot_product_matrix.max()])\n",
    "\n",
    "    dummy_image = np.zeros(train_data[0].shape)\n",
    "    dummy_image = dummy_image + float(train_data[0].max())\n",
    "    dummy_image[-1, 0, -1] = 0\n",
    "\n",
    "    # Set up figure if the first run\n",
    "\n",
    "    if fig.first:\n",
    "      ax.set_xticks([])\n",
    "      ax.set_yticks([])\n",
    "      ax.set_ylabel(\"Training Images\", fontsize=15)\n",
    "      ax.xaxis.set_label_position('top')\n",
    "      ax.set_xlabel(\"Test Images\", fontsize=15)\n",
    "      imagebox = OffsetImage(dummy_image.squeeze(), zoom=1.92, cmap='gray')\n",
    "      ab = AnnotationBbox(imagebox, (0, num_train_samples+.05), frameon=False, box_alignment=(0.5, .5))\n",
    "      ax.add_artist(ab)\n",
    "      for i in range(num_train_samples):\n",
    "          imagebox = OffsetImage(train_data[i].squeeze(), zoom=1.9, cmap='gray')\n",
    "          ab = AnnotationBbox(imagebox, (0, i), frameon=False, box_alignment=(.5, 0.5))\n",
    "          ax.add_artist(ab)\n",
    "\n",
    "      for i in range(num_test_samples):\n",
    "          imagebox = OffsetImage(test_data[i].squeeze(), zoom=1.9, cmap='gray')\n",
    "          ab = AnnotationBbox(imagebox, (i+1, num_train_samples), frameon=False, box_alignment=(0.5, .5))\n",
    "          ax.add_artist(ab)\n",
    "      t = ax.text(0, X_train.shape[0], 'X:', va='top', ha='center',\n",
    "                fontsize=15, color='black', backgroundcolor='white', fontweight='bold')\n",
    "      t = ax.text(0, X_train.shape[0]+.65, 'Y:', va='top', ha='center',\n",
    "                fontsize=15, color='black', backgroundcolor='white', fontweight='bold')\n",
    "    fig.first = False\n",
    "\n",
    "\n",
    "    # Annotate with predicted Y_test values\n",
    "\n",
    "    for i in range(num_test_samples):\n",
    "        t = ax.text(i+1, X_train.shape[0]+.65, f'{Y_test_pred[i]:.1f}', va='top', ha='center',\n",
    "                fontsize=15, color='red', backgroundcolor='white', fontweight='bold')\n",
    "\n",
    "\n",
    "w = widgets.interactive(update_and_visualize,\n",
    "         layer = widgets.Dropdown(\n",
    "            options=['conv1', 'conv2', 'dropout1', 'fc1', 'dropout2', 'fc2'],\n",
    "            value='fc2',\n",
    "            description='Layer',\n",
    "            disabled=False,\n",
    "            layout = widgets.Layout(margin='40px 10px 0 0')),\n",
    "         rating1 = widgets.FloatSlider(description='Rating', value=5, min=1, max=10, step=1, layout = widgets.Layout(margin='50px 0 43px 0'), style={'font_weight': 'bold'}),\n",
    "         rating2 = widgets.FloatSlider(description='Rating',value=5, min=1, max=10, step=1, layout = widgets.Layout(margin='0 0 43px 0'), style={'font_weight': 'bold'}),\n",
    "         rating3 = widgets.FloatSlider(description='Rating',value=5, min=1, max=10, step=1, layout = widgets.Layout(margin='0 0 43px 0'), style={'font_weight': 'bold'}),\n",
    "         rating4 = widgets.FloatSlider(description='Rating',value=5, min=1, max=10, step=1, layout = widgets.Layout(margin='0 0 43px 0'), style={'font_weight': 'bold'}),\n",
    "         rating5 = widgets.FloatSlider(description='Rating',value=5, min=1, max=10, step=1, layout = widgets.Layout(margin='0 0 43px 0'), style={'font_weight': 'bold'}),\n",
    "         rating6 = widgets.FloatSlider(description='Rating',value=5, min=1, max=10, step=1, layout = widgets.Layout(margin='0 0 43px 0'), style={'font_weight': 'bold'}),\n",
    "         rating7 = widgets.FloatSlider(description='Rating',value=5, min=1, max=10, step=1, layout = widgets.Layout(margin='0 0 43px 0'), style={'font_weight': 'bold'}),\n",
    "         rating8 = widgets.FloatSlider(description='Rating',value=5, min=1, max=10, step=1, layout = widgets.Layout(margin='0 0 43px 0'), style={'font_weight': 'bold'}),\n",
    "         rating9 = widgets.FloatSlider(description='Rating',value=5, min=1, max=10, step=1, layout = widgets.Layout(margin='0 0 43px 0'), style={'font_weight': 'bold'}),\n",
    "         rating10 = widgets.FloatSlider(description='Rating',value=5, min=1, max=10, step=1, layout = widgets.Layout(margin='0 0 43px 0'), style={'font_weight': 'bold'})\n",
    "         )\n",
    "widgets.HBox([w, fig.canvas], layout=widgets.Layout(width='100%', display='flex', align_items='stretch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A7smVeVmBdjr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "065274d1c51747e29c4e149975f4d946": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatSliderModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatSliderModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "FloatSliderView",
      "continuous_update": true,
      "description": "Rating",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_ea8816332c464bd7b9d9dd38c2d2f677",
      "max": 10,
      "min": 1,
      "orientation": "horizontal",
      "readout": true,
      "readout_format": ".2f",
      "step": 1,
      "style": "IPY_MODEL_2c0e92b8cea94ac7949815a0fef19f2c",
      "value": 5
     }
    },
    "0950638daa3846eca85a90cdd05e48b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "SliderStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "SliderStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "",
      "handle_color": null
     }
    },
    "0a4e21333d524e42a1e50589f75a0317": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e72e094a071416090c339586f4e5a4a": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_250bc438f3c646f39c6bd284f1857b9c",
      "msg_id": "",
      "outputs": []
     }
    },
    "114d68b97dc245a5a5dd346eaaa5614a": {
     "model_module": "jupyter-matplotlib",
     "model_module_version": "^0.11",
     "model_name": "MPLCanvasModel",
     "state": {
      "_cursor": "default",
      "_data_url": null,
      "_dom_classes": [],
      "_figure_label": "Figure 1",
      "_image_mode": "full",
      "_message": "",
      "_model_module": "jupyter-matplotlib",
      "_model_module_version": "^0.11",
      "_model_name": "MPLCanvasModel",
      "_rubberband_height": 0,
      "_rubberband_width": 0,
      "_rubberband_x": 0,
      "_rubberband_y": 0,
      "_size": [
       600,
       900
      ],
      "_view_count": null,
      "_view_module": "jupyter-matplotlib",
      "_view_module_version": "^0.11",
      "_view_name": "MPLCanvasView",
      "capture_scroll": false,
      "footer_visible": true,
      "header_visible": true,
      "layout": "IPY_MODEL_fa9e19d637a348ca9834686ea29e169f",
      "pan_zoom_throttle": 33,
      "resizable": true,
      "toolbar": "IPY_MODEL_ba262fa175df4bc39c3932f39a5a914c",
      "toolbar_position": "left",
      "toolbar_visible": "fade-in-fade-out"
     }
    },
    "1a5e30d968cf43d5b3e06089bd768743": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": "0 0 43px 0",
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "225a3a182aa94869a713119eca6696c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatSliderModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatSliderModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "FloatSliderView",
      "continuous_update": true,
      "description": "Rating",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_4511df597bee4954937076306a7b8784",
      "max": 10,
      "min": 1,
      "orientation": "horizontal",
      "readout": true,
      "readout_format": ".2f",
      "step": 1,
      "style": "IPY_MODEL_7a3bd08ad75d4ebe9f8fca0c676cbdf8",
      "value": 5
     }
    },
    "2471acbae9c5425d83c49ba409699118": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "SliderStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "SliderStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "",
      "handle_color": null
     }
    },
    "250bc438f3c646f39c6bd284f1857b9c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c0e92b8cea94ac7949815a0fef19f2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "SliderStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "SliderStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "",
      "handle_color": null
     }
    },
    "33864b8f6a244b258a0a868bc69621ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "SliderStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "SliderStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "",
      "handle_color": null
     }
    },
    "44937249476243e4ad401ccd7b40814b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatSliderModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatSliderModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "FloatSliderView",
      "continuous_update": true,
      "description": "Rating",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_f5a38cabbf0b422fa7c7595efab483b9",
      "max": 10,
      "min": 1,
      "orientation": "horizontal",
      "readout": true,
      "readout_format": ".2f",
      "step": 1,
      "style": "IPY_MODEL_70e228b00b1d46e4aa945470bdfaf8a5",
      "value": 5
     }
    },
    "4511df597bee4954937076306a7b8784": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": "0 0 43px 0",
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a6bca4632ca4220bdb4ab8cf10c8cc2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "SliderStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "SliderStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "",
      "handle_color": null
     }
    },
    "5a9c82737bae437d9133805ddec8616a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": "0 0 43px 0",
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "608cdffaefaa437087fd9de5c59ec3b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "63f0a4bf85874b279f2f202203f648c9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": "0 0 43px 0",
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "70e228b00b1d46e4aa945470bdfaf8a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "SliderStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "SliderStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "",
      "handle_color": null
     }
    },
    "7a3bd08ad75d4ebe9f8fca0c676cbdf8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "SliderStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "SliderStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "",
      "handle_color": null
     }
    },
    "7a95657592544c3f9196cd779bb67fb5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "SliderStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "SliderStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "",
      "handle_color": null
     }
    },
    "7af64dfb6fbc462282f26f9b00c2a93a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": "50px 0 43px 0",
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86b08ea160514defbc059f815adeec53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatSliderModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatSliderModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "FloatSliderView",
      "continuous_update": true,
      "description": "Rating",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_63f0a4bf85874b279f2f202203f648c9",
      "max": 10,
      "min": 1,
      "orientation": "horizontal",
      "readout": true,
      "readout_format": ".2f",
      "step": 1,
      "style": "IPY_MODEL_d38db2885e214fa8a22aa2c21bdf2024",
      "value": 5
     }
    },
    "87e14015ac7f4e0380500f81a7bb5b25": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8a4272a9c1b749028adff1fb098a447f",
       "IPY_MODEL_114d68b97dc245a5a5dd346eaaa5614a"
      ],
      "layout": "IPY_MODEL_f6178852891a4a01828f023c60da2c55"
     }
    },
    "8a4272a9c1b749028adff1fb098a447f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [
       "widget-interact"
      ],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b10a79ec0c7249f596ae34896d6bcc51",
       "IPY_MODEL_be4cffe5f34244edb64d03cbf0a36b70",
       "IPY_MODEL_987f2d8fedc745578cd354f3de941752",
       "IPY_MODEL_d1ce01e80a3d4511bc7dd0bdedece3f1",
       "IPY_MODEL_c2dbab3dabd5436ab14db65399b95fc8",
       "IPY_MODEL_065274d1c51747e29c4e149975f4d946",
       "IPY_MODEL_44937249476243e4ad401ccd7b40814b",
       "IPY_MODEL_ac1c39d6e7ce4f18b32a2e4a591e9c0d",
       "IPY_MODEL_86b08ea160514defbc059f815adeec53",
       "IPY_MODEL_225a3a182aa94869a713119eca6696c7",
       "IPY_MODEL_cb0c793bad144905bd9ae9378cbe7f55",
       "IPY_MODEL_0e72e094a071416090c339586f4e5a4a"
      ],
      "layout": "IPY_MODEL_0a4e21333d524e42a1e50589f75a0317"
     }
    },
    "96cc25c3a49e4e25b0d6ded2b99ec04a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": "0 0 43px 0",
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "987f2d8fedc745578cd354f3de941752": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatSliderModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatSliderModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "FloatSliderView",
      "continuous_update": true,
      "description": "Rating",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_c64b2401ac1940a79cbcdbe1b4523014",
      "max": 10,
      "min": 1,
      "orientation": "horizontal",
      "readout": true,
      "readout_format": ".2f",
      "step": 1,
      "style": "IPY_MODEL_7a95657592544c3f9196cd779bb67fb5",
      "value": 5
     }
    },
    "a7d9002c9ebf49d5a4004e37ba730789": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": "40px 10px 0 0",
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac1c39d6e7ce4f18b32a2e4a591e9c0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatSliderModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatSliderModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "FloatSliderView",
      "continuous_update": true,
      "description": "Rating",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_1a5e30d968cf43d5b3e06089bd768743",
      "max": 10,
      "min": 1,
      "orientation": "horizontal",
      "readout": true,
      "readout_format": ".2f",
      "step": 1,
      "style": "IPY_MODEL_33864b8f6a244b258a0a868bc69621ee",
      "value": 5
     }
    },
    "afe2ee92fe3a42d197f71a59d3d5ac27": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "SliderStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "SliderStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "",
      "handle_color": null
     }
    },
    "b10a79ec0c7249f596ae34896d6bcc51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DropdownModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DropdownModel",
      "_options_labels": [
       "conv1",
       "conv2",
       "dropout1",
       "fc1",
       "dropout2",
       "fc2"
      ],
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "DropdownView",
      "description": "Layer",
      "description_tooltip": null,
      "disabled": false,
      "index": 5,
      "layout": "IPY_MODEL_a7d9002c9ebf49d5a4004e37ba730789",
      "style": "IPY_MODEL_608cdffaefaa437087fd9de5c59ec3b4"
     }
    },
    "ba262fa175df4bc39c3932f39a5a914c": {
     "model_module": "jupyter-matplotlib",
     "model_module_version": "^0.11",
     "model_name": "ToolbarModel",
     "state": {
      "_current_action": "",
      "_dom_classes": [],
      "_model_module": "jupyter-matplotlib",
      "_model_module_version": "^0.11",
      "_model_name": "ToolbarModel",
      "_view_count": null,
      "_view_module": "jupyter-matplotlib",
      "_view_module_version": "^0.11",
      "_view_name": "ToolbarView",
      "button_style": "",
      "collapsed": true,
      "layout": "IPY_MODEL_fe2a8dcb1d394791bdcde4a2aeac7ae0",
      "orientation": "vertical",
      "toolitems": [
       [
        "Home",
        "Reset original view",
        "home",
        "home"
       ],
       [
        "Back",
        "Back to previous view",
        "arrow-left",
        "back"
       ],
       [
        "Forward",
        "Forward to next view",
        "arrow-right",
        "forward"
       ],
       [
        "Pan",
        "Left button pans, Right button zooms\nx/y fixes axis, CTRL fixes aspect",
        "arrows",
        "pan"
       ],
       [
        "Zoom",
        "Zoom to rectangle\nx/y fixes axis",
        "square-o",
        "zoom"
       ],
       [
        "Download",
        "Download plot",
        "floppy-o",
        "save_figure"
       ]
      ]
     }
    },
    "be4cffe5f34244edb64d03cbf0a36b70": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatSliderModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatSliderModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "FloatSliderView",
      "continuous_update": true,
      "description": "Rating",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_7af64dfb6fbc462282f26f9b00c2a93a",
      "max": 10,
      "min": 1,
      "orientation": "horizontal",
      "readout": true,
      "readout_format": ".2f",
      "step": 1,
      "style": "IPY_MODEL_4a6bca4632ca4220bdb4ab8cf10c8cc2",
      "value": 5
     }
    },
    "c2dbab3dabd5436ab14db65399b95fc8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatSliderModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatSliderModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "FloatSliderView",
      "continuous_update": true,
      "description": "Rating",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_5a9c82737bae437d9133805ddec8616a",
      "max": 10,
      "min": 1,
      "orientation": "horizontal",
      "readout": true,
      "readout_format": ".2f",
      "step": 1,
      "style": "IPY_MODEL_0950638daa3846eca85a90cdd05e48b9",
      "value": 5
     }
    },
    "c64b2401ac1940a79cbcdbe1b4523014": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": "0 0 43px 0",
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb0c793bad144905bd9ae9378cbe7f55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatSliderModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatSliderModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "FloatSliderView",
      "continuous_update": true,
      "description": "Rating",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_96cc25c3a49e4e25b0d6ded2b99ec04a",
      "max": 10,
      "min": 1,
      "orientation": "horizontal",
      "readout": true,
      "readout_format": ".2f",
      "step": 1,
      "style": "IPY_MODEL_2471acbae9c5425d83c49ba409699118",
      "value": 5
     }
    },
    "d1ce01e80a3d4511bc7dd0bdedece3f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatSliderModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatSliderModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "FloatSliderView",
      "continuous_update": true,
      "description": "Rating",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_d94767b8626342c99e060f9ed6aca5ba",
      "max": 10,
      "min": 1,
      "orientation": "horizontal",
      "readout": true,
      "readout_format": ".2f",
      "step": 1,
      "style": "IPY_MODEL_afe2ee92fe3a42d197f71a59d3d5ac27",
      "value": 5
     }
    },
    "d38db2885e214fa8a22aa2c21bdf2024": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "SliderStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "SliderStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "",
      "handle_color": null
     }
    },
    "d94767b8626342c99e060f9ed6aca5ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": "0 0 43px 0",
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea8816332c464bd7b9d9dd38c2d2f677": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": "0 0 43px 0",
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5a38cabbf0b422fa7c7595efab483b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": "0 0 43px 0",
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6178852891a4a01828f023c60da2c55": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "stretch",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "fa9e19d637a348ca9834686ea29e169f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe2a8dcb1d394791bdcde4a2aeac7ae0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
